[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "介绍",
    "section": "",
    "text": "0.1 介绍\n《用 Python 介绍数据科学》课程草稿书\n这本书是由 The GRAPH Courses 提供的一门为期 3 个月的在线课程的课程笔记汇编。要访问课程视频、练习文件和在线测验，请访问我们的网站 thegraphcourses.org。\nThe GRAPH Courses 是 Global Research and Analyses for Public Health (GRAPH) Network 的一个项目，该网络是一个非营利组织，致力于通过经济实惠的现场训练营和免费的自学课程让编程和数据技能变得触手可及。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>介绍</span>"
    ]
  },
  {
    "objectID": "index.html#贡献者",
    "href": "index.html#贡献者",
    "title": "介绍",
    "section": "0.2 贡献者",
    "text": "0.2 贡献者\n我们非常感谢以下多年来为这些资料开发做出贡献的各位：\nAmanda McKinley, Andree Valle Campos, Aziza Merzouki, Benedict Nguimbis, Bennour Hsin, Camille Beatrice Valera, Daniel Camara, Eduardo Araujo, Elton Mukonda, Guy Wafeu, Imad El Badisy, Imane Bensouda Korachi, Joy Vaz, Kene David Nwosu, Lameck Agasa, Laure Nguemo, Laure Vancauwenberghe, Matteo Franza, Michal Shrestha, Olivia Keiser, Sabina Rodriguez Velasquez, Sara Botero Mesa.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>介绍</span>"
    ]
  },
  {
    "objectID": "index.html#合作伙伴与资助方",
    "href": "index.html#合作伙伴与资助方",
    "title": "介绍",
    "section": "0.3 合作伙伴与资助方",
    "text": "0.3 合作伙伴与资助方\n\n日内瓦大学\n牛津大学\n世界卫生组织\n全球基金\nErnst Goehner 基金会",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>介绍</span>"
    ]
  },
  {
    "objectID": "index.html#欢迎视频",
    "href": "index.html#欢迎视频",
    "title": "介绍",
    "section": "0.4 欢迎视频",
    "text": "0.4 欢迎视频",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>介绍</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html",
    "href": "p_foundations_google_colab_cn.html",
    "title": "2  Google Colab 入门指南",
    "section": "",
    "text": "2.1 学习目标",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#学习目标",
    "href": "p_foundations_google_colab_cn.html#学习目标",
    "title": "2  Google Colab 入门指南",
    "section": "",
    "text": "了解 Google Colab 是什么以及它在数据科学和人工智能方面的优势\n学习如何访问和导航 Google Colab\n在 Google Colab 中创建和管理笔记本\n在 Colab 单元格中运行 Python 代码\n使用文本单元格进行解释和格式化\n导入和使用预装的数据分析库\n导入和使用数据进行分析\n分享 Colab 笔记本",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#简介",
    "href": "p_foundations_google_colab_cn.html#简介",
    "title": "2  Google Colab 入门指南",
    "section": "2.2 简介",
    "text": "2.2 简介\nGoogle Collaboratory（简称 Colab）是一个免费的在线平台，允许您在浏览器中使用 Python 或 R 代码。对于 Python 入门来说，这是一个很好的方式，因为您不需要在计算机上安装任何东西。\n如果运行重负载工作，会有一些限制。可能会出现超时。但对于初学数据分析的人来说，它是完美且免费的。\n请注意，本文档是视频的摘要，而不是替代品。您应该观看视频以获得更完整的体验。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#colab-入门",
    "href": "p_foundations_google_colab_cn.html#colab-入门",
    "title": "2  Google Colab 入门指南",
    "section": "2.3 Colab 入门",
    "text": "2.3 Colab 入门\n\n在您喜欢的搜索引擎中搜索”Google Colab”\n通常第一个结果就是正确的。目前是 colab.research.google.com，但未来可能会改变\n使用您的 Google 账户登录（如果没有，请创建一个 Gmail 账户）",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#创建和管理笔记本",
    "href": "p_foundations_google_colab_cn.html#创建和管理笔记本",
    "title": "2  Google Colab 入门指南",
    "section": "2.4 创建和管理笔记本",
    "text": "2.4 创建和管理笔记本\n\n笔记本是在 Colab 中组织工作的主要方式，包含代码单元格和文本单元格\n创建新笔记本：文件 &gt; 新建笔记本\n重命名笔记本以便于组织",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#使用代码单元格",
    "href": "p_foundations_google_colab_cn.html#使用代码单元格",
    "title": "2  Google Colab 入门指南",
    "section": "2.5 使用代码单元格",
    "text": "2.5 使用代码单元格\n\n左上角应该有一个按钮，允许您添加代码或文本单元格\n代码单元格是编写和执行 Python 代码的地方\n在单元格中输入 1 + 1 然后运行\n通过点击播放按钮或使用键盘快捷键运行单元格：\n\nMac 上使用 Command + Enter 或 Windows 上使用 Ctrl + Enter：运行当前单元格\nShift + Enter：运行当前单元格并在下方创建新单元格\n\n尝试熟悉键盘快捷键\n第一次运行代码单元格可能需要一段时间，因为需要初始化 Python 引擎\n运行单元格时，最终输出显示在单元格下方\n要查看多个输出，请使用 print() 显式打印。例如：\n\nprint(1)\nprint(2)",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#文本单元格",
    "href": "p_foundations_google_colab_cn.html#文本单元格",
    "title": "2  Google Colab 入门指南",
    "section": "2.6 文本单元格",
    "text": "2.6 文本单元格\n\n使用文本单元格进行解释和标题\n文本单元格上方的工具栏允许您格式化文本，但要注意生成的 markdown",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#数据处理示例",
    "href": "p_foundations_google_colab_cn.html#数据处理示例",
    "title": "2  Google Colab 入门指南",
    "section": "2.7 数据处理示例",
    "text": "2.7 数据处理示例\n\n点击文件选项卡查看”sample_data”文件夹\n导入加利福尼亚房屋测试数据集：\n\nimport pandas\nhousing_data = pandas.read_csv(\"/content/sample_data/california_housing_test.csv\")\nhousing_data.describe()\n\n在单元格中输入 housing_data 并运行以查看数据集",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#练习题导入数据",
    "href": "p_foundations_google_colab_cn.html#练习题导入数据",
    "title": "2  Google Colab 入门指南",
    "section": "2.8 练习题：导入数据",
    "text": "2.8 练习题：导入数据\n\n导入”california_housing_train”数据集\n使用 describe() 函数获取数据集摘要",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#从-drive-获取数据",
    "href": "p_foundations_google_colab_cn.html#从-drive-获取数据",
    "title": "2  Google Colab 入门指南",
    "section": "2.9 从 Drive 获取数据",
    "text": "2.9 从 Drive 获取数据\n\n在文件选项卡中，点击按钮挂载您的驱动器\n创建文件夹并从计算机上传 CSV 文件到该文件夹\n我们可以像之前一样使用 pandas 导入数据",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#练习题导入数据-1",
    "href": "p_foundations_google_colab_cn.html#练习题导入数据-1",
    "title": "2  Google Colab 入门指南",
    "section": "2.10 练习题：导入数据",
    "text": "2.10 练习题：导入数据\n\n导入您上传到驱动器的 CSV 文件\n使用 describe() 函数获取数据集摘要",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#笔记本保存在哪里",
    "href": "p_foundations_google_colab_cn.html#笔记本保存在哪里",
    "title": "2  Google Colab 入门指南",
    "section": "2.11 笔记本保存在哪里？",
    "text": "2.11 笔记本保存在哪里？\n\n所有工作自动保存到您的 Google Drive\n在 drive.google.com 的”Colab Notebooks”文件夹中访问您的笔记本",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#分享和协作",
    "href": "p_foundations_google_colab_cn.html#分享和协作",
    "title": "2  Google Colab 入门指南",
    "section": "2.12 分享和协作",
    "text": "2.12 分享和协作\n\n通过链接分享笔记本，给予查看者或编辑者访问权限\n之后可以从 Google Drive 访问笔记本\n以各种格式下载笔记本（ipynb, py）",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_google_colab_cn.html#结论",
    "href": "p_foundations_google_colab_cn.html#结论",
    "title": "2  Google Colab 入门指南",
    "section": "2.13 结论",
    "text": "2.13 结论\nGoogle Colab 为数据科学和人工智能项目提供了一个强大、易用的平台。它预配置的环境和便捷的分享功能使其成为开始数据分析的绝佳方式。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Google Colab 入门指南</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html",
    "href": "p_foundations_coding_basics_cn.html",
    "title": "3  编程基础",
    "section": "",
    "text": "3.1 学习目标",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#学习目标",
    "href": "p_foundations_coding_basics_cn.html#学习目标",
    "title": "3  编程基础",
    "section": "",
    "text": "你可以在 Python 中编写和使用注释(单行和多行)。\n你知道如何将 Python 用作基本算术运算的计算器,并理解运算顺序。\n你可以使用数学库进行更复杂的数学运算。\n你理解如何在 Python 代码中使用适当的间距以提高可读性。\n你可以创建、操作和重新赋值不同类型的变量(字符串、整数、浮点数)。\n你可以获取用户输入并进行计算。\n你理解在 Python 中命名变量的基本规则和最佳实践。\n你可以识别并修复与变量使用和命名相关的常见错误。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#介绍",
    "href": "p_foundations_coding_basics_cn.html#介绍",
    "title": "3  编程基础",
    "section": "3.2 介绍",
    "text": "3.2 介绍\n在本课程中,你将学习使用 Python 的基础知识。\n要开始,请打开你喜欢的 Python 环境(例如 Jupyter Notebook、VS Code 或 PyCharm),并创建一个新的 Python 文件或笔记本。\n接下来,根据你的环境,保存文件,文件名如“coding_basics.py”或“coding_basics.ipynb”。\n你现在应该将本课程中的所有代码输入到该文件中。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#注释",
    "href": "p_foundations_coding_basics_cn.html#注释",
    "title": "3  编程基础",
    "section": "3.3 注释",
    "text": "3.3 注释\n注释是 Python 忽略的文本。它们用于解释代码在做什么。\n你使用符号 #,读作“井号”或“pound”,来开始注释。同一行中 # 之后的任何内容都会被忽略。例如:\n\n# 加法\n2 + 2\n\n4\n\n\n如果我们只是尝试在代码上方写 Addition,会导致错误:\n\nAddition\n2 + 2\n\nNameError: name 'Addition' is not defined\n我们可以将注释放在代码的同一行,但它需要放在代码之后。\n\n2 + 2  # 加法\n\n4\n\n\n要编写多行注释,你可以添加更多的 # 符号:\n\n# 加法\n# 添加两个数字\n2 + 2\n\n4\n\n\n或者你可以使用三引号 ''' 或 \"\"\":\n\n'''\n加法:\n下面我们添加两个数字\n'''\n2 + 2\n\n4\n\n\n或者:\n\n\"\"\"\n加法:\n下面我们添加两个数字\n\"\"\"\n2 + 2\n\n4\n\n\n\n\n\n\n\n\n词汇\n\n\n\n注释:代码中被 Python 忽略的一段文本。注释用于解释代码在做什么,旨在供人类阅读。\n\n\n\n\n\n\n\n\n练习\n\n\n\n3.4 练习题:Python 中的注释\n以下哪些代码块是有效的 Python 注释方式?\n# 添加两个数字\n2 + 2\n2 + 2 # 添加两个数字\n''' 添加两个数字\n2 + 2\n# 添加两个数字 2 + 2\n通过尝试运行每个代码块来检查你的答案。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题python-中的注释",
    "href": "p_foundations_coding_basics_cn.html#练习题python-中的注释",
    "title": "3  编程基础",
    "section": "3.4 练习题:Python 中的注释",
    "text": "3.4 练习题:Python 中的注释\n以下哪些代码块是有效的 Python 注释方式?\n# 添加两个数字\n2 + 2\n2 + 2 # 添加两个数字\n''' 添加两个数字\n2 + 2\n# 添加两个数字 2 + 2\n通过尝试运行每个代码块来检查你的答案。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#python-作为计算器",
    "href": "p_foundations_coding_basics_cn.html#python-作为计算器",
    "title": "3  编程基础",
    "section": "3.5 Python 作为计算器",
    "text": "3.5 Python 作为计算器\n如你所见,Python 可以按照标准方式作为计算器使用。\n以下是一些其他基本算术运算的例子:\n\n2 - 2 # 二减二\n\n0\n\n\n\n2 * 2  # 二乘二 \n\n4\n\n\n\n2 / 2  # 二除以二\n\n1.0\n\n\n\n2 ** 2  # 二的二次方\n\n4\n\n\n还有一些你可能会遇到的其他运算符。例如,% 是取模运算符,它返回除法的余数。\n\n10 % 3  # 十模三\n\n1\n\n\n// 是地板除运算符,它先除法然后向下取整到最接近的整数。\n\n10 // 3  # 十地板除三\n\n3\n\n\n\n\n\n\n\n\n练习\n\n\n\n3.6 练习题:取模与地板除\n猜测以下代码块的结果,然后运行它们以检查你的答案:\n\n5 % 4\n\n\n5 // 4",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题取模与地板除",
    "href": "p_foundations_coding_basics_cn.html#练习题取模与地板除",
    "title": "3  编程基础",
    "section": "3.6 练习题:取模与地板除",
    "text": "3.6 练习题:取模与地板除\n猜测以下代码块的结果,然后运行它们以检查你的答案:\n\n5 % 4\n\n\n5 // 4",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#运算顺序",
    "href": "p_foundations_coding_basics_cn.html#运算顺序",
    "title": "3  编程基础",
    "section": "3.7 运算顺序",
    "text": "3.7 运算顺序\nPython 遵循标准的 PEMDAS 运算顺序(括号、指数、乘法、除法、加法、减法)。\n例如,乘法在加法之前计算,所以下面的结果是 6。\n\n2 + 2 * 2   \n\n6\n\n\n\n\n\n\n\n\n练习\n\n\n\n3.8 练习题:评估算术表达式\n以下哪些代码块将计算为 10?\n\n2 + 2 * 4\n\n\n6 + 2 ** 2",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题评估算术表达式",
    "href": "p_foundations_coding_basics_cn.html#练习题评估算术表达式",
    "title": "3  编程基础",
    "section": "3.8 练习题:评估算术表达式",
    "text": "3.8 练习题:评估算术表达式\n以下哪些代码块将计算为 10?\n\n2 + 2 * 4\n\n\n6 + 2 ** 2",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#使用数学库",
    "href": "p_foundations_coding_basics_cn.html#使用数学库",
    "title": "3  编程基础",
    "section": "3.9 使用数学库",
    "text": "3.9 使用数学库\n我们还可以使用 math 库来进行更复杂的数学运算。例如,我们可以使用 math.sqrt 函数计算一个数的平方根。\n\nimport math\nmath.sqrt(100)  # 平方根\n\n10.0\n\n\n或者我们可以使用 math.log 函数计算一个数的自然对数。\n\nimport math\nmath.log(100)  # 对数\n\n4.605170185988092\n\n\nmath.sqrt 和 math.log 是 Python 函数 的例子,其中一个 参数(例如 100)被传递给函数以进行计算。\n我们将在后面学习更多关于函数的内容。\n\n\n\n\n\n\n词汇\n\n\n\n函数:执行特定任务的可重用代码块。函数通常接受输入(称为参数)并返回输出。\n\n\n\n\n\n\n\n\n练习\n\n\n\n\n3.10 练习题:使用数学库\n使用 math 库,计算 81 的平方根。\n在下方编写你的代码并运行以检查你的答案:\n\n# 你的代码在这里\n\n\n\n3.11 练习题:描述 Random 库的使用\n考虑以下代码,它生成一个 1 到 10 之间的随机数:\n\nimport random\nrandom.randint(1, 10)\n\n1\n\n\n在这段代码中,确定库、函数和函数的参数。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题使用数学库",
    "href": "p_foundations_coding_basics_cn.html#练习题使用数学库",
    "title": "3  编程基础",
    "section": "3.10 练习题:使用数学库",
    "text": "3.10 练习题:使用数学库\n使用 math 库,计算 81 的平方根。\n在下方编写你的代码并运行以检查你的答案:\n\n# 你的代码在这里",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题描述-random-库的使用",
    "href": "p_foundations_coding_basics_cn.html#练习题描述-random-库的使用",
    "title": "3  编程基础",
    "section": "3.11 练习题:描述 Random 库的使用",
    "text": "3.11 练习题:描述 Random 库的使用\n考虑以下代码,它生成一个 1 到 10 之间的随机数:\n\nimport random\nrandom.randint(1, 10)\n\n1\n\n\n在这段代码中,确定库、函数和函数的参数。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#代码中的间距",
    "href": "p_foundations_coding_basics_cn.html#代码中的间距",
    "title": "3  编程基础",
    "section": "3.12 代码中的间距",
    "text": "3.12 代码中的间距\n良好的间距使你的代码更易读。在 Python 中,两个简单的间距实践可以大大提高代码的可读性:使用空行和在运算符周围添加空格。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#缩进",
    "href": "p_foundations_coding_basics_cn.html#缩进",
    "title": "3  编程基础",
    "section": "3.13 缩进",
    "text": "3.13 缩进\nPython 使用缩进来表示循环、函数和其他代码块的开始和结束。我们将在后面的课程中详细介绍这一点。\n目前,需要注意的一件事是避免在代码前意外加入空格。\n例如,考虑以下代码块:\n\nimport math\n# 获取 100 的平方根\n math.sqrt(100)\n\n尝试运行这段代码会导致错误:\nIndentationError: unexpected indent\n这是由于 math.sqrt 函数前的空格。我们可以通过删除空格来修复它。\n\nimport math\n# 获取 100 的平方根\nmath.sqrt(100)",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#空行",
    "href": "p_foundations_coding_basics_cn.html#空行",
    "title": "3  编程基础",
    "section": "3.14 空行",
    "text": "3.14 空行\n使用空行来分隔代码的不同部分。\n例如,考虑以下代码块:\n\n# 设置数字\nx = 5\ny = 10\n# 执行计算\nresult = x + y\n# 显示结果\nprint(result)\n\n15\n\n\n我们可以添加空行来分隔代码的不同部分:\n\n# 设置数字\nx = 5\ny = 10\n\n# 执行计算\nresult = x + y\n\n# 显示结果\nprint(result)\n\n15\n\n\n空行有助于将代码组织成逻辑部分,类似于书写中的段落。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#运算符周围的空格",
    "href": "p_foundations_coding_basics_cn.html#运算符周围的空格",
    "title": "3  编程基础",
    "section": "3.15 运算符周围的空格",
    "text": "3.15 运算符周围的空格\n在数学运算符周围添加空格可以提高可读性:\n\n# 难以阅读\nx=5+3*2\n\n# 容易阅读\nx = 5 + 3 * 2\n\n在列举项目时,在每个逗号后添加一个空格:\n\n# 难以阅读\nprint(1,2,3)\n\n# 容易阅读\nprint(1, 2, 3)\n\n这一做法遵循书面英语的惯例,我们在逗号后加一个空格。它使代码中的项目列表更易读。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#python-中的变量",
    "href": "p_foundations_coding_basics_cn.html#python-中的变量",
    "title": "3  编程基础",
    "section": "3.16 Python 中的变量",
    "text": "3.16 Python 中的变量\n如你所见,为了在 Python 中存储一个值以供将来使用,我们使用 赋值运算符 = 将其赋值给一个 变量。\n\nmy_var = 2 + 2  # 将 `2 + 2` 的结果赋值给名为 `my_var` 的变量\nprint(my_var)  # 打印 my_var\n\n4\n\n\n现在你已经创建了变量 my_var,Python 知道它并将在这个 Python 会话中跟踪它。\n你可以打开你的环境查看你创建了哪些变量。这取决于你的 IDE 而有所不同。\n那么,变量到底是什么?可以将其视为一个命名的容器,可以保存一个值。当你运行以下代码:\n\nmy_var = 20\n\n你是在告诉 Python,“将数字 20 存储在名为 ‘my_var’ 的变量中”。\n一旦代码运行,我们可以用 Python 术语说,“变量 my_var 的值是 20”。\n尝试为以下代码块编写类似的句子:\n\nfirst_name = \"Joanna\"\n\n运行这段代码后,我们可以用 Python 术语说,“变量 first_name 的值是 Joanna”。\n\n\n\n\n\n\n词汇\n\n\n\n像 “Joanna” 这样的文本值称为 字符串,而像 20 这样的数字称为 整数。如果数字有小数点,则称为 浮点数,是“浮点数”(floating-point number)的简称。\n以下是这三种变量类型的示例:\n\n# 字符串变量\nfirst_name = \"Joanna\"\n\n# 整数变量\nage = 5\n\n# 浮点数变量\nheight = 1.4\n\n你可以使用 type() 函数检查变量的类型。\n\nprint(type(first_name))\nprint(type(age))\nprint(type(height))\n\n&lt;class 'str'&gt;\n&lt;class 'int'&gt;\n&lt;class 'float'&gt;\n\n\n\n\n\n\n\n\n\n\n词汇\n\n\n\n变量:一个可以保存值的命名容器。在 Python 中,变量可以存储不同类型的数据,包括数字、字符串和更复杂的对象。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#重新赋值变量",
    "href": "p_foundations_coding_basics_cn.html#重新赋值变量",
    "title": "3  编程基础",
    "section": "3.17 重新赋值变量",
    "text": "3.17 重新赋值变量\n重新赋值变量就像是更改容器的内容。\n例如,之前我们运行了这段代码,将值 “Joanna” 存储在 first_name 变量中:\n\nfirst_name = \"Joanna\"\n\n要将其更改为不同的值,只需运行一个新的赋值语句并使用新值:\n\nfirst_name = \"Luigi\"\n\n你可以打印变量以观察变化:\n\nfirst_name\n\n'Luigi'",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#操作变量",
    "href": "p_foundations_coding_basics_cn.html#操作变量",
    "title": "3  编程基础",
    "section": "3.18 操作变量",
    "text": "3.18 操作变量\n大部分时间你将在 Python 中操作变量。让我们看一些快速的例子。\n你可以对变量运行简单的命令。例如,下面我们将值 100 存储在变量中,然后对变量取平方根:\n\nimport math\n\nmy_number = 100\nmath.sqrt(my_number)\n\n10.0\n\n\nPython 将 my_number 视为数字 100,因此能够计算其平方根。\n\n你还可以将现有变量组合起来创建新变量。例如,输入以下代码,将 my_number 加到自身,并将结果存储在名为 my_sum 的新变量中:\n\nmy_sum = my_number + my_number\nmy_sum\n\n200\n\n\nmy_sum 的值应该是多少?先猜测,然后通过打印来检查。\n\nPython 还允许我们使用 + 运算符连接字符串。例如,我们可以连接 first_name 和 last_name 变量来创建一个名为 full_name 的新变量:\n\nfirst_name = \"Joanna\"\nlast_name = \"Luigi\"\nfull_name = first_name + \" \" + last_name\nfull_name\n\n'Joanna Luigi'\n\n\n\n\n\n\n\n\n练习\n\n\n\n3.19 练习题:变量赋值与操作\n考虑以下代码。变量 answer 的值是多少?想一想,然后运行代码检查你的答案。\n\neight = 9\nanswer = eight - 8\nanswer",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题变量赋值与操作",
    "href": "p_foundations_coding_basics_cn.html#练习题变量赋值与操作",
    "title": "3  编程基础",
    "section": "3.19 练习题:变量赋值与操作",
    "text": "3.19 练习题:变量赋值与操作\n考虑以下代码。变量 answer 的值是多少?想一想,然后运行代码检查你的答案。\n\neight = 9\nanswer = eight - 8\nanswer",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#获取用户输入",
    "href": "p_foundations_coding_basics_cn.html#获取用户输入",
    "title": "3  编程基础",
    "section": "3.20 获取用户输入",
    "text": "3.20 获取用户输入\n尽管在数据分析中不常用,但 Python 的 input() 函数是一个很酷的 Python 功能,你应该了解。它允许你获取用户输入。\n这是一个简单的例子。我们可以请求用户输入并将其存储在名为 name 的变量中。\n\nname = input()\n\n然后我们可以向用户打印一个问候语。\n\nprint(\"Hello,\", name)\n\n我们还可以在输入提示中包含一个问题:\n\nname = input('What is your name? ')\nprint(\"Hello,\", name)\n\n让我们看另一个例子。我们将告诉用户他们名字中有多少个字母。\n\nname = input('What is your name? ')\nprint(\"There are\", len(name), \"letters in your name\")\n\n例如,如果你运行这段代码并输入 “Kene”,你可能会看到:\nWhat is your name? Kene\nThere are 4 letters in your name\n\n\n\n\n\n\n练习\n\n\n\n3.21 练习题:使用 Input()\n编写一个简短的程序,询问用户他们最喜欢的颜色,然后打印一条消息,说“xx 颜色也是我最喜欢的颜色!”,其中 xx 是他们输入的颜色。通过运行程序并输入一个颜色来测试你的程序。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题使用-input",
    "href": "p_foundations_coding_basics_cn.html#练习题使用-input",
    "title": "3  编程基础",
    "section": "3.21 练习题:使用 Input()",
    "text": "3.21 练习题:使用 Input()\n编写一个简短的程序,询问用户他们最喜欢的颜色,然后打印一条消息,说“xx 颜色也是我最喜欢的颜色!”,其中 xx 是他们输入的颜色。通过运行程序并输入一个颜色来测试你的程序。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#与变量相关的常见错误",
    "href": "p_foundations_coding_basics_cn.html#与变量相关的常见错误",
    "title": "3  编程基础",
    "section": "3.22 与变量相关的常见错误",
    "text": "3.22 与变量相关的常见错误\n在 Python 中使用变量时,你会遇到的最常见错误之一是 NameError。当你尝试使用一个尚未定义的变量时,就会发生这种错误。例如:\n\nmy_number = 48  # 定义 `my_number`\nMy_number + 2  # 尝试将 2 加到 `my_number`\n\n如果你运行这段代码,会得到如下错误信息:\nNameError: name 'My_number' is not defined\n在这里,Python 返回错误信息,因为我们尚未创建(或 定义)变量 My_number。记住,Python 是区分大小写的;我们定义了 my_number,但尝试使用 My_number。\n要修复此问题,确保你使用的是正确的变量名:\n\nmy_number = 48\nmy_number + 2  # 这将工作并返回 50\n\n50\n\n\n始终仔细检查你的变量名以避免此错误。记住,在 Python 中,my_number、My_number 和 MY_NUMBER 都是不同的变量。\n\n当你开始学习 Python 时,处理错误可能会令人沮丧。它们通常很难理解。\n但习惯读取和理解错误很重要,因为你在编码职业生涯中会经常遇到错误。\n稍后,我们将向你展示如何使用像 ChatGPT 这样的语言模型(LLMs)来调试错误。\n但在此之前,最好尝试自己发现和修复错误。\n\n\n\n\n\n\n练习\n\n\n\n3.23 练习题:调试变量错误\n下面的代码返回一个错误。为什么?(仔细看看)\n\nmy_1st_name = \"Kene\"\nmy_last_name = \"Nwosu\"\n\nprint(my_Ist_name, my_last_name)\n\n提示:看看变量名。它们是否一致?",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题调试变量错误",
    "href": "p_foundations_coding_basics_cn.html#练习题调试变量错误",
    "title": "3  编程基础",
    "section": "3.23 练习题:调试变量错误",
    "text": "3.23 练习题:调试变量错误\n下面的代码返回一个错误。为什么?(仔细看看)\n\nmy_1st_name = \"Kene\"\nmy_last_name = \"Nwosu\"\n\nprint(my_Ist_name, my_last_name)\n\n提示:看看变量名。它们是否一致?",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#命名变量",
    "href": "p_foundations_coding_basics_cn.html#命名变量",
    "title": "3  编程基础",
    "section": "3.24 命名变量",
    "text": "3.24 命名变量\n\n计算机科学中只有 两件难事:缓存失效和 命名事物。\n— Phil Karlton.\n\n因为你在 Python 中的很多工作涉及与你创建的变量互动,给这些变量选择智能的名字很重要。\n命名变量很难,因为名字应该既 简短(这样你可以快速键入它们)又 信息丰富(这样你可以轻松记住变量包含的内容),而这两个目标往往相冲突。\n因此,像下面这样太长的名字是不好的,因为它们需要很长时间来输入。\n\nsample_of_the_ebola_outbreak_dataset_from_sierra_leone_in_2014\n\n而像 data 这样的名字也是不好的,因为它不具有信息性;名字没有很好地说明变量包含什么。\n随着你编写更多的 Python 代码,你将学会如何编写简短且信息丰富的名字。\n\n对于由多个单词组成的名字,有几种约定用于分隔单词:\n\nsnake_case = \"蛇形命名使用下划线\"\ncamelCase = \"骆驼命名法将新单词首字母大写(但不包括第一个单词)\"\nPascalCase = \"帕斯卡命名法将所有单词包括第一个单词都首字母大写\"\n\n我们推荐 snake_case,它使用全小写单词,并用 _ 分隔单词。\n\n还要注意,变量名有一些限制:\n\n名称必须以字母或下划线开头。因此 2014_data 不是一个有效的名字(因为它以数字开头)。尝试运行下面的代码块看看会得到什么错误。\n\n\n2014_data = \"This is not a valid name\"\n\n\n名称只能包含字母、数字和下划线 (_)。因此 ebola-data 或 ebola~data 或带空格的 ebola data 都不是有效的名字。\n\n\nebola-data = \"This is not a valid name\"\n\n\nebola~data = \"This is not a valid name\"\n\n\n\n\n\n\n\n附注\n\n\n\n虽然我们在 Python 中推荐使用 snake_case 作为变量名,但你可能会看到其他约定,如 camelCase 或 PascalCase,特别是在使用其他语言的代码或某些 Python 库时。在你自己的代码中要保持一致,并遵循你所工作的任何项目或团队的惯例。\n\n\n\n\n\n\n\n\n练习\n\n\n\n3.25 练习题:有效的变量命名约定\n以下哪些变量名在 Python 中是有效的?尝试在不运行代码的情况下确定,然后通过尝试运行每行代码来检查你的答案。\n然后修复无效的变量名。\n\n1st_name = \"John\"\nlast_name = \"Doe\"\nfull-name = \"John Doe\"\nage_in_years = 30\ncurrent@job = \"Developer\"\nPhoneNumber = \"555-1234\"\n_secret_code = 42",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#练习题有效的变量命名约定",
    "href": "p_foundations_coding_basics_cn.html#练习题有效的变量命名约定",
    "title": "3  编程基础",
    "section": "3.25 练习题:有效的变量命名约定",
    "text": "3.25 练习题:有效的变量命名约定\n以下哪些变量名在 Python 中是有效的?尝试在不运行代码的情况下确定,然后通过尝试运行每行代码来检查你的答案。\n然后修复无效的变量名。\n\n1st_name = \"John\"\nlast_name = \"Doe\"\nfull-name = \"John Doe\"\nage_in_years = 30\ncurrent@job = \"Developer\"\nPhoneNumber = \"555-1234\"\n_secret_code = 42",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_coding_basics_cn.html#总结",
    "href": "p_foundations_coding_basics_cn.html#总结",
    "title": "3  编程基础",
    "section": "3.26 总结",
    "text": "3.26 总结\n在本课程中,我们涵盖了 Python 编程的基本构建块:\n\n注释:使用 # 进行单行注释和三引号进行多行注释。\n基本算术:将 Python 用作计算器,并理解运算顺序。\n数学库:执行复杂的数学运算。\n代码间距:通过适当的间距提高可读性。\n变量:创建、操作和重新赋值不同类型的变量。\n获取用户输入:使用 input() 函数获取用户输入。\n变量命名:遵循命名变量的规则和最佳实践。\n常见错误:识别并修复与变量相关的错误。\n\n这些概念构成了 Python 编程的基础。随着你继续学习,你将以这些基础为基础,创建更复杂和强大的程序。记住,实践是掌握这些概念的关键!",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>编程基础</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html",
    "href": "p_foundations_functions_methods_cn.html",
    "title": "4  Python中的函数、方法和库",
    "section": "",
    "text": "4.1 学习目标",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#学习目标",
    "href": "p_foundations_functions_methods_cn.html#学习目标",
    "title": "4  Python中的函数、方法和库",
    "section": "",
    "text": "你理解Python中的函数和方法是什么。\n你能识别和使用函数和方法中的参数。\n你知道如何在对象上调用内置函数和方法。\n你理解Python中的库及其导入方式。\n你知道如何安装一个简单的外部库并在代码中使用它。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#介绍",
    "href": "p_foundations_functions_methods_cn.html#介绍",
    "title": "4  Python中的函数、方法和库",
    "section": "4.2 介绍",
    "text": "4.2 介绍\n在本课中,你将学习Python中的函数、方法和库,基于我们在前一课中涵盖的基础知识。\n首先,打开你喜欢的Python环境(例如,Jupyter Notebook、VS Code或PyCharm),并创建一个新的Python文件或笔记本。\n接下来,根据你的环境,将文件保存为类似 “functions_and_libraries.py” 或 “functions_and_libraries.ipynb” 的名称。\n现在,你应该将本课的所有代码输入到该文件中。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#函数",
    "href": "p_foundations_functions_methods_cn.html#函数",
    "title": "4  Python中的函数、方法和库",
    "section": "4.3 函数",
    "text": "4.3 函数\n函数是执行特定任务的一段代码。它可以接收输入(参数)并返回输出。以下是一个只使用一个参数的内置函数的例子:\n\n# Using the len() function to get the length of a string\nlen(\"Python\")\n\n6\n\n\nround()函数接受两个参数:要四舍五入的数字和要四舍五入的小数位数。\n\n# Using the round() function to round a number\nround(3.1415, 2)\n\n3.14\n\n\n\n\n\n\n\n\n练习\n\n\n\n4.3.1 问题:使用内置函数\n使用abs()函数获取-5的绝对值。\n在下方编写你的代码并运行以检查答案:\n\n# Your code here",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#参数形参",
    "href": "p_foundations_functions_methods_cn.html#参数形参",
    "title": "4  Python中的函数、方法和库",
    "section": "4.4 参数(形参)",
    "text": "4.4 参数(形参)\n参数(也称为形参)是在调用函数(或方法)时传递给它的值。\n传递参数给函数有不同的方法。\n再次考虑round()函数。\n如果我们查看round()函数的文档,使用:\n\nround?\n\n我们看到它接受两个参数:\n\nnumber:要四舍五入的数字。\nndigits:要四舍五入的小数位数。\n\n传递参数给这个函数有两种主要的方法。\n\n位置参数:按照定义的顺序传递。由于参数的默认顺序是number然后ndigits,我们可以按照这个顺序传递参数,而无需指定参数名,就像上面所做的那样。\n\n\nround(3.1415, 2)\n\n3.14\n\n\n如果我们交换参数的顺序,就会出现错误:\n\nround(2, 3.1415)\n\n\n关键字参数:通过指定参数名后跟=和参数值来传递。\n\n\nround(number=3.1415, ndigits=2)\n\n3.14\n\n\n使用这种方法,我们可以按任何顺序传递参数,只要使用参数名。\n\nround(ndigits=2, number=3.1415)\n\n3.14\n\n\n通常建议指定关键字,除非函数简单且参数很少,或者从上下文中参数的顺序很明显。\n\n\n\n\n\n\n练习\n\n\n\n\n4.4.1 问题:使用位置参数与pow()\n使用pow()函数通过传递位置参数来计算2的7次方。你可能需要查阅pow()函数的文档来了解它的工作方式。\n在下方编写你的代码并运行以检查答案:\n\n# Your code here\n\n\n\n4.4.2 问题:使用关键字参数与round()\n使用round()函数通过指定关键字参数将数字9.87652四舍五入到3位小数。\n在下方编写你的代码并运行以检查答案:\n\n# Your code here",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#方法",
    "href": "p_foundations_functions_methods_cn.html#方法",
    "title": "4  Python中的函数、方法和库",
    "section": "4.5 方法",
    "text": "4.5 方法\n方法类似于函数,但它们与特定的对象或数据类型相关联。它们通过点符号调用。\n例如,每个字符串对象都有一系列内置方法,如upper()用于转换为大写,lower()用于转换为小写,replace()用于替换子字符串等等。\n让我们看看如何使用这些方法:\n\nname = \"python\"\nprint(name.upper())\nprint(name.lower())\nprint(name.replace(\"p\", \"🐍\"))\n\nPYTHON\npython\n🐍ython\n\n\n我们还可以直接在字符串对象上调用这些方法,而不将其赋值给变量:\n\n# Using the upper() method on a string\nprint(\"python\".upper())\nprint(\"PYTHON\".lower())\nprint(\"python\".replace(\"p\", \"🐍\"))\n\nPYTHON\npython\n🐍ython\n\n\n同样,Python中的数字也有一些内置方法。例如,as_integer_ratio()(在Python 3.8中添加)方法将一个小数转换为两个整数的比率。\n\n# Using the as_integer_ratio() method on a float\nexample_decimal = 1.5\nexample_decimal.as_integer_ratio()\n\n(3, 2)\n\n\n\n\n\n\n\n\n练习\n\n\n\n4.5.1 问题:术语定义\n想出以下术语的简明定义,使对你而言清晰(即使在技术上不是完全准确的):\n\nFunction\nMethod\nArgument (Parameter)\nDot Notation\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n4.5.2 问题:使用方法\n\n在字符串 “Helo” 上调用 replace() 方法,将单个 l 替换为双 l。\n在字符串 “Hello World” 上调用 split() 方法,将字符串拆分为单词列表。\n\n\n# Your code here",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#python中的库",
    "href": "p_foundations_functions_methods_cn.html#python中的库",
    "title": "4  Python中的函数、方法和库",
    "section": "4.6 Python中的库",
    "text": "4.6 Python中的库\n库是你可以在程序中使用的预编写代码的集合。它们通过提供额外的函数和工具扩展了Python的功能。\n例如,math库提供数学函数,如用于平方根的sqrt()和用于正弦的sin()。\n如果我们在未导入math库的情况下尝试使用sqrt()函数,就会出现错误:\n\n# This will cause a NameError\nsqrt(16)\n\n我们可以导入math库并像这样使用sqrt()函数:\n\n# Import the library\nimport math\n\n然后我们可以像这样使用sqrt()函数:\n\n# Use the sqrt() function\nmath.sqrt(16)\n\n4.0\n\n\n我们可以以类似的方式获取函数的帮助,调用函数和它所在的库:\n\n# Get help on the sqrt() function\nmath.sqrt?\n\n我们还可以为库取别名进行导入。例如,我们可以将math库导入并取别名为m:\n\n# Import the entire library with an alias\nimport math as m\n# Then we can use the alias to call the function\nm.sqrt(16)\n\n4.0\n\n\n最后,如果你想省略别名/库名,你可以单独导入函数:\n\n# Import specific functions from a library\nfrom math import sqrt, sin\n# Then we can use the function directly\nsqrt(16)\nsin(0)\n\n0.0\n\n\n或者导入库中的所有内容:\n\n# Import everything from the library\nfrom math import *\n# Then we can all functions directly, such as sqrt() and sin()\nsqrt(16)\ncos(0)\ntan(0)\nsin(0)\n\n0.0\n\n\n真是有很多导入库的方法!你大部分时间会看到import ... as ...语法,有时也会看到from ... import ...语法。\n注意,通常我们会在文件的顶部,在一个代码块中导入所有需要的库。这是一种良好的实践。\n\n\n\n\n\n\n练习\n\n\n\n4.6.1 问题:术语定义\n想出以下术语的简明定义,使对你来说清晰(即使在技术上并不完全准确的):\n\nLibrary (Module)\nImport\nAlias\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n4.6.2 问题:使用已导入库的函数\n\n导入random库并使用randint()函数生成1到10之间的随机整数。导入后,你可以使用?运算符获取关于该函数的帮助。\n\n\n# Your code here",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#安装库",
    "href": "p_foundations_functions_methods_cn.html#安装库",
    "title": "4  Python中的函数、方法和库",
    "section": "4.7 安装库",
    "text": "4.7 安装库\n虽然Python自带了许多内置库,但还有成千上万的额外库可用,你可以安装它们以进一步扩展Python的功能。让我们以cowsay库为例,看看如何安装和使用一个简单的外部库。\n如果我们在未先安装此库的情况下尝试导入它,就会出现错误:\n\nimport cowsay\n\n要安装该库,你可以在Google Colab的代码单元中使用!pip install命令。对于cowsay,你需要运行:\n\n!pip install cowsay\n\nPip从称为PyPI的远程仓库安装软件包。任何人都可以创建并上传软件包到PyPI。经过一些检查后,它就可供任何人安装了。\n\n\n\n\n\n\n附注\n\n\n\n对于在本地Python环境中工作的用户,你可以在终端中使用pip安装cowsay:\npip install cowsay\n\n\n安装后,我们现在可以导入并使用cowsay库:\n\nimport cowsay\n\n# Make the cow say something\ncowsay.cow('Moo!')\n\n  ____\n| Moo! |\n  ====\n    \\\n     \\\n       ^__^\n       (oo)\\_______\n       (__)\\       )\\/\\\n           ||----w |\n           ||     ||\n\n\n这将显示一只说”Moo!“的ASCII艺术牛。\n\n\n\n\n\n\n练习\n\n\n\n4.7.1 问题:使用emoji库\n\n安装emoji库。\n导入emoji库。\n查阅emoji库中emojize()函数的帮助。\n使用emojize()函数显示“点赞”表情。\n\n\n# Your code here",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_functions_methods_cn.html#总结",
    "href": "p_foundations_functions_methods_cn.html#总结",
    "title": "4  Python中的函数、方法和库",
    "section": "4.8 总结",
    "text": "4.8 总结\n在本课中,我们涵盖了:\n\nPython中的函数和方法\n参数及其使用方法\n导入和使用库\n安装和使用外部库\n\n这些概念是Python编程的基础,并将在你继续提升技能的过程中广泛使用。练习使用不同的函数、方法和库,以更熟练掌握这些概念。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python中的函数、方法和库</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html",
    "href": "p_foundations_data_structures_cn.html",
    "title": "5  Python中的数据结构",
    "section": "",
    "text": "5.1 介绍\n到目前为止,在我们的Python探索中,我们一直在处理简单的、单一的值,如数字和字符串。但是,正如你所知,数据通常以更大的结构形式出现。你最熟悉的结构是带有行和列的表格。\n在本课程中,我们将探索在Python中组织数据的构建块,从列表、字典、Series,最后到表格,或者更正式地说,是数据框(DataFrames)。\n让我们开始吧!",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#学习目标",
    "href": "p_foundations_data_structures_cn.html#学习目标",
    "title": "5  Python中的数据结构",
    "section": "5.2 学习目标",
    "text": "5.2 学习目标\n\n创建和使用Python列表和字典\n理解和使用Pandas Series\n探索Pandas DataFrame用于组织结构化数据",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#导入",
    "href": "p_foundations_data_structures_cn.html#导入",
    "title": "5  Python中的数据结构",
    "section": "5.3 导入",
    "text": "5.3 导入\n我们需要在本课程中使用pandas。你可以这样导入它:\n\nimport pandas as pd\n\n如果你收到错误,可能需要安装它。你可以在单元格中运行 !pip install pandas 来安装。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#python-列表",
    "href": "p_foundations_data_structures_cn.html#python-列表",
    "title": "5  Python中的数据结构",
    "section": "5.4 Python 列表",
    "text": "5.4 Python 列表\n列表就像有序的容器,可以存放不同类型的信息。例如,你可能有一个购物清单:\n\nshopping = [\"apples\", \"bananas\", \"milk\", \"bread\"] \nshopping\n\n['apples', 'bananas', 'milk', 'bread']\n\n\n在Python中,我们使用所谓的“零基索引”来访问列表中的项。这意味着我们从0而不是1开始计数位置。\n让我们看一些例子:\n\nprint(shopping[0])  # 第一个项目(记住,我们从0开始!)\nprint(shopping[1])  # 第二个项目\nprint(shopping[2])  # 第三个项目\n\napples\nbananas\nmilk\n\n\n乍一看可能觉得奇怪,但这是许多编程语言中的常见做法。这与计算机如何存储信息以及编写算法的便利性有关。\n我们可以在创建列表后更改其内容,使用相同的索引系统。\n\nshopping[1] = \"oranges\"  # 替换第二个项目(索引为1)\nshopping\n\n['apples', 'oranges', 'milk', 'bread']\n\n\n列表有许多可用的方法。例如,我们可以使用 append() 方法向列表添加元素。\n\nshopping.append(\"eggs\")\nshopping\n\n['apples', 'oranges', 'milk', 'bread', 'eggs']\n\n\n在你Python数据之旅的初期阶段,你可能不会经常使用列表,所以我们将简要介绍。\n\n\n\n\n\n\n练习\n\n\n\n5.4.1 练习:使用列表\n\n创建一个名为 temps 的列表,包含这些值:1,2,3,4\n打印列表的第一个元素\n将最后一个元素改为6\n\n\n# 在此编写你的代码",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#python-字典",
    "href": "p_foundations_data_structures_cn.html#python-字典",
    "title": "5  Python中的数据结构",
    "section": "5.5 Python 字典",
    "text": "5.5 Python 字典\n字典就像带标签的存储箱,用于存放你的数据。每个数据(值)都有一个唯一的标签(键)。下面,我们有一个一些学生的成绩字典。\n\ngrades = {\"Alice\": 90, \"Bob\": 85, \"Charlie\": 92}\ngrades\n\n{'Alice': 90, 'Bob': 85, 'Charlie': 92}\n\n\n如你所见,字典使用大括号 {} 定义,键和值之间用冒号 : 分隔,键值对之间用逗号分隔。\n我们使用键来获取关联的值。\n\ngrades[\"Bob\"]\n\n85\n\n\n\n5.5.1 添加/修改条目\n我们可以轻松地在字典中添加新信息或更改现有数据。\n\ngrades[\"David\"] = 88  # 添加一个新学生\ngrades\n\n{'Alice': 90, 'Bob': 85, 'Charlie': 92, 'David': 88}\n\n\n\ngrades[\"Alice\"] = 95  # 更新Alice的成绩\ngrades\n\n{'Alice': 95, 'Bob': 85, 'Charlie': 92, 'David': 88}\n\n\n\n\n\n\n\n\n练习\n\n\n\n5.5.2 练习:使用字典\n\n创建一个名为 prices 的字典,包含以下键值对:“apple”: 0.50, “banana”: 0.25, “orange”: 0.75\n使用键打印橙子的价格\n添加一个新水果 “grape”,价格为1.5\n将 “banana” 的价格改为0.30\n\n\n# 在此编写你的代码",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#pandas-series",
    "href": "p_foundations_data_structures_cn.html#pandas-series",
    "title": "5  Python中的数据结构",
    "section": "5.6 Pandas Series",
    "text": "5.6 Pandas Series\nPandas 提供了一种名为 Series 的数据结构,类似于列表,但具有一些特别适用于数据分析的附加功能。\n让我们创建一个简单的Series:\n\ntemps = pd.Series([1, 2, 3, 4, 5])\ntemps\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\n\n\n我们可以使用内置的Series方法来计算摘要统计。\n\ntemps.mean()\ntemps.median()\ntemps.std()\n\nnp.float64(1.5811388300841898)\n\n\nSeries 的一个重要特性是它们可以有自定义索引,以便直观访问。\n\ntemps_labeled = pd.Series([1, 2, 3, 4], index=['Mon', 'Tue', 'Wed', 'Thu'])\ntemps_labeled\ntemps_labeled['Wed']\n\nnp.int64(3)\n\n\n这使它们类似于字典。\n\n\n\n\n\n\n练习\n\n\n\n5.6.1 练习:使用 Series\n\n创建一个名为 rain 的Series,包含这些值:5, 4, 3, 2\n获取平均降雨量和中位数降雨量\n\n\n# 在此编写你的代码",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#pandas-dataframe",
    "href": "p_foundations_data_structures_cn.html#pandas-dataframe",
    "title": "5  Python中的数据结构",
    "section": "5.7 Pandas DataFrame",
    "text": "5.7 Pandas DataFrame\n接下来,让我们考虑Pandas DataFrame,它们类似于Series,但有两维——想象一下电子表格或数据库表。\n这是数据分析中最重要的数据结构。\nDataFrame像是Python中的电子表格。它有行和列,非常适合组织结构化数据。\n大多数时候,你将导入外部数据框,但你也应该知道如何在Python中从头创建数据框。\n首先让我们创建三个列表:\n\n# 创建三个列表\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\nages = [25, 30, 28]\ncities = [\"Lagos\", \"London\", \"Lima\"]\n\n然后我们将它们组合成一个字典,最后转换为一个数据框。\n\ndata = {'name': names,\n        'age': ages,\n        'city': cities}\n\npeople_df = pd.DataFrame(data)\npeople_df\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\n0\nAlice\n25\nLagos\n\n\n1\nBob\n30\nLondon\n\n\n2\nCharlie\n28\nLima\n\n\n\n\n\n\n\n注意,我们本可以在没有中间Series的情况下创建数据框:\n\npeople_df = pd.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"age\": [25, 30, 28],\n        \"city\": [\"Lagos\", \"London\", \"Lima\"],\n    }\n)\npeople_df\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\n0\nAlice\n25\nLagos\n\n\n1\nBob\n30\nLondon\n\n\n2\nCharlie\n28\nLima\n\n\n\n\n\n\n\n我们可以从DataFrame中选择特定的列或行。\n\npeople_df[\"city\"]  # 选择一列。注意这会返回一个Series。\npeople_df.loc[0]  # 按标签选择一行。这也会返回一个Series。\n\nname    Alice\nage        25\ncity    Lagos\nName: 0, dtype: object\n\n\n我们可以对数据框调用方法。\n\npeople_df.describe() # 这是数值列的摘要\npeople_df.info() # 这是数据类型的摘要\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   name    3 non-null      object\n 1   age     3 non-null      int64 \n 2   city    3 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 204.0+ bytes\n\n\n我们还可以对从选择列结果的Series对象调用方法。\n例如,我们可以获取“city”列的摘要统计。\n\npeople_df[\"city\"].describe()  # 这是“city”列的摘要\npeople_df[\"age\"].mean()  # 这是“age”列的平均值\n\nnp.float64(27.666666666666668)\n\n\n在未来的一系列课程中,我们将深入探讨切片和操作DataFrame。本课程的目标只是让你熟悉基本语法和概念。\n\n\n\n\n\n\n练习\n\n\n\n5.7.1 练习:使用 DataFrame\n\n创建一个名为 students 的DataFrame,包含以下信息:\n\n列:“Name”, “Age”, “Grade”\nAlice的成绩是90,Bob的成绩是85,Charlie的成绩是70。你自行选择年龄。\n\n仅显示“Grade”列\n计算并显示学生的平均年龄\n显示Bob的那一行。\n\n\n# 在此编写你的代码",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_data_structures_cn.html#总结",
    "href": "p_foundations_data_structures_cn.html#总结",
    "title": "5  Python中的数据结构",
    "section": "5.8 总结",
    "text": "5.8 总结\n我们已经探索了Python数据分析的主要数据结构。从基本的列表和字典到Pandas Series和DataFrame,这些工具对于组织和分析数据至关重要。它们将是未来课程中更高级数据工作的基础。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python中的数据结构</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html",
    "href": "p_foundations_for_loops_cn.html",
    "title": "6  Python中的循环简介",
    "section": "",
    "text": "6.1 简介\n编程的核心概念是重复执行任务多次。for 循环是实现这一目标的基本方法之一。循环能够高效地重复操作,节省时间和精力。\n掌握这一概念对于编写智能的 Python 代码至关重要。\n让我们深入学习,提升您的编码技能!",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html#学习目标",
    "href": "p_foundations_for_loops_cn.html#学习目标",
    "title": "6  Python中的循环简介",
    "section": "6.2 学习目标",
    "text": "6.2 学习目标\n在本课程结束时,您将能够:\n\n使用 Python 中的基本 for 循环\n使用索引变量在循环中遍历列表\n在循环中使用 f-字符串格式化输出\n应用循环生成多个数据可视化图表",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html#包",
    "href": "p_foundations_for_loops_cn.html#包",
    "title": "6  Python中的循环简介",
    "section": "6.3 包",
    "text": "6.3 包\n在本课程中,我们将使用以下 Python 库:\n\nimport pandas as pd\nimport plotly.express as px\nfrom vega_datasets import data",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html#for-循环简介",
    "href": "p_foundations_for_loops_cn.html#for-循环简介",
    "title": "6  Python中的循环简介",
    "section": "6.4 for 循环简介",
    "text": "6.4 for 循环简介\n让我们从一个简单的例子开始。假设我们有一个儿童年龄(以年为单位)的列表,我们想要将其转换为月份:\n\nages = [7, 8, 9]  # List of ages in years\n\n我们可以尝试直接将列表乘以 12:\n\nages * 12\n\n[7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9,\n 7,\n 8,\n 9]\n\n\n但这并不能达到我们的目的。它只是将列表重复了 12 次。\n相反,我们需要遍历列表中的每个元素,并将其乘以 12:\n\nfor age in ages:\n    print(age * 12)\n\n84\n96\n108\n\n\nfor 和 in 是循环中必需的关键字。冒号以及第二行的缩进也是必需的。\n在这个循环中,age 是一个临时变量,在每次迭代时取 ages 列表中每个元素的值。首先,age 是 7,然后是 8,接着是 9。\n您可以为这个变量选择任何名称:\n\nfor random_name in ages:\n    print(random_name * 12)\n\n84\n96\n108\n\n\n请注意,我们需要使用 print 语句,因为循环不会自动打印结果:\n\nfor age in ages:\n    age * 12\n\n\n\n\n\n\n\n练习\n\n\n\n6.4.1 小时转分钟基础循环\n尝试使用 for 循环将小时转换为分钟。首先,从以下小时列表开始:\n\nhours = [3, 4, 5]  # List of hours\n# Your code here",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html#使用-f-字符串进行打印",
    "href": "p_foundations_for_loops_cn.html#使用-f-字符串进行打印",
    "title": "6  Python中的循环简介",
    "section": "6.5 使用 f-字符串进行打印",
    "text": "6.5 使用 f-字符串进行打印\n我们可能想要同时打印结果和原始年龄。我们可以通过使用 + 运算符连接字符串来实现。但我们需要使用 str() 将年龄转换为字符串。\n\nfor age in ages:\n    print(str(age) + \" years is \" + str(age * 12) + \" months\" )\n\n7 years is 84 months\n8 years is 96 months\n9 years is 108 months\n\n\n或者,我们可以使用一种称为 f-字符串的字符串。这种字符串允许我们直接嵌入变量。\n\nfor age in ages:\n    print(f\"{age} years is {age * 12} months\")\n\n7 years is 84 months\n8 years is 96 months\n9 years is 108 months\n\n\n在 f-字符串中,我们使用大括号 {} 来嵌入变量。\n\n\n\n\n\n\n练习\n\n\n\n6.5.1 练习:F-字符串\n再次将下面的小时列表转换为分钟。使用 f-字符串同时打印原始小时数和转换后的分钟数。\n\nhours = [3, 4, 5]  # List of hours\n# Your code here\n# Example output \"3 hours is 180 minutes\"",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html#for-循环在-python-中有用吗",
    "href": "p_foundations_for_loops_cn.html#for-循环在-python-中有用吗",
    "title": "6  Python中的循环简介",
    "section": "6.6 for 循环在 Python 中有用吗?",
    "text": "6.6 for 循环在 Python 中有用吗?\n虽然 for 循环很有用,但在许多情况下,有更高效的方法对数据集合执行操作。\n例如,我们最初的年龄转换可以使用 pandas Series 实现:\n\nimport pandas as pd\n\nages = pd.Series([7, 8, 9])\nmonths = ages * 12\nprint(months)\n\n0     84\n1     96\n2    108\ndtype: int64\n\n\n但尽管像 pandas 这样的库提供了强大的数据处理方式,for 循环对于那些无法轻易向量化的任务或当您需要对迭代过程进行精细控制时仍然是必不可少的。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_for_loops_cn.html#使用索引和值进行循环",
    "href": "p_foundations_for_loops_cn.html#使用索引和值进行循环",
    "title": "6  Python中的循环简介",
    "section": "6.7 使用索引和值进行循环",
    "text": "6.7 使用索引和值进行循环\n有时,我们希望同时访问列表中项的位置(索引)和值。enumerate() 函数可以帮助我们轻松实现这一点。\n让我们再次看一下 ages 列表:\n\nages = [7, 8, 9]  # List of ages in years\n\n首先,让我们看看 enumerate() 实际上做了什么:\n\nfor item in enumerate(ages):\n    print(item)\n\n(0, 7)\n(1, 8)\n(2, 9)\n\n\n如您所见,enumerate() 会给我们 (索引, 值) 的对。\n我们可以在 for 循环中直接展开这些对:\n\nfor i, age in enumerate(ages):\n    print(f\"The person at index {i} is aged {age}\")\n\nThe person at index 0 is aged 7\nThe person at index 1 is aged 8\nThe person at index 2 is aged 9\n\n\n这里,i 是索引,而 age 是该索引处的值。\n现在,让我们使用索引和值创建更详细的输出:\n\nfor i, age in enumerate(ages):\n    print(f\"The person at index {i} is aged {age} years which is {age * 12} months\")\n\nThe person at index 0 is aged 7 years which is 84 months\nThe person at index 1 is aged 8 years which is 96 months\nThe person at index 2 is aged 9 years which is 108 months\n\n\n当您在循环中需要同时获取位置和对应值时,这尤其有用。\n\n\n\n\n\n\n练习\n\n\n\n6.7.1 练习:使用 enumerate() 和 F-字符串\n使用 enumerate() 和 f-字符串为列表中的每个小时打印一句话:\n\nhours = [3, 4, 5]  # List of hours\n\n# Your code here\n# Example output: \"Hour 3 at index 0 is equal to 180 minutes\"",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Python中的循环简介</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html",
    "href": "p_foundations_writing_functions_cn.html",
    "title": "7  函数与条件语句入门",
    "section": "",
    "text": "7.1 简介\n到目前为止,在本课程中你主要使用了别人编写的函数。在本课中,你将学习如何在 Python 中编写自己的函数。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html#学习目标",
    "href": "p_foundations_writing_functions_cn.html#学习目标",
    "title": "7  函数与条件语句入门",
    "section": "7.2 学习目标",
    "text": "7.2 学习目标\n在本课结束时,你将能够:\n\n在 Python 中创建和使用自己的函数。\n设计函数参数并设置默认值。\n在函数中使用条件逻辑,如 if、elif 和 else。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html#包",
    "href": "p_foundations_writing_functions_cn.html#包",
    "title": "7  函数与条件语句入门",
    "section": "7.3 包",
    "text": "7.3 包\n运行以下代码以安装并加载本课所需的包:\n\n# Import packages\nimport pandas as pd\nimport numpy as np\nimport vega_datasets as vd",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html#函数基础",
    "href": "p_foundations_writing_functions_cn.html#函数基础",
    "title": "7  函数与条件语句入门",
    "section": "7.4 函数基础",
    "text": "7.4 函数基础\n让我们从创建一个非常简单的函数开始。考虑以下将磅(重量单位)转换为公斤(另一个重量单位)的函数:\n\ndef pounds_to_kg(pounds):\n    return pounds * 0.4536\n\n如果你执行这段代码,你将创建一个名为 pounds_to_kg 的函数,可以在脚本或控制台中直接使用:\n\nprint(pounds_to_kg(150))\n\n68.04\n\n\n让我们一步步解析这个简单函数的结构。\n首先,使用 def 关键字创建一个函数,后跟一对括号和一个冒号。\n\ndef function_name():\n    # Function body\n\n在括号内,我们指明函数的参数。我们的函数只接受一个参数,我们将其命名为 pounds。这是我们想要从磅转换为公斤的值。\n\ndef pounds_to_kg(pounds):\n    # Function body\n\n当然,我们可以将这个参数命名为任意名称,例如 p 或 weight。\n冒号之后的下一个元素是函数的主体。这是我们编写希望在调用函数时执行的代码的地方。\n\ndef pounds_to_kg(pounds):\n    return pounds * 0.4536\n\n我们使用 return 语句指定函数应输出的值。\n你也可以将结果赋给一个变量,然后返回该变量:\n\ndef pounds_to_kg(pounds):\n    kg = pounds * 0.4536\n    return kg\n\n这虽然有点冗长,但使函数更清晰。\n现在我们可以使用命名参数这样调用我们的函数:\n\npounds_to_kg(pounds=150)\n\n68.04\n\n\n或者不使用命名参数:\n\npounds_to_kg(150)\n\n68.04\n\n\n要在 DataFrame 中使用它,可以创建一个新列:\n\npounds_df = pd.DataFrame({'pounds': [150, 200, 250]})\npounds_df['kg'] = pounds_to_kg(pounds_df['pounds'])\npounds_df\n\n\n\n\n\n\n\n\npounds\nkg\n\n\n\n\n0\n150\n68.04\n\n\n1\n200\n90.72\n\n\n2\n250\n113.40\n\n\n\n\n\n\n\n就是这样!你刚刚在 Python 中创建并使用了第一个函数。\n\n\n\n\n\n\n练习\n\n\n\n7.4.1 月龄转换函数\n创建一个名为 years_to_months 的简单函数,将年龄从年转换为月。\n在下面导入的 riots_df DataFrame 上使用它,创建一个名为 age_months 的新列:\n\nriots_df = vd.data.la_riots()\nriots_df \n\n\n\n\n\n\n\n\nfirst_name\nlast_name\nage\ngender\nrace\ndeath_date\naddress\nneighborhood\ntype\nlongitude\nlatitude\n\n\n\n\n0\nCesar A.\nAguilar\n18.0\nMale\nLatino\n1992-04-30\n2009 W. 6th St.\nWestlake\nOfficer-involved shooting\n-118.273976\n34.059281\n\n\n1\nGeorge\nAlvarez\n42.0\nMale\nLatino\n1992-05-01\nMain & College streets\nChinatown\nNot riot-related\n-118.234098\n34.062690\n\n\n2\nWilson\nAlvarez\n40.0\nMale\nLatino\n1992-05-23\n3100 Rosecrans Ave.\nHawthorne\nHomicide\n-118.326816\n33.901662\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n60\nElbert O.\nWilkins\n33.0\nMale\nBlack\n1992-04-30\nWestern Avenue & 92nd Street\nGramercy Park\nHomicide\n-118.310004\n33.952767\n\n\n61\nJohn H.\nWillers\n37.0\nMale\nWhite\n1992-04-29\n10621 Sepulveda Blvd.\nMission Hills\nHomicide\n-118.467770\n34.263184\n\n\n62\nWillie Bernard\nWilliams\n29.0\nMale\nBlack\n1992-04-29\nGage & Western avenues\nChesterfield Square\nDeath\n-118.308952\n33.982363\n\n\n\n\n63 rows × 11 columns",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html#多参数函数",
    "href": "p_foundations_writing_functions_cn.html#多参数函数",
    "title": "7  函数与条件语句入门",
    "section": "7.5 多参数函数",
    "text": "7.5 多参数函数\n大多数函数接受多个参数而不仅仅是一个。让我们看一个接受三个参数的函数示例:\n\ndef calc_calories(carb_grams, protein_grams, fat_grams):\n    result = (carb_grams * 4) + (protein_grams * 4) + (fat_grams * 9)\n    return result\n\ncalc_calories(carb_grams=50, protein_grams=25, fat_grams=10)\n\n390\n\n\ncalc_calories 函数根据碳水化合物、蛋白质和脂肪的克数计算总卡路里。碳水化合物和蛋白质估计为每克 4 卡路里,而脂肪估计为每克 9 卡路里。\n如果试图在不提供所有参数的情况下使用该函数,将会产生错误。\n\ncalc_calories(carb_grams=50, protein_grams=25)\n\nTypeError: calc_calories() missing 1 required positional argument: 'fat_grams'\n你可以为函数的参数定义默认值。如果调用时未赋值,则该参数将采用默认值。让我们通过为所有参数赋予默认值,使所有参数都变为可选:\n\ndef calc_calories(carb_grams=0, protein_grams=0, fat_grams=0):\n    result = (carb_grams * 4) + (protein_grams * 4) + (fat_grams * 9)\n    return result\n\n现在,我们可以只用部分参数调用函数而不会出错:\n\ncalc_calories(carb_grams=50, protein_grams=25)\n\n300\n\n\n让我们在一个示例数据集上使用它:\n\nfood_df = pd.DataFrame({\n    'food': ['Apple', 'Avocado'],\n    'carb_grams': [25, 10],\n    'protein_grams': [0, 1],\n    'fat_grams': [0, 14]\n})\nfood_df['calories'] = calc_calories(food_df['carb_grams'], food_df['protein_grams'], food_df['fat_grams'])\nfood_df\n\n\n\n\n\n\n\n\nfood\ncarb_grams\nprotein_grams\nfat_grams\ncalories\n\n\n\n\n0\nApple\n25\n0\n0\n100\n\n\n1\nAvocado\n10\n1\n14\n170\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n7.5.1 BMI 计算函数\n创建一个名为 calc_bmi 的函数,计算一个或多个人的身体质量指数(BMI),然后通过运行下面的代码块应用该函数。BMI 公式为体重(kg)除以身高(m)的平方。\n\n# Your code here\n\n\nbmi_df = pd.DataFrame({\n    'Weight': [70, 80, 100],  # in kg\n    'Height': [1.7, 1.8, 1.2]  # in meters\n})\nbmi_df['BMI'] = calc_bmi(bmi_df['Weight'], bmi_df['Height'])\nbmi_df",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html#条件语句简介ifelif-和-else",
    "href": "p_foundations_writing_functions_cn.html#条件语句简介ifelif-和-else",
    "title": "7  函数与条件语句入门",
    "section": "7.6 条件语句简介:if、elif 和 else",
    "text": "7.6 条件语句简介:if、elif 和 else\n条件语句允许你仅在满足某些条件时执行代码。Python 中的基本语法是:\n\nif condition:\n    # Code to execute if condition is True\nelif another_condition:\n    # Code to execute if the previous condition was False and this condition is True\nelse:\n    # Code to execute if all previous conditions were False\n\n让我们看一个在函数中使用条件语句的示例。假设我们想编写一个函数,将数字分类为正数、负数或零。\n\ndef class_num(num):\n    if num &gt; 0:\n        return \"Positive\"\n    elif num &lt; 0:\n        return \"Negative\"\n    else:\n        return \"Zero\"\n\nprint(class_num(10))    # Output: Positive\nprint(class_num(-5))    # Output: Negative\nprint(class_num(0))     # Output: Zero\n\nPositive\nNegative\nZero\n\n\n如果你像上面对 BMI 函数那样使用这个函数,将会得到一个错误:\n\nnum_df = pd.DataFrame({'num': [10, -5, 0]})\nnum_df\n\n\n\n\n\n\n\n\nnum\n\n\n\n\n0\n10\n\n\n1\n-5\n\n\n2\n0\n\n\n\n\n\n\n\n\nnum_df['category'] = class_num(num_df['num'])\n\nValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n原因是 if 语句并不是为处理系列(它们不是固有的向量化)的,而是处理单个值。为了解决这个问题,我们可以使用 np.vectorize 函数创建函数的向量化版本:\n\nclass_num_vec = np.vectorize(class_num)\nnum_df['category'] = class_num_vec(num_df['num'])\nnum_df\n\n\n\n\n\n\n\n\nnum\ncategory\n\n\n\n\n0\n10\nPositive\n\n\n1\n-5\nNegative\n\n\n2\n0\nZero\n\n\n\n\n\n\n\n为了更多地练习条件语句,让我们编写一个将成绩分类为简单类别的函数:\n\n如果成绩为 85 或以上,类别为 ‘优秀’。\n如果成绩在 60 到 84 之间,类别为 ‘及格’。\n如果成绩低于 60,类别为 ‘不及格’。\n如果成绩为负或无效,返回 ‘无效成绩’。\n\n\ndef categorize_grade(grade):\n    if grade &gt;= 85 and grade &lt;= 100:\n        return 'Excellent'\n    elif grade &gt;= 60 and grade &lt; 85:\n        return 'Pass'\n    elif grade &gt;= 0 and grade &lt; 60:\n        return 'Fail'\n    else:\n        return 'Invalid grade'\n\ncategorize_grade(95)  # Output: Excellent\n\n'Excellent'\n\n\n我们可以将此函数应用于 DataFrame 中的一列,但首先需要将其向量化:\n\ncategorize_grade = np.vectorize(categorize_grade)\n\n\ngrades_df = pd.DataFrame({'grade': [95, 82, 76, 65, 58, -5]})\ngrades_df['grade_cat'] = categorize_grade(grades_df['grade'])\ngrades_df\n\n\n\n\n\n\n\n\ngrade\ngrade_cat\n\n\n\n\n0\n95\nExcellent\n\n\n1\n82\nPass\n\n\n2\n76\nPass\n\n\n3\n65\nPass\n\n\n4\n58\nFail\n\n\n5\n-5\nInvalid grade\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n7.6.1 年龄分类函数\n现在,尝试编写一个将年龄分类为不同生命阶段的函数,使用以下标准:\n\n如果年龄小于 18 岁,类别为 ‘未成年人’。\n如果年龄大于或等于 18 岁且小于 65 岁,类别为 ‘成年人’。\n如果年龄大于或等于 65 岁,类别为 ‘老年人’。\n如果年龄为负或无效,返回 ‘无效年龄’。\n\n在下面打印的 riots_df DataFrame 上使用它,创建一个名为 Age_Category 的新列。\n\n# Your code here\n\nriots_df = vd.data.la_riots()\nriots_df\n\n\n\n\n\n\n\n\nfirst_name\nlast_name\nage\ngender\nrace\ndeath_date\naddress\nneighborhood\ntype\nlongitude\nlatitude\n\n\n\n\n0\nCesar A.\nAguilar\n18.0\nMale\nLatino\n1992-04-30\n2009 W. 6th St.\nWestlake\nOfficer-involved shooting\n-118.273976\n34.059281\n\n\n1\nGeorge\nAlvarez\n42.0\nMale\nLatino\n1992-05-01\nMain & College streets\nChinatown\nNot riot-related\n-118.234098\n34.062690\n\n\n2\nWilson\nAlvarez\n40.0\nMale\nLatino\n1992-05-23\n3100 Rosecrans Ave.\nHawthorne\nHomicide\n-118.326816\n33.901662\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n60\nElbert O.\nWilkins\n33.0\nMale\nBlack\n1992-04-30\nWestern Avenue & 92nd Street\nGramercy Park\nHomicide\n-118.310004\n33.952767\n\n\n61\nJohn H.\nWillers\n37.0\nMale\nWhite\n1992-04-29\n10621 Sepulveda Blvd.\nMission Hills\nHomicide\n-118.467770\n34.263184\n\n\n62\nWillie Bernard\nWilliams\n29.0\nMale\nBlack\n1992-04-29\nGage & Western avenues\nChesterfield Square\nDeath\n-118.308952\n33.982363\n\n\n\n\n63 rows × 11 columns\n\n\n\n\n\n\n\n\n\n\n\n附注\n\n\n\n7.6.2 Apply 与 Vectorize\n在 DataFrame 上使用带有 if 语句的函数的另一种方法是使用 apply 方法。以下是如何使用 apply 实现成绩分类函数:\n\ngrades_df['grade_cat'] = grades_df['grade'].apply(categorize_grade)\ngrades_df\n\n\n\n\n\n\n\n\ngrade\ngrade_cat\n\n\n\n\n0\n95\nExcellent\n\n\n1\n82\nPass\n\n\n2\n76\nPass\n\n\n3\n65\nPass\n\n\n4\n58\nFail\n\n\n5\n-5\nInvalid grade\n\n\n\n\n\n\n\nvectorize 方法在处理多个参数时更容易使用,但你将在后续学习中接触到 apply 方法。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_foundations_writing_functions_cn.html#结论",
    "href": "p_foundations_writing_functions_cn.html#结论",
    "title": "7  函数与条件语句入门",
    "section": "7.7 结论",
    "text": "7.7 结论\n在本课中,我们介绍了在 Python 中编写函数的基础知识以及如何在这些函数中使用条件语句。函数是编程中必不可少的构建模块,允许你封装代码以便重用和更好的组织。条件语句使你的函数能够根据输入值或其他条件做出决策。",
    "crumbs": [
      "基础知识",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>函数与条件语句入门</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html",
    "href": "p_data_on_display_data_viz_types_cn.html",
    "title": "8  数据可视化类型",
    "section": "",
    "text": "8.1 幻灯片\n您可以查看下面的幻灯片,这些幻灯片用于录制视频。或者,您可以直接跳到以下部分,这些部分详细介绍了每种可视化类型。",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#引言",
    "href": "p_data_on_display_data_viz_types_cn.html#引言",
    "title": "8  数据可视化类型",
    "section": "8.2 引言",
    "text": "8.2 引言\n在数据可视化中,通常有三个主要步骤:\n\n整理和清理您的数据。\n\n选择适合您的问题的可视化类型。\n\n编写代码来实现该可视化。\n\n在本课程中,我们重点关注第2步:了解哪种类型的图表最适合特定类型的问题。我们将查看Plotly内置的tips数据集中的示例,探索:\n\n单变量(单一变量)数值数据\n\n单变量(单一变量)分类数据\n\n双变量数值 vs 数值\n\n双变量数值 vs 分类\n\n双变量分类 vs 分类\n\n时间序列\n\n然后,我们将使用另一个数据集(gapminder)进行练习,以强化如何为您的数据和问题选择有效的图表。",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#设置",
    "href": "p_data_on_display_data_viz_types_cn.html#设置",
    "title": "8  数据可视化类型",
    "section": "8.3 设置",
    "text": "8.3 设置\n运行以下代码以设置绘图环境并加载Plotly Express中的tips数据集。\n\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np\nimport plotly.io as pio\n\ntips = px.data.tips()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#单变量数值",
    "href": "p_data_on_display_data_viz_types_cn.html#单变量数值",
    "title": "8  数据可视化类型",
    "section": "9.1 1.1 单变量数值",
    "text": "9.1 1.1 单变量数值\n问题形式: &gt; 一个数值变量的分布是什么?\n&gt; 它的范围是多少?中位数是多少?大多数值位于哪里?\n可能的可视化包括:\n\n直方图 – 有助于查看值的整体分布。\n\n箱线图 – 突出显示中位数、四分位数和异常值。\n\n小提琴图 – 结合了箱线图和“平滑”直方图(密度)形状。\n\n条带/抖动图 – 显示每个单独的点,略微“抖动”以避免重叠。\n\n\n9.1.1 直方图\n\nfig_hist = px.histogram(tips, x='tip')\nfig_hist.show()\n\n                                                \n\n\n\n\n9.1.2 箱线图\n\nfig_box = px.box(tips, x='tip')\nfig_box.show()\n\n                                                \n\n\n\n\n9.1.3 小提琴图(带箱线图和点)\n\nfig_violin = px.violin(tips, x='tip', box=True, points='all')\nfig_violin.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#单变量分类",
    "href": "p_data_on_display_data_viz_types_cn.html#单变量分类",
    "title": "8  数据可视化类型",
    "section": "9.2 1.2 单变量分类",
    "text": "9.2 1.2 单变量分类\n问题形式: &gt; 每个类别有多少观测值?\n&gt; 以tips数据集为例,每个性别有多少观测值?\n可能的可视化包括:\n\n条形图 – 通常统计每个类别中的行数。\n\n饼图 – 如果类别较少并且想要突出比例,可以使用。\n\n\n9.2.1 条形图\n\nfig_bar_cat = px.histogram(tips, x='sex', color='sex', color_discrete_sequence=['#deb221', '#2f828a'])\nfig_bar_cat.update_layout(showlegend=False)\nfig_bar_cat.show()\n\n                                                \n\n\n\n\n9.2.2 饼图\n\nfig_pie_cat = px.pie(tips, names='sex', color='sex', values='tip',\n                     color_discrete_sequence=['#deb221', '#2f828a'])\nfig_pie_cat.update_layout(showlegend=False)\nfig_pie_cat.update_traces(textposition='none')\nfig_pie_cat.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#数值-vs-数值",
    "href": "p_data_on_display_data_viz_types_cn.html#数值-vs-数值",
    "title": "8  数据可视化类型",
    "section": "10.1 2.1 数值 vs 数值",
    "text": "10.1 2.1 数值 vs 数值\n典型问题: &gt; 两个数值变量是否相关?\n&gt; 以tips数据集为例,总账单与小费是否相关?\n散点图通常是首选。\n\nfig_scatter = px.scatter(tips, x='total_bill', y='tip')\nfig_scatter.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#数值-vs-分类",
    "href": "p_data_on_display_data_viz_types_cn.html#数值-vs-分类",
    "title": "8  数据可视化类型",
    "section": "10.2 2.2 数值 vs 分类",
    "text": "10.2 2.2 数值 vs 分类\n典型问题: &gt; 哪个组的平均值更高?\n&gt; 以tips数据集为例,男性还是女性的小费更多?\n可视化选项:\n\n分组直方图 – 每个类别的单独直方图(通常叠加)。\n\n分组箱线图/小提琴图/条带图 – 每个类别一个分布图。\n\n摘要条形图 – 显示每个类别的平均值(或中位数),可选带误差条。\n\n\n10.2.1 分组直方图\n\nfig_grouped_hist = px.histogram(tips, x='tip', color='sex', barmode='overlay',\n                                color_discrete_sequence=['#deb221', '#2f828a'])\nfig_grouped_hist.show()\n\n                                                \n\n\n\n\n10.2.2 分组小提琴图/箱线图/条带图\n\nfig_grouped_violin = px.violin(tips, y='sex', x='tip', color='sex',\n                               box=True, points='all',\n                               color_discrete_sequence=['#deb221', '#2f828a'])\nfig_grouped_violin.update_layout(showlegend=False)\nfig_grouped_violin.show()\n\n                                                \n\n\n\n\n10.2.3 摘要条形图(均值 + 标准差)\n\nsummary_df = tips.groupby('sex').agg({'tip': ['mean', 'std']}).reset_index()\nsummary_df.columns = ['sex', 'mean_tip', 'std_tip']\n\nfig_mean_bar = px.bar(\n    summary_df,\n    y='sex',\n    x='mean_tip',\n    error_x='std_tip',\n    color='sex',\n    color_discrete_sequence=['#deb221', '#2f828a'],\n)\nfig_mean_bar.update_layout(showlegend=False)\nfig_mean_bar.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#分类-vs-分类",
    "href": "p_data_on_display_data_viz_types_cn.html#分类-vs-分类",
    "title": "8  数据可视化类型",
    "section": "10.3 2.3 分类 vs 分类",
    "text": "10.3 2.3 分类 vs 分类\n典型问题: &gt; 两个分类变量如何重叠?\n&gt; 以tips数据集为例,按星期几性别比例有何不同?\n可视化选项:\n\n堆积条形图 – 总计数,按类别堆叠。\n\n分组条形图 – 每个类别的条形并排显示。\n\n百分比堆积条形图 – 每个条形缩放到100%,以显示比例。\n\n\n10.3.1 分组条形图\n\nfig_grouped_bar = px.histogram(tips, x='day', color='sex', barmode='group',\n                               color_discrete_sequence=['#deb221', '#2f828a'])\nfig_grouped_bar.show()\n\n                                                \n\n\n\n\n10.3.2 堆积条形图\n\nfig_stacked_bar = px.histogram(tips, x='day', color='sex',\n                               color_discrete_sequence=['#deb221', '#2f828a'])\nfig_stacked_bar.show()\n\n                                                \n\n\n\n\n10.3.3 百分比堆积\n\nfig_percent_stacked = px.histogram(tips, x='day', color='sex',\n                                   barmode='stack', barnorm='percent',\n                                   color_discrete_sequence=['#deb221', '#2f828a'])\nfig_percent_stacked.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#人均gdp在各大洲如何变化",
    "href": "p_data_on_display_data_viz_types_cn.html#人均gdp在各大洲如何变化",
    "title": "8  数据可视化类型",
    "section": "12.1 4.1 人均GDP在各大洲如何变化?",
    "text": "12.1 4.1 人均GDP在各大洲如何变化?\n\n人均GDP = 数值\n\n洲 = 分类\n\n按洲分组的小提琴图或箱线图效果良好。\n\nfig_gdp_violin = px.violin(\n    gap_2007, \n    x=\"gdpPercap\", \n    y=\"continent\", \n    color=\"continent\", \n    box=True, \n    points=\"all\",\n    color_discrete_sequence=px.colors.qualitative.G10\n)\nfig_gdp_violin.update_layout(showlegend=False)\nfig_gdp_violin.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#一个国家的人均gdp与预期寿命之间有关系吗",
    "href": "p_data_on_display_data_viz_types_cn.html#一个国家的人均gdp与预期寿命之间有关系吗",
    "title": "8  数据可视化类型",
    "section": "12.2 4.2 一个国家的人均GDP与预期寿命之间有关系吗?",
    "text": "12.2 4.2 一个国家的人均GDP与预期寿命之间有关系吗?\n\n人均GDP = 数值\n\n预期寿命 = 数值\n\n通常选择散点图。\n\nfig_scatter_gdp_life = px.scatter(gap_2007, x='gdpPercap', y='lifeExp')\nfig_scatter_gdp_life.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#预期寿命在收入组之间如何变化",
    "href": "p_data_on_display_data_viz_types_cn.html#预期寿命在收入组之间如何变化",
    "title": "8  数据可视化类型",
    "section": "12.3 4.3 预期寿命在收入组之间如何变化?",
    "text": "12.3 4.3 预期寿命在收入组之间如何变化?\n\n预期寿命 = 数值\n\n收入组 = 分类\n\n使用分组的箱线图、小提琴图或条带图。\n\nfig_life_violin = px.violin(gap_2007, x=\"income_group\", y=\"lifeExp\", box=True, points=\"all\")\nfig_life_violin.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_data_viz_types_cn.html#洲与收入组之间的关系是什么",
    "href": "p_data_on_display_data_viz_types_cn.html#洲与收入组之间的关系是什么",
    "title": "8  数据可视化类型",
    "section": "12.4 4.4 洲与收入组之间的关系是什么?",
    "text": "12.4 4.4 洲与收入组之间的关系是什么?\n\n洲 = 分类\n\n收入组 = 分类\n\n堆积条形图或百分比堆积条形图是不错的选择。\n\nfig_continent_income = px.histogram(\n    gap_2007,\n    x='continent',\n    color='income_group',\n    barmode='stack',\n    color_discrete_sequence=['#deb221', '#2f828a']\n)\nfig_continent_income.show()",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>数据可视化类型</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_univariate_cn.html",
    "href": "p_data_on_display_univariate_cn.html",
    "title": "9  使用 Plotly Express 的单变量图表",
    "section": "",
    "text": "9.1 简介\n在本课中,您将学习如何使用 Plotly Express 创建单变量图表。单变量图表对于理解单一变量的分布至关重要,无论该变量是分类的还是定量的。\n让我们开始吧!",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>使用 Plotly Express 的单变量图表</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_univariate_cn.html#学习目标",
    "href": "p_data_on_display_univariate_cn.html#学习目标",
    "title": "9  使用 Plotly Express 的单变量图表",
    "section": "9.2 学习目标",
    "text": "9.2 学习目标\n\n使用 Plotly Express 为分类数据创建条形图、饼图和树状图\n使用 Plotly Express 为定量数据生成直方图\n自定义图表的外观和标签",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>使用 Plotly Express 的单变量图表</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_univariate_cn.html#导入",
    "href": "p_data_on_display_univariate_cn.html#导入",
    "title": "9  使用 Plotly Express 的单变量图表",
    "section": "9.3 导入",
    "text": "9.3 导入\n本课需要 plotly.express,pandas 和 vega_datasets。如果您尚未安装,请先安装。\n\nimport plotly.express as px\nimport pandas as pd\nfrom vega_datasets import data",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>使用 Plotly Express 的单变量图表</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_univariate_cn.html#定量数据",
    "href": "p_data_on_display_univariate_cn.html#定量数据",
    "title": "9  使用 Plotly Express 的单变量图表",
    "section": "9.4 定量数据",
    "text": "9.4 定量数据\n\n9.4.1 直方图\n直方图用于可视化连续变量的分布。\n让我们创建一个“tips”数据集中小费金额的直方图。\n\ntips = px.data.tips()\ntips.head() # view the first 5 rows\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\npx.histogram(tips, x='tip')\n\n                                                \n\n\n我们可以看到,最高的条形对应于小费在 1.75 到 2.24 之间,频数为 55。这意味着有 55 个小费处于 1.75 到 2.24 之间。\n\n\n\n\n\n\n旁注\n\n\n\n请注意,Plotly 图表是交互式的。您可以将鼠标悬停在条形上,以查看每个区间中小费的确切数量。\n尝试使用右上角的按钮。将图表下载为 png 的按钮特别有用。\n\n\n\n\n\n\n\n\n练习\n\n\n\n9.4.2 练习题:速度分布直方图\n按照小费直方图的示例,使用 birdstrikes 数据集创建速度分布 (Speed_IAS_in_knots) 的直方图。\n\nbirdstrikes = data.birdstrikes()\nbirdstrikes.head()\n# Your code here\n\n\n\n\n\n\n\n\nAirport__Name\nAircraft__Make_Model\nEffect__Amount_of_damage\nFlight_Date\nAircraft__Airline_Operator\nOrigin_State\nWhen__Phase_of_flight\nWildlife__Size\nWildlife__Species\nWhen__Time_of_day\nCost__Other\nCost__Repair\nCost__Total_$\nSpeed_IAS_in_knots\n\n\n\n\n0\nBARKSDALE AIR FORCE BASE ARPT\nT-38A\nNone\n1/8/90 0:00\nMILITARY\nLouisiana\nClimb\nLarge\nTurkey vulture\nDay\n0\n0\n0\n300.0\n\n\n1\nBARKSDALE AIR FORCE BASE ARPT\nKC-10A\nNone\n1/9/90 0:00\nMILITARY\nLouisiana\nApproach\nMedium\nUnknown bird or bat\nNight\n0\n0\n0\n200.0\n\n\n2\nBARKSDALE AIR FORCE BASE ARPT\nB-52\nNone\n1/11/90 0:00\nMILITARY\nLouisiana\nTake-off run\nMedium\nUnknown bird or bat\nDay\n0\n0\n0\n130.0\n\n\n3\nNEW ORLEANS INTL\nB-737-300\nSubstantial\n1/11/90 0:00\nSOUTHWEST AIRLINES\nLouisiana\nTake-off run\nSmall\nRock pigeon\nDay\n0\n0\n0\n140.0\n\n\n4\nBARKSDALE AIR FORCE BASE ARPT\nKC-10A\nNone\n1/12/90 0:00\nMILITARY\nLouisiana\nClimb\nMedium\nUnknown bird or bat\nDay\n0\n0\n0\n160.0\n\n\n\n\n\n\n\n\n\n我们可以通过在单元格中键入 px.histogram? 并运行它来查看该函数的帮助文档。\n\npx.histogram?\n\n从帮助文档中,我们可以看到 px.histogram 函数具有许多可用于自定义图表的参数。\n让我们通过添加标题、自定义 x 轴标签和更改颜色使直方图更美观一些。\n\npx.histogram(\n    tips,\n    x=\"tip\",\n    labels={\"tip\": \"Tip Amount ($)\"},\n    title=\"Distribution of Tips\", \n    color_discrete_sequence=[\"lightseagreen\"]\n)\n\n                                                \n\n\n颜色名称基于 Mozilla 的标准 CSS 颜色命名。您可以在 这里 查看完整列表。\n或者,您可以使用十六进制颜色代码,例如 #1f77b4。您可以通过使用取色器轻松获取这些颜色。请在 Google 上搜索“color picker”。\n\npx.histogram(\n    tips,\n    x=\"tip\",\n    labels={\"tip\": \"Tip Amount ($)\"},\n    title=\"Distribution of Tips\", \n    color_discrete_sequence=[\"#6a5acd\"]\n)\n\n                                                \n\n\n\n\n\n\n\n\n练习\n\n\n\n9.4.3 练习题:鸟类撞击事件直方图自定义\n更新您的 birdstrikes 直方图,使用十六进制代码颜色,添加标题,并将 x 轴标签更改为“速度(海里每小时)”。\n\n# Your code here",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>使用 Plotly Express 的单变量图表</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_univariate_cn.html#分类数据",
    "href": "p_data_on_display_univariate_cn.html#分类数据",
    "title": "9  使用 Plotly Express 的单变量图表",
    "section": "9.5 分类数据",
    "text": "9.5 分类数据\n\n9.5.1 条形图\n条形图可用于显示单个分类变量的频数。\nPlotly 有一个 px.bar 函数,我们稍后会看到。但对于单一分类变量,Plotly 要求您使用的函数实际上是 px.histogram。(世界各地的统计学家都在抱怨;直方图本应仅用于定量数据!)\n让我们创建一个基本的条形图,显示 tips 数据集中性别的分布:\n\npx.histogram(tips, x='sex')   \n\n                                                \n\n\n让我们在条形上添加计数。\n\npx.histogram(tips, x='sex', text_auto= True)\n\n                                                \n\n\n我们可以通过添加颜色轴、自定义标签和标题来增强图表。\n\npx.histogram(tips, x='sex', text_auto=True, color='sex', \n             labels={'sex': 'Gender'},\n             title='Distribution of Customers by Gender')\n\n                                                \n\n\n可以说,在这个图中,我们不需要 color 轴,因为 sex 变量已经由 x 轴表示。但公众喜欢颜色,所以仍然值得包括。\n然而,我们应该移除图例。让我们还使用自定义颜色。\n为此,我们可以首先创建一个图形对象,然后使用该对象的 .layout.update 方法来更新图例。\n\ntips_by_sex = px.histogram(\n    tips,\n    x=\"sex\",\n    text_auto=True,\n    color=\"sex\",\n    labels={\"sex\": \"Gender\"},\n    title=\"Distribution of Customers by Gender\",\n    color_discrete_sequence=[\"#1f77b4\", \"#ff7f0e\"],\n)\n\ntips_by_sex.update_layout(showlegend=False)\n\n                                                \n\n\n\n\n\n\n\n\n练习\n\n\n\n9.5.2 练习题:鸟类撞击事件按飞行阶段统计\n创建一个条形图,显示按飞行阶段 When__Phase_of_flight 的鸟类撞击事件频率。添加适当的标签和标题。使用您选择的颜色,并移除图例。\n\n# Your code here\n\n\n\n:::\n\n9.5.2.1 排序类别\n有时在条形图中为类别指定特定顺序是很有用的。\n考虑一下这张 2013 年蒙特利尔市长选举中按区划分的当选者条形图。\n\nelection = px.data.election()\nelection.head()\n\n\n\n\n\n\n\n\ndistrict\nCoderre\nBergeron\nJoly\ntotal\nwinner\nresult\ndistrict_id\n\n\n\n\n0\n101-Bois-de-Liesse\n2481\n1829\n3024\n7334\nJoly\nplurality\n101\n\n\n1\n102-Cap-Saint-Jacques\n2525\n1163\n2675\n6363\nJoly\nplurality\n102\n\n\n2\n11-Sault-au-Récollet\n3348\n2770\n2532\n8650\nCoderre\nplurality\n11\n\n\n3\n111-Mile-End\n1734\n4782\n2514\n9030\nBergeron\nmajority\n111\n\n\n4\n112-DeLorimier\n1770\n5933\n3044\n10747\nBergeron\nmajority\n112\n\n\n\n\n\n\n\n\npx.histogram(election, x='winner')\n\n                                                \n\n\n让我们为类别定义一个自定义顺序。“Bergeron” 将排在第一位,然后是 “Joly”,然后是 “Coderre”。\n\ncustom_order = [\"Bergeron\", \"Joly\", \"Coderre\"]\nelection_chart = px.histogram(election, x='winner', category_orders={'winner': custom_order})\nelection_chart\n\n                                                \n\n\n我们也可以按频率对类别进行排序。\n我们可以使用 x 轴的 categoryorder 属性按频率对类别进行排序。\n\nelection_chart = px.histogram(election, x=\"winner\")\nelection_chart.update_xaxes(categoryorder=\"total descending\")\n\n                                                \n\n\n或者按升序:\n\nelection_chart = px.histogram(election, x=\"winner\")\nelection_chart.update_xaxes(categoryorder=\"total ascending\")\n\n                                                \n\n\n\n\n\n\n\n\n练习\n\n\n\n9.5.3 练习题:已排序的原产州条形图\n创建一个已排序的条形图,显示按原产州划分的鸟类撞击事件分布。按频率的降序排序条形。\n\n# Your code here\n\n\n\n\n\n\n9.5.4 水平条形图\n当您有许多类别时,水平条形图通常比垂直条形图更容易阅读。要创建水平条形图,只需使用 y 轴而不是 x 轴。\n\npx.histogram(tips, y='day')\n\n                                                \n\n\n\n\n\n\n\n\n练习\n\n\n\n9.5.5 练习题:原产州的水平条形图\n创建一个水平条形图,显示按原产州划分的鸟类撞击事件分布。\n\n# Your code here\n\n\n\n\n\n9.5.6 饼图\n饼图也有助于显示分类变量的比例。它们最好在类别数量较少时使用。类别数量较多时,饼图难以阅读。\n让我们创建一个按星期几分布的小费饼图。\n\npx.pie(tips, names=\"day\")\n\n                                                \n\n\n我们可以向饼图添加标签,使其更易于阅读。\n\ntips_by_day = px.pie(tips, names=\"day\")\ntips_by_day_with_labels = tips_by_day.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\ntips_by_day_with_labels\n\n                                                \n\n\n不再需要图例,因此我们可以将其移除。\n\ntips_by_day_with_labels.update_layout(showlegend=False)\n\n                                                \n\n\n\n\n\n\n\n\n专业提示\n\n\n\n如果您忘记了如何进行此类简单更改,请随时查阅 Plotly 文档、Google 或 ChatGPT。\n\n\n\n\n\n\n\n\n练习\n\n\n\n9.5.7 练习题:野生动物大小饼图\n创建一个饼图,显示按野生动物大小划分的鸟类撞击事件分布。将百分比和标签包含在饼片内。\n\n# Your code here\n\n\n\n:::",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>使用 Plotly Express 的单变量图表</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_univariate_cn.html#总结",
    "href": "p_data_on_display_univariate_cn.html#总结",
    "title": "9  使用 Plotly Express 的单变量图表",
    "section": "9.6 总结",
    "text": "9.6 总结\n在本课中,您学习了如何使用 Plotly Express 创建单变量图表。您现在应该对创建条形图、饼图和直方图有信心。您还应该对自定义图表的外观感到舒适。\n下节课见。",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>使用 Plotly Express 的单变量图表</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html",
    "href": "p_data_on_display_multivariate_cn.html",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "",
    "text": "10.1 介绍\n在本课程中,您将学习如何使用 Plotly Express 创建双变量和多变量图。这类图表对于探索两个或多个变量之间的关系至关重要,无论这些变量是定量的还是分类的。理解这些关系可以为您的数据提供更深入的见解。\n让我们开始吧!",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#学习目标",
    "href": "p_data_on_display_multivariate_cn.html#学习目标",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.2 学习目标",
    "text": "10.2 学习目标\n在本课程结束时,您将能够:\n\n为定量对定量数据创建散点图\n为定量对分类数据生成分组直方图和小提琴图\n为分类对分类数据创建分组、堆叠和百分比堆叠条形图\n使用条形图和折线图可视化时间序列数据\n创建气泡图以显示三个或更多变量之间的关系\n使用分面图比较不同数据子集的分布",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#导入",
    "href": "p_data_on_display_multivariate_cn.html#导入",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.3 导入",
    "text": "10.3 导入\n本课程需要 plotly.express、pandas、numpy 和 vega_datasets。如果尚未安装,请先安装它们。\n\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np\nfrom vega_datasets import data",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#数值与数值数据",
    "href": "p_data_on_display_multivariate_cn.html#数值与数值数据",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.4 数值与数值数据",
    "text": "10.4 数值与数值数据\n当两个变量都是定量的时,散点图是可视化它们关系的绝佳方式。\n\n10.4.1 散点图\n让我们创建一个散点图来检查 total_bill 和 tip 在 tips 数据集中的关系。tips 数据集包含在 Plotly Express 中,其中包含美国餐厅服务员收集的餐账和小费信息。\n首先,我们将加载数据集并查看前五行:\n\ntips = px.data.tips()\ntips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n接下来,我们将创建一个基本的散点图。我们将使用 px.scatter 函数来完成。\n\npx.scatter(tips, x='total_bill', y='tip')\n\n                                                \n\n\n从散点图中,我们可以观察到,随着总账单的增加,小费金额也趋于增加。\n让我们通过添加标签和标题来增强散点图。\n\npx.scatter(\n    tips,\n    x=\"total_bill\",\n    y=\"tip\",\n    labels={\"total_bill\": \"总账单($)\", \"tip\": \"小费($)\"},\n    title=\"总账单与小费金额之间的关系\",\n)\n\n                                                \n\n\n请记得,您可以在单元格中输入 px.scatter? 并执行单元格,以查看有关该函数的更多信息。\n\npx.scatter?\n\n\n\n10.4.2 练习题:预期寿命与人均 GDP\n\n\n\n\n\n\n练习\n\n\n\n使用 Gapminder 数据集(以下定义的2007年子集 g_2007),创建一个散点图,显示 gdpPercap(人均 GDP)和 lifeExp(预期寿命)之间的关系。\n根据图表,人均 GDP 和预期寿命之间是什么关系?\n\ngapminder = px.data.gapminder()\ng_2007 = gapminder.query('year == 2007')\ng_2007.head()\n# 您的代码在此处\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n11\nAfghanistan\nAsia\n2007\n43.828\n31889923\n974.580338\nAFG\n4\n\n\n23\nAlbania\nEurope\n2007\n76.423\n3600523\n5937.029526\nALB\n8\n\n\n35\nAlgeria\nAfrica\n2007\n72.301\n33333216\n6223.367465\nDZA\n12\n\n\n47\nAngola\nAfrica\n2007\n42.731\n12420476\n4797.231267\nAGO\n24\n\n\n59\nArgentina\nAmericas\n2007\n75.320\n40301927\n12779.379640\nARG\n32\n\n\n\n\n\n\n\n根据图表,人均 GDP 和预期寿命之间存在正相关关系,尽管在较高的 GDP 值时似乎趋于平稳。",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#数值与分类数据",
    "href": "p_data_on_display_multivariate_cn.html#数值与分类数据",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.5 数值与分类数据",
    "text": "10.5 数值与分类数据\n当一个变量是定量的,另一个是分类的时,我们可以使用分组直方图、小提琴图或箱线图来可视化定量变量在不同类别中的分布。\n\n10.5.1 分组直方图\n首先,以下是如何创建所有小费的常规直方图:\n\npx.histogram(tips, x='tip')\n\n                                                \n\n\n要创建分组直方图,请使用 color 参数指定分类变量。在这里,我们将按 sex 为直方图着色:\n\npx.histogram(tips, x='tip', color='sex')\n\n                                                \n\n\n默认情况下,每个类别的直方图是堆叠的。要更改此行为,您可以使用 barmode 参数。例如,barmode='overlay' 将创建一个重叠的直方图:\n\npx.histogram(tips, x=\"tip\", color=\"sex\", barmode=\"overlay\")\n\n                                                \n\n\n这将在彼此之上创建两个半透明的直方图,从而允许直接比较分布。\n\n\n10.5.2 练习题:按性别的年龄分布\n\n\n\n\n\n\n练习\n\n\n\n使用 vega_datasets 中的 la_riots 数据集,创建按 gender 分组的 age 直方图。比较不同性别之间的年龄分布。\n根据图表,年龄最大的受害者是男性还是女性?\n\nla_riots = data.la_riots()\nla_riots.head()\n# 您的代码在此处\n\n\n\n\n\n\n\n\nfirst_name\nlast_name\nage\ngender\nrace\ndeath_date\naddress\nneighborhood\ntype\nlongitude\nlatitude\n\n\n\n\n0\nCesar A.\nAguilar\n18.0\nMale\nLatino\n1992-04-30\n2009 W. 6th St.\nWestlake\nOfficer-involved shooting\n-118.273976\n34.059281\n\n\n1\nGeorge\nAlvarez\n42.0\nMale\nLatino\n1992-05-01\nMain & College streets\nChinatown\nNot riot-related\n-118.234098\n34.062690\n\n\n2\nWilson\nAlvarez\n40.0\nMale\nLatino\n1992-05-23\n3100 Rosecrans Ave.\nHawthorne\nHomicide\n-118.326816\n33.901662\n\n\n3\nBrian E.\nAndrew\n30.0\nMale\nBlack\n1992-04-30\nRosecrans & Chester avenues\nCompton\nOfficer-involved shooting\n-118.215390\n33.903457\n\n\n4\nVivian\nAustin\n87.0\nFemale\nBlack\n1992-05-03\n1600 W. 60th St.\nHarvard Park\nDeath\n-118.304741\n33.985667\n\n\n\n\n\n\n\n根据图表,年龄最大的受害者是女性。\n\n\n\n\n10.5.3 小提琴图和箱线图\n小提琴图对于比较定量变量在不同类别中的分布非常有用。它们显示了数据在不同值处的概率密度,并可以包括一个箱线图以总结关键统计量。\n首先,让我们创建一个所有小费的小提琴图:\n\npx.violin(tips, y=\"tip\")\n\n                                                \n\n\n我们可以通过将 box 参数设置为 True 来在小提琴图中添加箱线图:\n\npx.violin(tips, y=\"tip\", box=True)\n\n                                                \n\n\n仅使用箱线图,我们可以使用 px.box:\n\npx.box(tips, y=\"tip\")\n\n                                                \n\n\n要在小提琴图或箱线图中添加抖动点,我们可以使用 points='all' 参数。\n\npx.violin(tips, y=\"tip\", points=\"all\")\n\n                                                \n\n\n现在,创建按性别分组的小提琴图,使用 x 参数指定分类变量:\n\npx.violin(tips, y=\"tip\", x=\"sex\", box=True)\n\n                                                \n\n\n我们还可以添加颜色轴以区分小提琴图:\n\npx.violin(tips, y=\"tip\", x=\"sex\", color=\"sex\", box=True)\n\n                                                \n\n\n\n\n\n\n\n\n练习\n\n\n\n10.5.4 练习题:按洲分的预期寿命\n使用 g_2007 数据集,创建一个显示 lifeExp 按 continent 分布的小提琴图。\n根据图表,哪个洲的国家预期寿命中位数最高?\n\ng_2007 = gapminder.query(\"year == 2007\")\ng_2007.head()\n# 您的代码在此处\n\n\n\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\niso_alpha\niso_num\n\n\n\n\n11\nAfghanistan\nAsia\n2007\n43.828\n31889923\n974.580338\nAFG\n4\n\n\n23\nAlbania\nEurope\n2007\n76.423\n3600523\n5937.029526\nALB\n8\n\n\n35\nAlgeria\nAfrica\n2007\n72.301\n33333216\n6223.367465\nDZA\n12\n\n\n47\nAngola\nAfrica\n2007\n42.731\n12420476\n4797.231267\nAGO\n24\n\n\n59\nArgentina\nAmericas\n2007\n75.320\n40301927\n12779.379640\nARG\n32\n\n\n\n\n\n\n\n根据图表,澳大利亚大洋洲的国家预期寿命中位数最高。\n\n\n\n\n10.5.5 摘要条形图(平均值和标准差)\n有时,显示定量变量在不同类别中的平均值和标准差非常有用。这可以使用带有误差条的条形图来可视化。\n首先,让我们计算每个性别的小费平均值和标准差。您尚未学习如何执行此操作,但在后续课程中会涉及。\n\n# 计算平均值和标准差\nsummary_df = (\n    tips.groupby(\"sex\")\n    .agg(mean_tip=(\"tip\", \"mean\"), std_tip=(\"tip\", \"std\"))\n    .reset_index()\n)\nsummary_df\n\n\n\n\n\n\n\n\nsex\nmean_tip\nstd_tip\n\n\n\n\n0\nFemale\n2.833448\n1.159495\n\n\n1\nMale\n3.089618\n1.489102\n\n\n\n\n\n\n\n接下来,我们将使用 px.bar 创建条形图,并使用 error_y 参数添加误差条:\n\n# 创建条形图\npx.bar(summary_df, x=\"sex\", y=\"mean_tip\", error_y=\"std_tip\")\n\n                                                \n\n\n此条形图显示了每个性别的平均小费金额,误差条表示标准差。\n\n\n\n\n\n\n练习\n\n\n\n10.5.6 练习题:按天的平均总账单\n使用 tips 数据集,创建一个带有标准差误差条的按 day 分组的平均 total_bill 条形图。您可以复制并粘贴上面的示例代码,并修改以创建此图。\n根据图表,哪个星期天的平均总账单最高?\n\ntips.head()  # 查看 tips 数据集\n# 您的代码在此处\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n根据图表,星期天的平均账单最高。\n\n\n\n\n\n\n\n\n附注:px.bar 和 px.histogram 之间的区别\n\n\n\n请注意,这是我们第一次使用 px.bar 函数。在过去的图表中,我们使用 px.histogram 来制作条形图。\n条形图函数通常期望被绘制的数值变量已经在自己的列中,而直方图函数会为您进行分组。\n例如,在下面的单元格中,我们使用 px.histogram 制作 sex 列的条形图。生成的图表比较了数据集中男性和女性客户的数量。\n\npx.histogram(tips, x='sex')\n\n                                                \n\n\n要使用 px.bar 制作相同的图表,我们首先需要按 sex 列分组并计算每个性别的行数。\n\nsex_counts = tips['sex'].value_counts().reset_index()\nsex_counts\n\n\n\n\n\n\n\n\nsex\ncount\n\n\n\n\n0\nMale\n157\n\n\n1\nFemale\n87\n\n\n\n\n\n\n\n然后,我们可以使用 px.bar 绘制 sex 列:\n\npx.bar(sex_counts, x=\"sex\", y=\"count\")\n\n                                                \n\n\n这将生成一个每个性别一个条形的条形图。",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#分类与分类数据",
    "href": "p_data_on_display_multivariate_cn.html#分类与分类数据",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.6 分类与分类数据",
    "text": "10.6 分类与分类数据\n当两个变量都是分类时,带有颜色轴的条形图对于可视化类别之间的频率分布非常有效。我们将重点介绍三种类型的条形图:堆叠条形图、百分比堆叠条形图和分组/集群条形图。\n\n10.6.1 堆叠条形图\n堆叠条形图显示总计和每个类别中的分解。要制作堆叠条形图,请使用 color 参数指定分类变量:\n\npx.histogram(\n    tips,\n    x='day',\n    color='sex'\n)\n\n                                                \n\n\n让我们在条形上添加数字以显示确切的计数,并使用自定义颜色改善色彩调色板。\n\npx.histogram(\n    tips,\n    x=\"day\",\n    color=\"sex\",\n    text_auto=True,\n    color_discrete_sequence=[\"#deb221\", \"#2f828a\"],\n)\n\n                                                \n\n\n此堆叠条形图显示了每一天的总客户数量,按性别细分。\n\n\n\n\n\n\n练习\n\n\n\n10.6.2 练习题:按洲的高收入和低收入国家\n使用 g_2007_income 数据集,创建一个堆叠条形图,显示每个洲的高收入和低收入国家的数量。\n\ngap_dat = px.data.gapminder()\n\ng_2007_income = (\n    gap_dat.query(\"year == 2007\")\n    .drop(columns=[\"year\", \"iso_alpha\", \"iso_num\"])\n    .assign(\n        income_group=lambda df: np.where(\n            df.gdpPercap &gt; 15000, \"高收入\", \"低收入和中等收入\"\n        )\n    )\n)\n\ng_2007_income.head()\n# 您的代码在此处\n\n\n\n\n\n\n\n\ncountry\ncontinent\nlifeExp\npop\ngdpPercap\nincome_group\n\n\n\n\n11\nAfghanistan\nAsia\n43.828\n31889923\n974.580338\n低收入和中等收入\n\n\n23\nAlbania\nEurope\n76.423\n3600523\n5937.029526\n低收入和中等收入\n\n\n35\nAlgeria\nAfrica\n72.301\n33333216\n6223.367465\n低收入和中等收入\n\n\n47\nAngola\nAfrica\n42.731\n12420476\n4797.231267\n低收入和中等收入\n\n\n59\nArgentina\nAmericas\n75.320\n40301927\n12779.379640\n低收入和中等收入\n\n\n\n\n\n\n\n\n\n\n\n10.6.3 百分比堆叠条形图\n要显示比例而不是计数,我们可以通过将 barnorm 参数设置为 'percent' 来创建百分比堆叠条形图:\n\n# 创建百分比堆叠条形图\npx.histogram(tips, x=\"day\", color=\"sex\", barnorm=\"percent\")\n\n                                                \n\n\n此图表将条形高度规范化为表示百分比,显示每一天每个性别的比例。\n我们还可以在条形上添加文本标签以显示确切的百分比:\n\npx.histogram(tips, x=\"day\", color=\"sex\", barnorm=\"percent\", text_auto=\".1f\")\n\n                                                \n\n\ntext_auto 参数中的符号 .1f 将文本标签格式化为一位小数。\n\n\n\n\n\n\n练习\n\n\n\n10.6.4 练习题:按洲的高收入和低收入国家比例\n再次使用 g_2007_income 数据集,创建一个百分比堆叠条形图,显示每个洲高收入和低收入国家的比例。添加文本标签以显示确切的百分比。\n根据图表,哪个洲的高收入国家比例最高?此图表有哪些限制?\n\n# 您的代码在此处\n\n\n\n\n\n10.6.5 集群条形图\n对于集群条形图,将 barmode 参数设置为 'group' 以将每个类别的条形并排放置:\n\npx.histogram(tips, x=\"day\", color=\"sex\", barmode=\"group\")\n\n                                                \n\n\n这种布局使得跨类别的值比较更加容易。",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#时间序列数据",
    "href": "p_data_on_display_multivariate_cn.html#时间序列数据",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.7 时间序列数据",
    "text": "10.7 时间序列数据\n时间序列数据表示在不同时间点收集的观察值。它对于分析趋势、模式和随时间的变化至关重要。让我们使用 Gapminder 数据集中尼日利亚的人口数据探索一些基本的时间序列可视化。\n首先,让我们准备数据:\n\n# 加载 Gapminder 数据集\ngapminder = px.data.gapminder()\n\n# 子集数据为尼日利亚\nnigeria_pop = gapminder.query('country == \"Nigeria\"')[['year', 'pop']]\nnigeria_pop\n\n\n\n\n\n\n\n\nyear\npop\n\n\n\n\n1128\n1952\n33119096\n\n\n1129\n1957\n37173340\n\n\n1130\n1962\n41871351\n\n\n1131\n1967\n47287752\n\n\n1132\n1972\n53740085\n\n\n1133\n1977\n62209173\n\n\n1134\n1982\n73039376\n\n\n1135\n1987\n81551520\n\n\n1136\n1992\n93364244\n\n\n1137\n1997\n106207839\n\n\n1138\n2002\n119901274\n\n\n1139\n2007\n135031164\n\n\n\n\n\n\n\n\n10.7.1 条形图\n条形图可以用于绘制时间序列数据。\n\n# 条形图\npx.bar(nigeria_pop, x=\"year\", y=\"pop\")\n\n                                                \n\n\n此条形图清晰地展示了尼日利亚人口随年份的变化,每个条形代表特定年份的人口。\n\n\n10.7.2 折线图\n折线图非常适合显示随时间的连续变化:\n\n# 折线图\npx.line(nigeria_pop, x=\"year\", y=\"pop\")\n\n                                                \n\n\n折线图连接了人口值,使得整体人口增长趋势更易于观察。\n在折线图中添加标记点可以突出显示特定的数据点:\n\n# 带点的折线图\npx.line(nigeria_pop, x='year', y='pop', markers=True)\n\n                                                \n\n\n我们还可以通过添加 color 参数来比较多个国家的人口增长:\n\nnigeria_ghana = gapminder.query('country in [\"Nigeria\", \"Ghana\"]')\npx.line(nigeria_ghana, x=\"year\", y=\"pop\", color=\"country\", markers=True)\n\n                                                \n\n\n此图表允许我们比较尼日利亚和加纳的人口增长趋势。\n\n\n\n\n\n\n练习\n\n\n\n10.7.3 练习题:人均 GDP 时间序列\n使用 Gapminder 数据集,创建伊拉克人均 GDP 的时间序列可视化。\n\n# 您的代码在此处\n\n1980 年代伊拉克发生了什么事件,可能解释了图表中的现象?",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#三个或更多变量的图表",
    "href": "p_data_on_display_multivariate_cn.html#三个或更多变量的图表",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.8 三个或更多变量的图表",
    "text": "10.8 三个或更多变量的图表\n虽然双变量可视化是最常见的可视化类型,但有时三个或更多变量的图表也是有用的。让我们探索一些示例。\n\n10.8.1 气泡图\n气泡图通过将点的大小映射到第三个变量来显示三个变量之间的关系。下面,我们绘制了 gdpPercap 和 lifeExp 之间的关系,点的大小表示国家的人口。\n\npx.scatter(g_2007, x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\")\n\n                                                \n\n\n我们可以轻松地识别出人口最多的国家,如中国、印度和美国。我们还可以添加颜色轴以区分不同洲:\n\npx.scatter(g_2007, x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\")\n\n                                                \n\n\n现在我们绘制了四个不同的变量:\n\ngdpPercap 在 x 轴\nlifeExp 在 y 轴\npop 作为点的大小\ncontinent 作为点的颜色\n\n\n\n\n\n\n\n练习\n\n\n\n10.8.2 练习题:小费气泡图\n使用 tips 数据集,创建一个气泡图,显示 total_bill 和 tip 之间的关系,点的大小表示聚会的 size,颜色表示星期几的 day。\n使用此图回答以下问题:\n\n最高的两个小费金额是哪几天的,且桌子的人数是多少?\n\n\ntips.head()\n# 您的代码在此处\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\n\n\n\n10.8.3 分面图\n分面图将单个图表拆分为多个图表,每个图表显示数据的不同子集。这对于比较不同子集之间的分布非常有用。\n例如,我们可以按洲对气泡图进行分面:\n\npx.scatter(\n    g_2007,\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    size=\"pop\",\n    color=\"continent\",\n    facet_col=\"continent\",\n)\n\n                                                \n\n\n我们可以通过更改 facet_col_wrap 参数来更改分面排列。例如,facet_col_wrap=2 将分面排列为两列:\n\npx.scatter(\n    g_2007,\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    size=\"pop\",\n    color=\"continent\",\n    facet_col=\"continent\",\n    facet_col_wrap=2,\n)\n\n                                                \n\n\n类似地,我们可以按星期几对小费的小提琴图进行分面:\n\npx.violin(\n    tips,\n    x=\"sex\",\n    y=\"tip\",\n    color=\"sex\",\n    facet_col=\"day\",\n    facet_col_wrap=2,\n)\n\n                                                \n\n\n分面图使我们能够比较不同日子的分布,提供更细致的见解。\n\n\n\n\n\n\n练习\n\n\n\n10.8.4 练习题:小费分面图\n使用 tips 数据集,创建一个按 day 分面、按 time 列百分比堆叠、颜色按 sex 列的条形图。\n哪个日子的哪个时间段拥有最高比例的男性客户(例如,星期五午餐、星期六晚餐等)?\n\ntips.head()\n# 您的代码在此处\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_data_on_display_multivariate_cn.html#总结",
    "href": "p_data_on_display_multivariate_cn.html#总结",
    "title": "10  使用 Plotly Express 的双变量和多变量图",
    "section": "10.9 总结",
    "text": "10.9 总结\n在本课程中,您学习了如何使用 Plotly Express 创建双变量和多变量图。理解这些可视化技术将帮助您更有效地探索和传达数据中的关系。\n下节课见!",
    "crumbs": [
      "数据可视化",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>使用 Plotly Express 的双变量和多变量图</span>"
    ]
  },
  {
    "objectID": "p_tools_installing_python_cn.html",
    "href": "p_tools_installing_python_cn.html",
    "title": "11  安装 Python",
    "section": "",
    "text": "11.1 介绍\n在我们的学习序列中,您迄今大部分时间都在使用 Google Colab,这是一个便捷的基于云的环境,用于运行 Python 代码。现在是时候开始在您自己的机器上本地工作了。这允许您离线工作,并让您对开发环境具有更多控制权。\n我们将引导您安装 Python 3.12.0,以确保与我们将要涵盖的示例和练习兼容。让我们开始吧!\n在继续之前,我们将指示分为两个轨道:\n请按照适用于您的操作系统的指示进行操作。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>安装 Python</span>"
    ]
  },
  {
    "objectID": "p_tools_installing_python_cn.html#介绍",
    "href": "p_tools_installing_python_cn.html#介绍",
    "title": "11  安装 Python",
    "section": "",
    "text": "Windows 用户\nmacOS 用户",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>安装 Python</span>"
    ]
  },
  {
    "objectID": "p_tools_installing_python_cn.html#windows-用户",
    "href": "p_tools_installing_python_cn.html#windows-用户",
    "title": "11  安装 Python",
    "section": "11.2 Windows 用户",
    "text": "11.2 Windows 用户\n\n11.2.1 步骤 1:检查您当前的 Python 版本\n\n在开始菜单中搜索“命令提示符”。\n在终端窗口中输入 python --version,然后按 回车。\n如果已安装 Python,它将显示版本号。\n如果您已经安装了 3.12.0 版本,您可以跳过其余步骤。如果您拥有其他版本(无论高低),请继续下一步安装 3.12.0。\n\n\n\n11.2.2 步骤 2:下载 Python 3.12.0\n\n打开您的网络浏览器。\n前往 Google,并搜索 “Python 3.12.0”。\n在搜索结果中,找到提到 Python 3.12.0 的 python.org 链接。\n滚动到 Python 3.12.0 页面底部,找到 “Windows 安装程序(64 位)”。然后点击链接下载安装程序。\n\n\n\n11.2.3 步骤 3:安装 Python\n\n找到下载的文件(通常在您的 下载 文件夹中)。\n双击安装程序以运行它。\n重要: 在安装程序窗口底部勾选 “Add Python 3.12 to PATH”。\n如果有选项,也请选择使用管理员权限。\n最后,您可能会被问及是否要禁用路径长度限制。也点击“是”。\n等待安装完成。\n\n\n\n11.2.4 步骤 4:验证安装\n\n如果旧的命令提示符窗口仍然打开,请将其关闭。\n在开始菜单中再次搜索“命令提示符”并打开一个新的终端窗口。\n输入 python --version 并按 回车。\n您应该会看到 Python 3.12.0。 (如果您电脑上已经有 Python,可能会看到更新的版本。这没关系。从我们的 IDE 中,我们将能够选择刚刚安装的正确版本的 Python。)\n\n\n\n11.2.5 步骤 5:在本地运行 Python\n\n在命令提示符中输入 python 并按 回车。\n在 &gt;&gt;&gt; 提示符下,输入 2 + 2 并按 回车。\n您应该会看到 4。\n输入 exit() 并按 回车。\n\n太好了! 您已成功安装 Python,并运行了您的第一个本地 Python 命令。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>安装 Python</span>"
    ]
  },
  {
    "objectID": "p_tools_installing_python_cn.html#macos-用户",
    "href": "p_tools_installing_python_cn.html#macos-用户",
    "title": "11  安装 Python",
    "section": "11.3 macOS 用户",
    "text": "11.3 macOS 用户\n\n11.3.1 步骤 1:检查您当前的 Python 版本\n\n前往 应用程序 &gt; 实用工具 &gt; 终端。\n输入 python3 --version 并按 回车。\n如果已安装 Python,它将显示版本号。\n如果您没有安装命令行开发工具,可能会弹出一个提示让您安装。请接受并安装。\n如果您的电脑尚未安装 Python,您会收到错误提示。\n否则,您应该会看到一个版本号。\n如果您已经安装了 3.12.0 版本,您可以跳过其余步骤。如果您拥有其他版本(无论高低),请继续下一步安装 3.12.0。\n\n\n\n11.3.2 步骤 2:下载 Python 3.12.0\n\n打开您的网络浏览器。\n前往 Google,并搜索 “Python 3.12.0”。\n在搜索结果中,找到提到 Python 3.12.0 的 python.org 链接。\n确保 URL 来自 www.python.org,以避免非官方来源。\n滚动到 Python 3.12.0 页面底部。\n在 “文件” 部分下,找到 “macOS 64 位 universal2 安装程序”。\n点击链接下载安装程序。\n\n\n\n11.3.3 步骤 3:安装 Python 3.12.0\n\n找到下载的文件(通常在您的 下载 文件夹中)。\n双击安装程序以运行它。\n等待安装完成。\n安装完成后,点击 “关闭”。\n\n\n\n11.3.4 步骤 4:验证安装\n\n如果旧的终端窗口仍然打开,请将其关闭。\n再次前往 应用程序 &gt; 实用工具 &gt; 终端。\n输入 python3 --version 并按 回车。\n您应该会看到 Python 3.12.0。\n\n\n\n11.3.5 步骤 5:在本地运行 Python\n\n在终端中输入 python3 并按 回车。\n在 &gt;&gt;&gt; 提示符下,输入 2 + 2 并按 回车。\n您应该会看到 4。\n输入 exit() 并按 回车。\n\n太好了! 您已成功在 Mac 上安装 Python 3.12.0,并运行了您的第一个本地 Python 命令。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>安装 Python</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html",
    "href": "p_tools_using_vscode_cn.html",
    "title": "12  安装和使用 VS Code",
    "section": "",
    "text": "12.1 介绍\n在本课中,我们将探索 Visual Studio Code(VS Code),一款功能强大且多用途的编辑器,用于编写、运行和调试 Python 代码。由于其丰富的功能集和广泛的扩展库,VS Code 被广泛使用,使编码更加高效和愉快。\n请注意,本课最好以视频形式学习,因为有许多图形用户界面步骤难以用文字描述。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#学习目标",
    "href": "p_tools_using_vscode_cn.html#学习目标",
    "title": "12  安装和使用 VS Code",
    "section": "12.2 学习目标",
    "text": "12.2 学习目标\n本课程结束时,您应该能够:\n\n打开 VS Code 并导航到编辑器、终端和资源管理器标签。\n创建一个新的 Python 文件,并使用 Python 扩展运行它。\n使用命令面板搜索并选择一个配色主题。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#安装-vs-code",
    "href": "p_tools_using_vscode_cn.html#安装-vs-code",
    "title": "12  安装和使用 VS Code",
    "section": "12.3 安装 VS Code",
    "text": "12.3 安装 VS Code\nVS Code 可用于 Windows、macOS 和 Linux。在您喜欢的搜索引擎中搜索“VS Code”,然后访问官方网站 code.visualstudio.com。下载适用于您计算机操作系统的版本。\n对于 macOS 用户,安装 VS Code 后,您可能需要将图标拖到“应用程序”文件夹中。\n从“应用程序”文件夹中,打开 VS Code。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#导航资源管理器标签",
    "href": "p_tools_using_vscode_cn.html#导航资源管理器标签",
    "title": "12  安装和使用 VS Code",
    "section": "12.4 导航资源管理器标签",
    "text": "12.4 导航资源管理器标签\n资源管理器 标签显示您当前工作空间中的文件和文件夹。当您第一次打开 VS Code 时,可能会提示您尚未打开任何文件夹。我们在 Python 中的大部分工作将组织在包含多个文件的文件夹(也称为工作空间)中。\n让我们创建第一个工作空间:\n\n在您的计算机上,导航到桌面或其他易于记忆的位置。\n创建一个名为 first_python_workspace 的新文件夹。\n在 VS Code 中,点击 “Open Folder” 按钮并找到您新建的文件夹。或者,您也可以将文件夹拖入 VS Code 窗口。\n\n现在您的工作空间已在 VS Code 中打开,您可以创建一个新文件:\n\n在 资源管理器 标签中,在工作空间文件夹内右击。\n选择 “New File”。\n将文件命名为 first_script.py。文件将自动在编辑器中打开。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#编写和保存-python-代码",
    "href": "p_tools_using_vscode_cn.html#编写和保存-python-代码",
    "title": "12  安装和使用 VS Code",
    "section": "12.5 编写和保存 Python 代码",
    "text": "12.5 编写和保存 Python 代码\n让我们在新文件中编写一些 Python 代码:\nprint(2 + 2)\n要保存文件,请按 Ctrl + S(或在 macOS 上按 Cmd + S)。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#安装-python-扩展",
    "href": "p_tools_using_vscode_cn.html#安装-python-扩展",
    "title": "12  安装和使用 VS Code",
    "section": "12.6 安装 Python 扩展",
    "text": "12.6 安装 Python 扩展\n要在 VS Code 中运行 Python 代码,我们需要安装 Python 扩展:\n\n点击左侧侧边栏中的 扩展 标签(看起来像四个方块)。\n在顶部的搜索栏中,输入 “Python”。\n找到由 Microsoft 发布的名为 “Python” 的扩展,然后点击 安装。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#运行您的-python-脚本",
    "href": "p_tools_using_vscode_cn.html#运行您的-python-脚本",
    "title": "12  安装和使用 VS Code",
    "section": "12.7 运行您的 Python 脚本",
    "text": "12.7 运行您的 Python 脚本\n安装 Python 扩展后,您现在可以运行您的脚本:\n\n如果 first_script.py 尚未打开,请打开它。\n点击编辑器右上角的 运行 图标(播放按钮)。\n\n或者,您可以在编辑器中右击并选择运行 Python,然后选择 “Run Python File in Terminal”。\n\n终端窗口将打开在屏幕底部,您的代码将执行。您应该会看到输出:\n4",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#使用命令面板",
    "href": "p_tools_using_vscode_cn.html#使用命令面板",
    "title": "12  安装和使用 VS Code",
    "section": "12.8 使用命令面板",
    "text": "12.8 使用命令面板\n命令面板 是 VS Code 中一个强大的功能,允许您访问各种命令和设置:\n要访问它,请点击 VS Code 窗口顶部的搜索栏,然后按 &gt; 或选择“显示并运行命令”选项。\n让我们练习更改配色主题:\n\n输入 ‘theme’ 并选择 ‘Preferences: Color Theme’。\n使用上下箭头键循环浏览可用的配色主题。\n按 Enter 选择您喜欢的主题。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_using_vscode_cn.html#总结",
    "href": "p_tools_using_vscode_cn.html#总结",
    "title": "12  安装和使用 VS Code",
    "section": "12.9 总结",
    "text": "12.9 总结\n在本课中,我们:\n\n安装了 VS Code 并设置了一个工作空间。\n创建并保存了一个 Python 脚本。\n安装了 Python 扩展 以启用运行和调试代码。\n使用了命令面板 来自定义编辑器的外观。\n\n祝编码愉快!",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装和使用 VS Code</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html",
    "href": "p_tools_venv_cn.html",
    "title": "13  文件夹和虚拟环境",
    "section": "",
    "text": "13.1 介绍\n在本课程中,我们将使用 Visual Studio Code (VS Code) 探索 Python 中的虚拟环境。我们将创建一个新的工作区,设置一个虚拟环境,并安装项目特定的包。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#学习目标",
    "href": "p_tools_venv_cn.html#学习目标",
    "title": "13  文件夹和虚拟环境",
    "section": "13.2 学习目标",
    "text": "13.2 学习目标\n完成本课程后,您应该能够:\n\n在 VS Code 中创建一个新的工作区\n理解虚拟环境的概念\n在 VS Code 中创建和使用虚拟环境\n在虚拟环境中安装和使用包",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#创建新的工作区",
    "href": "p_tools_venv_cn.html#创建新的工作区",
    "title": "13  文件夹和虚拟环境",
    "section": "13.3 创建新的工作区",
    "text": "13.3 创建新的工作区\n在您的桌面或 Documents 文件夹中,创建一个新文件夹并命名为 graph_courses_python。这是本课程许多项目的主文件夹,请确保将其放在一个容易找到的位置。\n打开 VS Code。\n转到 文件 &gt; 打开文件夹。\n导航到您刚创建的 graph_courses_python 文件夹并选择它。\n现在创建一个新的脚本,命名为 test_cowsay.py。\n在文件中输入 print(2 + 2),然后点击运行按钮以确保一切正常工作。\n接下来,让我们尝试导入我们尚未安装的包。将以下行添加到您的文件中:\n\nimport cowsay\n\ncowsay.cow(\"Hello, World!\")\n\n如果您尝试运行此代码,将会出现错误。\n这是因为我们尚未安装 cowsay 包。为了正确安装它,我们需要使用虚拟环境。\n\n13.3.1 词汇:环境与解释器\n\n环境 是一个文件夹,包含特定版本的 Python 及您安装的任何包。\nPython 解释器 是特定的",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#创建虚拟环境",
    "href": "p_tools_venv_cn.html#创建虚拟环境",
    "title": "13  文件夹和虚拟环境",
    "section": "13.4 创建虚拟环境",
    "text": "13.4 创建虚拟环境\n\n打开 命令面板\n输入 Python: Create Environment 并选择它。\n选择 Venv 作为环境类型。\n选择您要使用的 Python 解释器(例如,Python 3.12.0)。\n\n您现在应该看到一个名为 .venv 的新文件夹。这就是虚拟环境。里面有一个名为 lib 的文件夹,包含包。\n接下来,告诉 VS Code 使用这个虚拟环境:\n\n再次打开 命令面板。\n输入 Python: Select Interpreter 并选择它。\n选择与您的虚拟环境相关联的解释器(它应列在 .venv 下)。\n\n现在我们已经创建并选择了我们的虚拟环境。我们可以在不影响其他项目的情况下安装包。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#安装包",
    "href": "p_tools_venv_cn.html#安装包",
    "title": "13  文件夹和虚拟环境",
    "section": "13.5 安装包",
    "text": "13.5 安装包\n让我们安装 cowsay 包。\n\n在 VS Code 中打开一个 新终端。 您可以通过终端文件菜单选项然后选择“新终端”来完成。\n确保终端正在使用您的虚拟环境。您可以通过将鼠标悬停在终端窗口中的终端图标上来检查。它应该提到已激活 .venv 环境等信息。\n运行以下命令:\n\n#| eval: false\npip install cowsay\n有时,您可能会遇到 pip 在终端中无法识别的问题。这可能是由于 VS Code 的环境检测出现暂时性故障。如果发生这种情况,请尝试以下步骤:\n\n关闭并重新打开 VS Code。\n使用命令面板重新选择 Python 解释器。\n打开一个新终端。\n\n这些步骤应能解决问题并恢复对 pip 的访问。如果问题仍然存在,可能表明存在更复杂的配置问题,需要进一步调查。\n现在我们应该可以使用 cowsay 包。打开 test_cowsay.py 并点击运行按钮来执行脚本。\n您应该会看到一头牛在打招呼!",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#关键步骤总结",
    "href": "p_tools_venv_cn.html#关键步骤总结",
    "title": "13  文件夹和虚拟环境",
    "section": "13.6 关键步骤总结",
    "text": "13.6 关键步骤总结\n恭喜!您已经创建了一个虚拟环境并安装了一个包。\n这些是任何新 Python 项目的关键步骤:\n\nFolder:创建一个项目文件夹。\nEnvironment:设置一个虚拟环境。\nInterpreter:选择合适的 Python 解释器。\nLibraries:安装必要的包。\n\n记住这个首字母缩略词 FEIL 以帮助您记忆这些步骤。(如果您不完成这些步骤,您将增加“失败”(FEILure)的可能性 😅)\n每次开始一个新项目都需要设置一个虚拟环境有点麻烦,但这是一个养成的好习惯。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#演示环境隔离",
    "href": "p_tools_venv_cn.html#演示环境隔离",
    "title": "13  文件夹和虚拟环境",
    "section": "13.7 演示环境隔离",
    "text": "13.7 演示环境隔离\n让我们演示虚拟环境是如何隔离的。\n\n使用文件 &gt; 打开文件夹菜单选项打开您之前的工作区 my_first_workspace。\n创建一个 Python 文件并尝试使用 cowsay 包:\n::: {#41ccc204 .cell execution_count=2} {.python .cell-code}  import cowsay :::\n\n这可能无法正常工作,因为该环境中未安装 cowsay。如果它确实工作,这意味着您已在全局范围内安装了 cowsay,这也是可以的。\n现在,让我们返回到我们的主文件夹/工作区。这是您将在本课程中进行大部分分析的地方。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#安装课程包",
    "href": "p_tools_venv_cn.html#安装课程包",
    "title": "13  文件夹和虚拟环境",
    "section": "13.8 安装课程包",
    "text": "13.8 安装课程包\n作为最后一步,让我们安装课程所需的包。虽然我们可以在遇到每个包时分别安装,但一次性安装所有包更有效。在终端中运行以下命令。请非常仔细地输入这些命令。\n#| eval: false\npip install plotly pandas jupyter ipykernel kaleido itables\n\npandas:数据操作库。\nplotly:可视化库。\njupyter 和 ipykernel:允许我们使用 Quarto 显示我们的图表。\nkaleido:用于以不同格式保存图表的库。\nitables:在 Quarto 中显示表格的库。\n\n安装完成后,终端中的光标应再次处于活动状态。例如,您应该可以按回车键开始一个新命令。\n将此包列表保留以备将来参考,因为您可能会在大多数项目中需要它们。\n此命令将一次性安装所有所需的包。如果您的安装在某个点停止,请尝试重新运行该命令。有时网络问题可能会导致安装失败。如果它冻结超过 10 分钟,请关闭终端并重新运行该命令。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_venv_cn.html#结论",
    "href": "p_tools_venv_cn.html#结论",
    "title": "13  文件夹和虚拟环境",
    "section": "13.9 结论",
    "text": "13.9 结论\n您现在已经学习了如何创建工作区,设置虚拟环境,安装包,并在 Python 项目中使用它们。请记住,每个项目都应该有自己的虚拟环境,以保持依赖项的隔离和可管理性。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>文件夹和虚拟环境</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html",
    "href": "p_tools_quarto_cn.html",
    "title": "14  使用 Quarto",
    "section": "",
    "text": "14.1 介绍\n作为数据分析师,你角色的重要部分是通过报告将结果传达给他人。Quarto 是生成此类报告最强大、最灵活的工具之一。它使你能够通过结合格式化文本和代码生成的结果来生成动态文档。使用 Quarto,你可以创建各种格式的文档,如 HTML、PDF、Word、PowerPoint 幻灯片、网页仪表板等。\n我们在 GRAPH 课程中的大部分文档实际上都是用 Quarto 编写的!\n在本课中,我们将介绍这个强大工具的基础知识。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#学习目标",
    "href": "p_tools_quarto_cn.html#学习目标",
    "title": "14  使用 Quarto",
    "section": "14.2 学习目标",
    "text": "14.2 学习目标\n完成本课后,你应该能:\n\n创建并渲染包含 Python 代码和叙述文本的 Quarto 文档。\n以多种格式输出文档,包括 HTML、PDF、Word 等。\n理解基本的 Markdown 语法。\n使用代码块选项来控制代码执行和输出显示。\n使用 Python 包在 Quarto 文档中显示表格和图形。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#安装-quarto",
    "href": "p_tools_quarto_cn.html#安装-quarto",
    "title": "14  使用 Quarto",
    "section": "14.3 安装 Quarto",
    "text": "14.3 安装 Quarto\n要开始使用,首先需要安装 Quarto。\n在你喜欢的搜索引擎中搜索“quarto download”。按照结果进入“Quarto.org”网站,然后按照你的操作系统的说明进行操作。(我们不在这里提供直接链接,因为确切链接可能会随着时间变化。)\n安装后,可以通过在命令行或终端中运行以下命令来检查是否已安装:\nquarto --version\n现在 Quarto 已安装,使用它来安装 tinytex 包,我们需要该包来编译我们的 PDF:\nquarto install tinytex\n要在 VSCode 中使用 Quarto 的所有功能,我们需要安装 Quarto 扩展和 Jupyter 扩展。你可以在 VSCode 的扩展标签中安装这些扩展。确保安装这些扩展的官方版本。Quarto 由 Quarto 发布,Jupyter 由微软发布。\n这需要安装很多扩展,但不要担心——你只需在电脑上完成这些步骤一次。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#项目设置",
    "href": "p_tools_quarto_cn.html#项目设置",
    "title": "14  使用 Quarto",
    "section": "14.4 项目设置",
    "text": "14.4 项目设置\n首先,在 VSCode 中打开你的 graph_courses_python 项目。\n如果你没有观看前一个解释项目设置的视频,请现在观看。在那个视频中,我们解释了如何创建项目文件夹、创建虚拟环境、选择解释器,并安装 jupyter、ipykernel、kaleido、itables、plotly 和 pandas 包。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#创建新文档",
    "href": "p_tools_quarto_cn.html#创建新文档",
    "title": "14  使用 Quarto",
    "section": "14.5 创建新文档",
    "text": "14.5 创建新文档\nQuarto 文档是一个简单的文本文件,扩展名为 .qmd。\n要创建一个新的 Quarto 文档,创建一个新文件并将其保存为 .qmd 扩展名,例如 first_quarto_doc.qmd。\n在你的文档中添加以下文本的两个部分:\n# 第一节\n\n你好\n\n\n# 第二节\n\n世界",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#添加代码块",
    "href": "p_tools_quarto_cn.html#添加代码块",
    "title": "14  使用 Quarto",
    "section": "14.6 添加代码块",
    "text": "14.6 添加代码块\n你可以使用以下语法及快捷键 Cmd + Shift + I(Mac 上)或 Ctrl + Shift + I(Windows 上)向文档中添加代码块。或者,可以点击屏幕右上方的“…”按钮。\n让我们创建一个将两个数字相加并显示结果的代码块:\n\n2 + 2\n\n4\n\n\n你应该在工具栏中看到一个“运行单元格”按钮。点击它来运行代码块。\n如果你尚未在当前环境中安装 ipykernel 包,VSCode 可能会提示你安装。去安装它。\n现在练习在文档末尾添加另一个将 3 乘以 3 的代码块。\n添加这些后,你应该也会看到“运行下一个单元”和“运行上方”按钮出现。\n还有两个你应该熟悉的快捷键:\n\nCmd + Enter(Mac)或 Ctrl + Enter(Windows/Linux)运行代码块。\nOption + Enter(Mac)或 Alt + Enter(Windows/Linux)运行当前行或选中的代码部分。\n\n要测试这些快捷键,在一个代码块中添加多行代码,然后练习使用第一个快捷键运行整个块,用第二个快捷键逐行运行。\n如你所见,我们可以将 Quarto 用作类似于 Jupyter notebook 或 Google Colab 的交互式文档。但真正使它出色的是其输出多种格式的能力。\n课程后面,我们将看到如何使用此功能。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#quarto-文档头部-yaml",
    "href": "p_tools_quarto_cn.html#quarto-文档头部-yaml",
    "title": "14  使用 Quarto",
    "section": "14.7 Quarto 文档头部 (YAML)",
    "text": "14.7 Quarto 文档头部 (YAML)\n在文档顶部,我们添加一个 YAML 部分。这是我们可以指定文档详情的地方,例如标题、作者和格式。\n---\ntitle: \"我的第一个 Quarto 文档\"\nauthor: \"你的名字\"\nformat: html\n---\n现在,我们将只使用 html 格式。\n要渲染文档,点击屏幕右上方的“Render”按钮。\n(要正确渲染,你需要安装 jupyter 包。如果你尚未设置虚拟环境,请观看我们关于设置虚拟环境的视频,并了解如何安装包。)\n你应该会在 VSCode 中看到一个新标签页,显示已经渲染的文档。\n如果你转到资源管理器,你应该会看到一个名为 first_quarto_doc.html 的新文件。\n所以现在我们拥有了 Quarto 文档的主要元素:\n\nYAML 头部\n部分标题\n文本\n代码块\n这些代码块的输出\n\n这些元素共同使 Quarto 成为报告的一个非常强大的工具。\n你还可以使用额外的选项来自定义输出格式。例如,要将资源直接嵌入到 HTML 文件中,可以修改 YAML 头部中的 format 部分:\nformat:\n  html:\n    embed-resources: true",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#输出格式",
    "href": "p_tools_quarto_cn.html#输出格式",
    "title": "14  使用 Quarto",
    "section": "14.8 输出格式",
    "text": "14.8 输出格式\n如我们之前讨论的,Quarto 的一个强大功能是它能够输出多种格式。\n你可以在 YAML 头部中更改 format 值来尝试其他格式。\n尝试以下格式:\n\nhtml:将文档渲染为 HTML 网页。\npdf:将文档渲染为 PDF。你需要在电脑上安装 LaTeX(或 tinytex)才能使用此格式。\ndocx:将文档渲染为 Microsoft Word 文档。\npptx:将文档渲染为 PowerPoint 演示文稿。\nrevealjs:将文档渲染为 HTML 幻灯片。\ndashboard:将文档渲染为交互式仪表板。\n\n请注意,由于不同的操作系统或软件版本,这些格式中的一些可能无法在你的电脑上正常工作。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#markdown",
    "href": "p_tools_quarto_cn.html#markdown",
    "title": "14  使用 Quarto",
    "section": "14.9 Markdown",
    "text": "14.9 Markdown\nQuarto 文档中的文本使用 Markdown 编写。\nMarkdown 是一组用于为纯文本添加格式的简单约定。例如,要将文本设置为斜体,可以将其用星号包裹 *text here*,要开始一个新标题,可以使用井号 #。我们将在下面详细学习这些内容。\n你可以通过在一行开始添加一个或多个 # 来定义不同级别的标题:\n# 一级标题\n\n## 二级标题\n\n### 三级标题\n文档主体由遵循 Markdown 语法的文本组成。Markdown 文件是包含轻量级标记的文本文件,帮助设置标题级别或格式化文本。例如,以下文本:\nThis is text with *italics* and **bold**.\n\nYou can define bulleted lists:\n\n- First element\n- Second element\n将生成以下格式化的文本:\n\n这是带有斜体和粗体的文本。\n你可以定义无序列表:\n\n第一项\n第二项\n\n\n注意,你需要在列表前后留空行,并将列表项保持在单独的行上。否则,它们会挤在一起,而不是形成列表。\n我们看到,放在星号之间的词语会变为斜体,而以破折号开头的行会转换为项目符号列表。\nMarkdown 语法还允许其他格式化,例如插入链接或图片。例如,以下代码:\n[示例链接](https://example.com)\n… 将生成以下链接:\n\n示例链接\n\n我们还可以嵌入图片。在你的文档中,你可以输入:\n![替代文本](images/picture_name.jpg)\n将“替代文本”替换为图片的描述(也可以为空),将“images”替换为项目中的图片文件夹名称,将“picture_name.jpg”替换为你想要使用的图片名称。或者,在某些编辑器中,你可以将图片拖放到文档中。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#代码块选项",
    "href": "p_tools_quarto_cn.html#代码块选项",
    "title": "14  使用 Quarto",
    "section": "14.10 代码块选项",
    "text": "14.10 代码块选项\n可以为每个代码块传递选项以修改其行为。\n例如,一个代码块如下所示:\n\n# Your code here\nx = 2 + 2\nprint(x)\n\n4\n\n\n但你可以添加选项来控制代码块的执行和显示:\n\n\n4\n\n\n在此示例中,echo: false 选项告诉 Quarto 不在渲染的文档中显示代码,仅显示输出。\n\n14.10.1 全局选项\n你可能希望全局应用选项到文档中的所有代码块。你可以在 YAML 头部的 execute 键下设置默认的代码执行选项。\n例如:\n---\ntitle: \"Quarto 文档\"\nformat: html\nexecute:\n  echo: false\n---\n这将为所有代码块设置 echo: false。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#显示表格",
    "href": "p_tools_quarto_cn.html#显示表格",
    "title": "14  使用 Quarto",
    "section": "14.11 显示表格",
    "text": "14.11 显示表格\n默认情况下,pandas DataFrame 在 Quarto 中显示整洁。然而,对于交互式表格,我们可以使用 itables 包。\n确保你已安装 itables 包。如果没有,可以使用以下命令安装:\n\n!pip install itables\n\n然后,你可以运行类似以下的代码:\n\nimport plotly.express as px\nfrom itables import show\n\ntips = px.data.tips()\nshow(tips)\n\n\n\n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.2.2 from the internet...\n(need help?)\n\n\n\n\n\n\n\n\n请注意,交互式表格仅在 HTML 格式中有效。我们将在后面查看其他格式的表格。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#显示图表",
    "href": "p_tools_quarto_cn.html#显示图表",
    "title": "14  使用 Quarto",
    "section": "14.12 显示图表",
    "text": "14.12 显示图表\n对于交互式图表,plotly 包非常有用。\n\ntips = px.data.tips()\ntips_sex = px.violin(tips, x=\"day\", y=\"total_bill\", color=\"sex\")\ntips_sex.show()\n\n                                                \n\n\n这将在 HTML 输出中显示一个交互式的 Plotly 图表。\n对于静态输出,如 PDF 和 Word 文档,我们需要将图表保存为图像文件,然后将其包含在文档中。\n首先,将图表保存为图像:\n\ntips_sex.write_image(\"tips_sex_plot.png\")\n\n此命令将在与你的文档相同的文件夹中创建一个静态图像文件。然后,我们可以将其包含在文档中,如下所示:\n![按日和性别划分的总账单小提琴图](tips_sex_plot.png)\n这将在输出中显示图片。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_tools_quarto_cn.html#结束语",
    "href": "p_tools_quarto_cn.html#结束语",
    "title": "14  使用 Quarto",
    "section": "14.13 结束语",
    "text": "14.13 结束语\n在本课中,我们学习了如何创建和渲染 Quarto 文档,添加格式,以及包含代码块。我们还学习了如何使用代码块选项来控制文档的行为。我们尝试了不同的输出格式以及如何自定义文档的显示。\n通过这些工具,你可以创建动态和交互式的报告,能够以各种格式轻松分享。Quarto 的灵活性和与 Python 的集成使其成为数据分析师和研究人员的优秀选择。",
    "crumbs": [
      "本地 Python 工具",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>使用 Quarto</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html",
    "href": "p_untangled_subset_columns_cn.html",
    "title": "15  选择列子集",
    "section": "",
    "text": "15.1 介绍\n今天我们将开始探索使用 pandas 进行数据处理!\n我们的第一个重点将是选择和重命名列。通常,您的数据集包含许多您不需要的列,您希望将其缩减为几列。Pandas 使这变得容易。让我们来看一下。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#学习目标",
    "href": "p_untangled_subset_columns_cn.html#学习目标",
    "title": "15  选择列子集",
    "section": "15.2 学习目标",
    "text": "15.2 学习目标\n\n您可以使用方括号 []、filter() 和 drop() 从 DataFrame 中保留或删除列。\n您可以使用 filter() 根据正则表达式模式选择列。\n您可以使用 rename() 更改列名。\n您可以使用正则表达式清理列名。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#关于-pandas",
    "href": "p_untangled_subset_columns_cn.html#关于-pandas",
    "title": "15  选择列子集",
    "section": "15.3 关于 pandas",
    "text": "15.3 关于 pandas\nPandas 是一个流行的数据处理和分析库。它旨在使在 Python 中处理表格数据变得容易。\n如果尚未安装,请在终端中使用以下命令安装 pandas:\n\npip install pandas \n\n然后在脚本中使用以下命令导入 pandas:\n\nimport pandas as pd",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#雅温得-covid-19-数据集",
    "href": "p_untangled_subset_columns_cn.html#雅温得-covid-19-数据集",
    "title": "15  选择列子集",
    "section": "15.4 雅温得 COVID-19 数据集",
    "text": "15.4 雅温得 COVID-19 数据集\n本课中,我们分析了 2020 年底在喀麦隆雅温得进行的一项 COVID-19 调查的结果。该调查通过抗体检测估计了该地区有多少人感染了 COVID-19。\n您可以在此处了解有关此数据集的更多信息: https://www.nature.com/articles/s41467-021-25946-0\n要下载数据集,请访问此链接: https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/yaounde_data.zip\n然后解压文件,并将 yaounde_data.csv 文件放在与笔记本相同目录下的 data 文件夹中。\n让我们加载并检查数据集:\n\nyao = pd.read_csv(\"data/yaounde_data.csv\")\nyao\n\n\n\n\n\n\n\n\nid\ndate_surveyed\nage\nage_category\nage_category_3\nsex\nhighest_education\noccupation\nweight_kg\nheight_cm\n...\nis_drug_antibio\nis_drug_hydrocortisone\nis_drug_other_anti_inflam\nis_drug_antiviral\nis_drug_chloro\nis_drug_tradn\nis_drug_oxygen\nis_drug_other\nis_drug_no_resp\nis_drug_none\n\n\n\n\n0\nBRIQUETERIE_000_0001\n2020-10-22\n45\n45 - 64\nAdult\nFemale\nSecondary\nInformal worker\n95\n169\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nBRIQUETERIE_000_0002\n2020-10-24\n55\n45 - 64\nAdult\nMale\nUniversity\nSalaried worker\n96\n185\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\nTSINGAOLIGA_026_0002\n2020-11-11\n31\n30 - 44\nAdult\nFemale\nSecondary\nUnemployed\n66\n169\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n970\nTSINGAOLIGA_026_0003\n2020-11-11\n17\n15 - 29\nChild\nFemale\nSecondary\nUnemployed\n67\n162\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n971 rows × 53 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#使用方括号-选择列",
    "href": "p_untangled_subset_columns_cn.html#使用方括号-选择列",
    "title": "15  选择列子集",
    "section": "15.5 使用方括号 [] 选择列",
    "text": "15.5 使用方括号 [] 选择列\n在 pandas 中,选择列的最常用方法是简单地使用方括号 [] 和列名。例如,要选择 age 和 sex 列,我们输入:\n\nyao[[\"age\", \"sex\"]]\n\n\n\n\n\n\n\n\nage\nsex\n\n\n\n\n0\n45\nFemale\n\n\n1\n55\nMale\n\n\n...\n...\n...\n\n\n969\n31\nFemale\n\n\n970\n17\nFemale\n\n\n\n\n971 rows × 2 columns\n\n\n\n注意双重方括号 [[]]。没有它,您将收到一个错误:\n\nyao[\"age\", \"sex\"]\n\nKeyError: ('age', 'sex')\n如果您想选择单个列,您可以省略双重方括号,但输出将不再是 DataFrame。比较以下内容:\n\nyao[\"age\"] # does not return a DataFrame\n\n0      45\n1      55\n       ..\n969    31\n970    17\nName: age, Length: 971, dtype: int64\n\n\n\nyao[[\"age\"]]  # returns a DataFrame\n\n\n\n\n\n\n\n\nage\n\n\n\n\n0\n45\n\n\n1\n55\n\n\n...\n...\n\n\n969\n31\n\n\n970\n17\n\n\n\n\n971 rows × 1 columns\n\n\n\n\n\n\n\n\n\n关键点\n\n\n\n15.6 存储数据子集\n注意,这些选择并没有修改 DataFrame 本身。如果我们想要修改后的版本,我们需要创建一个新的 DataFrame 来存储子集。例如,下面我们创建了一个仅包含三列的子集:\n\nyao_subset = yao[[\"age\", \"sex\", \"igg_result\"]]\nyao_subset\n\n\n\n\n\n\n\n\nage\nsex\nigg_result\n\n\n\n\n0\n45\nFemale\nNegative\n\n\n1\n55\nMale\nPositive\n\n\n...\n...\n...\n...\n\n\n969\n31\nFemale\nNegative\n\n\n970\n17\nFemale\nNegative\n\n\n\n\n971 rows × 3 columns\n\n\n\n如果我们想要覆盖一个 DataFrame,我们可以将子集重新赋给原始 DataFrame。让我们将 yao_subset DataFrame 覆盖为仅包含 age 列:\n\nyao_subset = yao_subset[[\"age\"]]\nyao_subset\n\n\n\n\n\n\n\n\nage\n\n\n\n\n0\n45\n\n\n1\n55\n\n\n...\n...\n\n\n969\n31\n\n\n970\n17\n\n\n\n\n971 rows × 1 columns\n\n\n\nyao_subset DataFrame 已从 3 列变为 1 列。\n\n\n\n\n\n\n\n\n练习\n\n\n\n15.6.1 练习题:使用 [] 选择列\n\n使用 [] 运算符选择 yao DataFrame 中的 “weight_kg” 和 “height_cm” 变量。将结果赋值给一个名为 yao_weight_height 的新 DataFrame。然后打印这个新 DataFrame。\n\n\n# Your code here\n\n\n\n\n\n\n\n\n\n专业提示\n\n\n\n在 pandas 中,有许多方法可以选择列。在闲暇时间,您可以选择探索 .loc[] 和 .take() 方法,它们提供了额外的功能。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#存储数据子集",
    "href": "p_untangled_subset_columns_cn.html#存储数据子集",
    "title": "15  选择列子集",
    "section": "15.6 存储数据子集",
    "text": "15.6 存储数据子集\n注意,这些选择并没有修改 DataFrame 本身。如果我们想要修改后的版本,我们需要创建一个新的 DataFrame 来存储子集。例如,下面我们创建了一个仅包含三列的子集:\n\nyao_subset = yao[[\"age\", \"sex\", \"igg_result\"]]\nyao_subset\n\n\n\n\n\n\n\n\nage\nsex\nigg_result\n\n\n\n\n0\n45\nFemale\nNegative\n\n\n1\n55\nMale\nPositive\n\n\n...\n...\n...\n...\n\n\n969\n31\nFemale\nNegative\n\n\n970\n17\nFemale\nNegative\n\n\n\n\n971 rows × 3 columns\n\n\n\n如果我们想要覆盖一个 DataFrame,我们可以将子集重新赋给原始 DataFrame。让我们将 yao_subset DataFrame 覆盖为仅包含 age 列:\n\nyao_subset = yao_subset[[\"age\"]]\nyao_subset\n\n\n\n\n\n\n\n\nage\n\n\n\n\n0\n45\n\n\n1\n55\n\n\n...\n...\n\n\n969\n31\n\n\n970\n17\n\n\n\n\n971 rows × 1 columns\n\n\n\nyao_subset DataFrame 已从 3 列变为 1 列。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#使用-drop-排除列",
    "href": "p_untangled_subset_columns_cn.html#使用-drop-排除列",
    "title": "15  选择列子集",
    "section": "15.7 使用 drop() 排除列",
    "text": "15.7 使用 drop() 排除列\n有时删除不需要的列比明确选择需要的列更有用。\n要删除列,我们可以使用带有 columns 参数的 drop() 方法。要删除 age 列,我们输入:\n\nyao.drop(columns=[\"age\"])\n\n\n\n\n\n\n\n\nid\ndate_surveyed\nage_category\nage_category_3\nsex\nhighest_education\noccupation\nweight_kg\nheight_cm\nis_smoker\n...\nis_drug_antibio\nis_drug_hydrocortisone\nis_drug_other_anti_inflam\nis_drug_antiviral\nis_drug_chloro\nis_drug_tradn\nis_drug_oxygen\nis_drug_other\nis_drug_no_resp\nis_drug_none\n\n\n\n\n0\nBRIQUETERIE_000_0001\n2020-10-22\n45 - 64\nAdult\nFemale\nSecondary\nInformal worker\n95\n169\nNon-smoker\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nBRIQUETERIE_000_0002\n2020-10-24\n45 - 64\nAdult\nMale\nUniversity\nSalaried worker\n96\n185\nEx-smoker\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\nTSINGAOLIGA_026_0002\n2020-11-11\n30 - 44\nAdult\nFemale\nSecondary\nUnemployed\n66\n169\nNon-smoker\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n970\nTSINGAOLIGA_026_0003\n2020-11-11\n15 - 29\nChild\nFemale\nSecondary\nUnemployed\n67\n162\nNon-smoker\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n971 rows × 52 columns\n\n\n\n要删除几列:\n\nyao.drop(columns=[\"age\", \"sex\"])\n\n\n\n\n\n\n\n\nid\ndate_surveyed\nage_category\nage_category_3\nhighest_education\noccupation\nweight_kg\nheight_cm\nis_smoker\nis_pregnant\n...\nis_drug_antibio\nis_drug_hydrocortisone\nis_drug_other_anti_inflam\nis_drug_antiviral\nis_drug_chloro\nis_drug_tradn\nis_drug_oxygen\nis_drug_other\nis_drug_no_resp\nis_drug_none\n\n\n\n\n0\nBRIQUETERIE_000_0001\n2020-10-22\n45 - 64\nAdult\nSecondary\nInformal worker\n95\n169\nNon-smoker\nNo\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nBRIQUETERIE_000_0002\n2020-10-24\n45 - 64\nAdult\nUniversity\nSalaried worker\n96\n185\nEx-smoker\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\nTSINGAOLIGA_026_0002\n2020-11-11\n30 - 44\nAdult\nSecondary\nUnemployed\n66\n169\nNon-smoker\nNo\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n970\nTSINGAOLIGA_026_0003\n2020-11-11\n15 - 29\nChild\nSecondary\nUnemployed\n67\n162\nNon-smoker\nNo response\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n971 rows × 51 columns\n\n\n\n同样,注意这并没有修改 DataFrame 本身。如果我们想要修改后的版本,我们需要创建一个新的 DataFrame 来存储子集。例如,下面我们创建了一个删除 age 和 sex 的子集:\n\nyao_subset = yao.drop(columns=[\"age\", \"sex\"])\nyao_subset\n\n\n\n\n\n\n\n\nid\ndate_surveyed\nage_category\nage_category_3\nhighest_education\noccupation\nweight_kg\nheight_cm\nis_smoker\nis_pregnant\n...\nis_drug_antibio\nis_drug_hydrocortisone\nis_drug_other_anti_inflam\nis_drug_antiviral\nis_drug_chloro\nis_drug_tradn\nis_drug_oxygen\nis_drug_other\nis_drug_no_resp\nis_drug_none\n\n\n\n\n0\nBRIQUETERIE_000_0001\n2020-10-22\n45 - 64\nAdult\nSecondary\nInformal worker\n95\n169\nNon-smoker\nNo\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nBRIQUETERIE_000_0002\n2020-10-24\n45 - 64\nAdult\nUniversity\nSalaried worker\n96\n185\nEx-smoker\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\nTSINGAOLIGA_026_0002\n2020-11-11\n30 - 44\nAdult\nSecondary\nUnemployed\n66\n169\nNon-smoker\nNo\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n970\nTSINGAOLIGA_026_0003\n2020-11-11\n15 - 29\nChild\nSecondary\nUnemployed\n67\n162\nNon-smoker\nNo response\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n971 rows × 51 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n15.7.1 练习题:使用 drop() 删除列\n\n从 yao DataFrame 中删除 highest_education 和 consultation 列。将结果赋值给一个名为 yao_no_education_consultation 的新 DataFrame。打印这个新 DataFrame。\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#使用-filter-按正则表达式选择列",
    "href": "p_untangled_subset_columns_cn.html#使用-filter-按正则表达式选择列",
    "title": "15  选择列子集",
    "section": "15.8 使用 filter() 按正则表达式选择列",
    "text": "15.8 使用 filter() 按正则表达式选择列\nfilter() 方法及其 regex 参数提供了一种基于列名中模式来选择列的强大方式。例如,要选择包含字符串 “ig” 的列,我们可以编写:\n\nyao.filter(regex=\"ig\")\n\n\n\n\n\n\n\n\nhighest_education\nweight_kg\nheight_cm\nneighborhood\nigg_result\nigm_result\nsymp_fatigue\n\n\n\n\n0\nSecondary\n95\n169\nBriqueterie\nNegative\nNegative\nNo\n\n\n1\nUniversity\n96\n185\nBriqueterie\nPositive\nNegative\nNo\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\nSecondary\n66\n169\nTsinga Oliga\nNegative\nNegative\nNo\n\n\n970\nSecondary\n67\n162\nTsinga Oliga\nNegative\nNegative\nNo\n\n\n\n\n971 rows × 7 columns\n\n\n\n参数 regex 指定要匹配的模式。Regex 代表正则表达式,指的是定义搜索模式的字符序列。\n要选择以字符串 “ig” 开头的列,我们编写:\n\nyao.filter(regex=\"^ig\")\n\n\n\n\n\n\n\n\nigg_result\nigm_result\n\n\n\n\n0\nNegative\nNegative\n\n\n1\nPositive\nNegative\n\n\n...\n...\n...\n\n\n969\nNegative\nNegative\n\n\n970\nNegative\nNegative\n\n\n\n\n971 rows × 2 columns\n\n\n\n符号 ^ 是一个正则表达式字符,匹配字符串的开头。\n要选择以字符串 “result” 结尾的列,我们可以编写:\n\nyao.filter(regex=\"result$\")\n\n\n\n\n\n\n\n\nigg_result\nigm_result\n\n\n\n\n0\nNegative\nNegative\n\n\n1\nPositive\nNegative\n\n\n...\n...\n...\n\n\n969\nNegative\nNegative\n\n\n970\nNegative\nNegative\n\n\n\n\n971 rows × 2 columns\n\n\n\n字符 $ 是正则表达式,它匹配字符串的结尾。\n\n\n\n\n\n\n专业提示\n\n\n\n正则表达式非常难以记忆,但像 ChatGPT 这样的 LLM 在生成正确的模式方面非常擅长。例如,只需询问:“以 ‘ig’ 开头的字符串的正则表达式是什么?”\n\n\n\n\n\n\n\n\n练习\n\n\n\n15.8.1 练习题:使用正则表达式选择列\n\n选择 yao DataFrame 中所有以 “is_” 开头的列。将结果赋值给一个名为 yao_is_columns 的新 DataFrame。然后打印这个新 DataFrame。\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#使用-rename-更改列名",
    "href": "p_untangled_subset_columns_cn.html#使用-rename-更改列名",
    "title": "15  选择列子集",
    "section": "15.9 使用 rename() 更改列名",
    "text": "15.9 使用 rename() 更改列名\n我们可以使用 rename() 方法更改列名:\n\nyao.rename(columns={\"age\": \"patient_age\", \"sex\": \"patient_sex\"})\n\n\n\n\n\n\n\n\nid\ndate_surveyed\npatient_age\nage_category\nage_category_3\npatient_sex\nhighest_education\noccupation\nweight_kg\nheight_cm\n...\nis_drug_antibio\nis_drug_hydrocortisone\nis_drug_other_anti_inflam\nis_drug_antiviral\nis_drug_chloro\nis_drug_tradn\nis_drug_oxygen\nis_drug_other\nis_drug_no_resp\nis_drug_none\n\n\n\n\n0\nBRIQUETERIE_000_0001\n2020-10-22\n45\n45 - 64\nAdult\nFemale\nSecondary\nInformal worker\n95\n169\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nBRIQUETERIE_000_0002\n2020-10-24\n55\n45 - 64\nAdult\nMale\nUniversity\nSalaried worker\n96\n185\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\nTSINGAOLIGA_026_0002\n2020-11-11\n31\n30 - 44\nAdult\nFemale\nSecondary\nUnemployed\n66\n169\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n970\nTSINGAOLIGA_026_0003\n2020-11-11\n17\n15 - 29\nChild\nFemale\nSecondary\nUnemployed\n67\n162\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n971 rows × 53 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n15.9.1 练习题:使用 rename() 重命名列\n\n将 yao DataFrame 中的 age_category 列重命名为 age_cat。将结果赋值给一个名为 yao_age_cat 的新 DataFrame。然后打印这个新 DataFrame。\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#清理混乱的列名",
    "href": "p_untangled_subset_columns_cn.html#清理混乱的列名",
    "title": "15  选择列子集",
    "section": "15.10 清理混乱的列名",
    "text": "15.10 清理混乱的列名\n要清理列名,您可以在 pandas 中使用带有 str.replace() 方法的正则表达式。\n这里是如何在具有混乱列名的测试 DataFrame 上进行操作。混乱的列名是指包含空格、特殊字符或其他非字母数字字符的名称。\n\ntest_df = pd.DataFrame(\n    {\"good_name\": range(3), \"bad name\": range(3), \"bad*@name*2\": range(3)}\n)\ntest_df\n\n\n\n\n\n\n\n\ngood_name\nbad name\nbad*@name*2\n\n\n\n\n0\n0\n0\n0\n\n\n1\n1\n1\n1\n\n\n2\n2\n2\n2\n\n\n\n\n\n\n\n这样的列名并不理想,因为例如,我们无法像处理干净的名称那样使用点操作符选择它们:\n\ntest_df.good_name  # this works\n\n0    0\n1    1\n2    2\nName: good_name, dtype: int64\n\n\n但这不起作用:\n\ntest_df.bad name\n\n      test_df.bad name\n                 ^\nSyntaxError: invalid syntax\n我们可以使用 str.replace() 方法结合正则表达式自动清理这些名称。\n\nclean_names = test_df.columns.str.replace(r'[^a-zA-Z0-9]', '_', regex=True)\n\n正则表达式 r'[^a-zA-Z0-9]' 匹配任何不是字母(无论是大写还是小写)或数字的字符。str.replace() 方法将这些字符替换为下划线 (‘_’),使列名更易读并可在点表示法中使用。\n现在我们可以用清理过的名称替换 DataFrame 中的列名:\n\ntest_df.columns = clean_names\ntest_df\n\n\n\n\n\n\n\n\ngood_name\nbad_name\nbad__name_2\n\n\n\n\n0\n0\n0\n0\n\n\n1\n1\n1\n1\n\n\n2\n2\n2\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n15.10.1 练习题:使用正则表达式清理列名\n\n考虑下方定义的具有混乱列名的数据框。使用 str.replace() 方法清理列名。\n\n\ncleaning_practice = pd.DataFrame(\n    {\"Aloha\": range(3), \"Bell Chart\": range(3), \"Animals@the zoo\": range(3)}\n)\ncleaning_practice\n\n\n\n\n\n\n\n\nAloha\nBell Chart\nAnimals@the zoo\n\n\n\n\n0\n0\n0\n0\n\n\n1\n1\n1\n1\n\n\n2\n2\n2\n2",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_subset_columns_cn.html#总结",
    "href": "p_untangled_subset_columns_cn.html#总结",
    "title": "15  选择列子集",
    "section": "15.11 总结",
    "text": "15.11 总结\n希望本课向您展示了 pandas 在数据处理方面是多么直观和有用!\n这是系列基础数据整理技术的第一课:下节课再见,了解更多内容。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>选择列子集</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html",
    "href": "p_untangled_query_rows_cn.html",
    "title": "16  查询行",
    "section": "",
    "text": "16.1 介绍\n查询行是数据分析中最常用的操作之一。它允许您过滤数据集,关注特定的子集,从而实现更有针对性和高效的分析。\n在本课程中,我们将探索使用 pandas 对行进行子集操作的各种技术。\n让我们开始吧!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#学习目标",
    "href": "p_untangled_query_rows_cn.html#学习目标",
    "title": "16  查询行",
    "section": "16.2 学习目标",
    "text": "16.2 学习目标\n\n您可以使用 query() 方法从 DataFrame 中保留或删除行。\n您可以使用大于 (&gt;)、小于 (&lt;)、等于 (==)、不等于 (!=)、以及属于 (isin()) 等关系运算符来指定条件。\n您可以使用 & 和 | 组合条件。\n您可以使用 ~ 取反条件。\n您可以使用 isna() 和 notna() 方法。\n您可以使用 str.contains() 根据字符串模式进行查询。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#雅温得-covid-19-数据集",
    "href": "p_untangled_query_rows_cn.html#雅温得-covid-19-数据集",
    "title": "16  查询行",
    "section": "16.3 雅温得 COVID-19 数据集",
    "text": "16.3 雅温得 COVID-19 数据集\n在本课程中,我们将再次使用喀麦隆雅温得进行的 COVID-19 血清学调查的数据。\n您可以从此链接下载数据集:yaounde_data.csv\n您可以在这里了解有关此数据集的更多信息:https://www.nature.com/articles/s41467-021-25946-0\n让我们将数据加载到 pandas DataFrame 中。\n\nimport pandas as pd\n\nyaounde = pd.read_csv(\"data/yaounde_data.csv\")\n# a smaller subset of variables\nyao = yaounde[\n    [\n        \"age\",\n        \"sex\",\n        \"weight_kg\",\n        \"neighborhood\",\n        \"occupation\",\n        \"symptoms\",\n        \"is_smoker\",\n        \"is_pregnant\",\n        \"igg_result\",\n        \"igm_result\",\n    ]\n]\nyao.head()\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n2\n23\nMale\n74\nBriqueterie\nStudent\nNo symptoms\nSmoker\nNaN\nNegative\nNegative\n\n\n3\n20\nFemale\n70\nBriqueterie\nStudent\nRhinitis--Sneezing--Anosmia or ageusia\nNon-smoker\nNo\nPositive\nNegative\n\n\n4\n55\nFemale\n67\nBriqueterie\nTrader--Farmer\nNo symptoms\nNon-smoker\nNo\nPositive\nNegative",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#介绍-query",
    "href": "p_untangled_query_rows_cn.html#介绍-query",
    "title": "16  查询行",
    "section": "16.4 介绍 query()",
    "text": "16.4 介绍 query()\n我们可以使用 query() 方法保留满足一系列条件的行。让我们看一个简单的例子。如果我们只想保留男性记录,我们可以运行:\n\nyao.query('sex == \"Male\"')\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n2\n23\nMale\n74\nBriqueterie\nStudent\nNo symptoms\nSmoker\nNaN\nNegative\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n966\n32\nMale\n54\nTsinga Oliga\nInformal worker\nRhinitis--Sneezing--Diarrhoea\nSmoker\nNaN\nNegative\nNegative\n\n\n968\n35\nMale\n77\nTsinga Oliga\nInformal worker\nHeadache\nSmoker\nNaN\nPositive\nNegative\n\n\n\n\n422 rows × 10 columns\n\n\n\n如您所见,query() 的语法非常简单。(将代码放在引号中可能有点令人惊讶,但它非常易读。)\n注意这里使用的是双等号 (==) 而不是单等号 (=)。== 用于测试相等性,而单等号用于赋值。这是初学者常犯的错误来源,因此要注意。\n我们可以将 query() 与 shape[0] 链接起来,以计算男性受访者的数量。\n\nyao.query('sex == \"Male\"').shape[0]\n\n422\n\n\n\n\n\n\n\n\n提示\n\n\n\nshape 属性返回 DataFrame 中的行数和列数。第一个元素,shape[0],是行数,第二个元素,shape[1],是列数。\n例如:\n\nyao.shape\n\n(971, 10)\n\n\n\nyao.shape[0] # 行数\n\n971\n\n\n\nyao.shape[1]  # 列数\n\n10\n\n\n\n\n\n\n\n\n\n\n关键点\n\n\n\n请注意,这些子集不会修改 DataFrame 本身。如果我们想要一个修改后的版本,我们需要创建一个新的 DataFrame 来存储子集。例如,下面我们创建了一个男性受访者的子集:\n\nyao_male = yao.query('sex == \"Male\"')\nyao_male\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n2\n23\nMale\n74\nBriqueterie\nStudent\nNo symptoms\nSmoker\nNaN\nNegative\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n966\n32\nMale\n54\nTsinga Oliga\nInformal worker\nRhinitis--Sneezing--Diarrhoea\nSmoker\nNaN\nNegative\nNegative\n\n\n968\n35\nMale\n77\nTsinga Oliga\nInformal worker\nHeadache\nSmoker\nNaN\nPositive\nNegative\n\n\n\n\n422 rows × 10 columns\n\n\n\n但为了便于说明,下面的例子中我们只是打印结果,而不存储到变量中。\n\n\n\n\n\n\n\n\n练习\n\n\n\n16.4.1 练习题:筛选怀孕的受访者\n筛选 yao 数据框,保留在调查期间怀孕的受访者(is_pregnant 列包含 “Yes”、“No” 或 NaN)。将结果赋值给一个新的 DataFrame,名为 yao_pregnant。然后打印这个新的 DataFrame。应该有 24 行。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#关系运算符",
    "href": "p_untangled_query_rows_cn.html#关系运算符",
    "title": "16  查询行",
    "section": "16.5 关系运算符",
    "text": "16.5 关系运算符\n上面介绍的 == 运算符是一个“关系”运算符的例子,因为它测试两个值之间的关系。以下是一些更多这些运算符的列表。在查询数据中的行时,您将经常使用它们。\n\n\n\n运算符\n当满足以下条件时为真\n\n\nA == B\nA 等于 B\n\n\nA != B\nA 不等于 B\n\n\nA &lt; B\nA 小于 B\n\n\nA &lt;= B\nA 小于或等于 B\n\n\nA &gt; B\nA 大于 B\n\n\nA &gt;= B\nA 大于或等于 B\n\n\nA.isin([B])\nA 是 B 的一个元素\n\n\n\n让我们看看如何在 query() 中使用这些运算符:\n\nyao.query('sex == \"Female\"')  # 保留 `sex` 为 female 的行\nyao.query('sex != \"Male\"')  # 保留 `sex` 不为 \"Male\" 的行\nyao.query(\"age &lt; 6\")  # 保留年龄小于 6 岁的受访者\nyao.query(\"age &gt;= 70\")  # 保留年龄至少为 70 岁的受访者\n\n# 保留所在社区为 \"Tsinga\" 或 \"Messa\" 的受访者\nyao.query('neighborhood.isin([\"Tsinga\", \"Messa\"])')\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n605\n55\nMale\n70\nMessa\nInformal worker\nNo symptoms\nNon-smoker\nNaN\nNegative\nNegative\n\n\n606\n59\nFemale\n59\nMessa\nTrader\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n902\n25\nFemale\n41\nTsinga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n903\n28\nMale\n69\nTsinga\nTrader\nSneezing--Headache\nEx-smoker\nNaN\nNegative\nNegative\n\n\n\n\n129 rows × 10 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n16.5.1 练习题:筛选儿童\n\n从 yao 中,仅保留儿童(18 岁以下)的受访者。将结果赋值给一个新的 DataFrame,名为 yao_children。应该有 291 行。\n\n\n# Your code here\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n16.5.2 练习题:筛选 Tsinga 和 Messa\n\n使用 isin(),仅保留居住在 “Carriere” 或 “Ekoudou” 社区的受访者。将结果赋值给一个新的 DataFrame,名为 yao_carriere_ekoudou。应该有 426 行。\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#在-query-中访问外部变量",
    "href": "p_untangled_query_rows_cn.html#在-query-中访问外部变量",
    "title": "16  查询行",
    "section": "16.6 在 query() 中访问外部变量",
    "text": "16.6 在 query() 中访问外部变量\nquery() 方法允许您使用 @ 符号访问 DataFrame 外部的变量。当您想在查询条件中使用动态值时,这很有用。\n例如,假设您有变量 min_age 想要在查询中使用。可以这样做:\n\nmin_age = 25\n\n# 使用外部变量进行查询\nyao.query('age &gt;= @min_age')\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n968\n35\nMale\n77\nTsinga Oliga\nInformal worker\nHeadache\nSmoker\nNaN\nPositive\nNegative\n\n\n969\n31\nFemale\n66\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n\n\n524 rows × 10 columns\n\n\n\n此功能在您需要基于可能变化或在运行时确定的值过滤数据时非常有用。\n\n\n\n\n\n\n练习\n\n\n\n16.6.1 练习题:筛选年轻的受访者\n\n从 yao 中,保留年龄小于或等于下面定义的变量 max_age 的受访者。将结果赋值给一个新的 DataFrame,名为 yao_young。应该有 590 行。\n\n\nmax_age = 30\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#使用-和-组合条件",
    "href": "p_untangled_query_rows_cn.html#使用-和-组合条件",
    "title": "16  查询行",
    "section": "16.7 使用 & 和 | 组合条件",
    "text": "16.7 使用 & 和 | 组合条件\n我们可以使用 &(“与”符号)和 |(“或”符号)向 query() 传递多个条件。\n例如,要保留年龄小于 18 岁或大于 65 岁的受访者,可以写:\n\nyao.query(\"age &lt; 18 | age &gt; 65\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n5\n17\nFemale\n65\nBriqueterie\nStudent\nFever--Cough--Rhinitis--Nausea or vomiting--Di...\nNon-smoker\nNo\nNegative\nNegative\n\n\n6\n13\nFemale\n65\nBriqueterie\nStudent\nSneezing\nNon-smoker\nNo\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n962\n15\nMale\n44\nTsinga Oliga\nStudent\nFever--Cough--Rhinitis\nNon-smoker\nNaN\nPositive\nNegative\n\n\n970\n17\nFemale\n67\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo response\nNegative\nNegative\n\n\n\n\n331 rows × 10 columns\n\n\n\n要保留怀孕且曾吸烟的受访者,我们写:\n\nyao.query('is_pregnant == \"Yes\" & is_smoker == \"Ex-smoker\"')\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n273\n25\nFemale\n90\nCarriere\nHome-maker\nCough--Rhinitis--Sneezing\nEx-smoker\nYes\nPositive\nNegative\n\n\n\n\n\n\n\n要保留所有怀孕或曾吸烟的受访者,我们写:\n\nyao.query('is_pregnant == \"Yes\" | is_smoker == \"Ex-smoker\"')\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n14\n42\nMale\n71\nBriqueterie\nTrader\nNo symptoms\nEx-smoker\nNaN\nNegative\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n953\n31\nFemale\n90\nTsinga Oliga\nSalaried worker\nFever--Cough--Sore throat--Headache\nEx-smoker\nNo\nPositive\nNegative\n\n\n967\n23\nFemale\n76\nTsinga Oliga\nInformal worker--Trader\nHeadache\nNon-smoker\nYes\nNegative\nNegative\n\n\n\n\n94 rows × 10 columns\n\n\n\n\n\n\n\n\n\n旁注\n\n\n\n要获取列中的唯一值,您可以使用 value_counts() 方法。\n\nyao.is_smoker.value_counts()\n\nis_smoker\nNon-smoker    859\nEx-smoker      71\nSmoker         39\nName: count, dtype: int64\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n16.7.1 练习题:筛选 IgG 阳性男性\n筛选 yao,仅保留 IgG 阳性的男性。将结果赋值给一个新的 DataFrame,名为 yao_igg_positive_men。查询后应该有 148 行。仔细考虑是使用 & 还是 |。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#使用-运算符取反条件",
    "href": "p_untangled_query_rows_cn.html#使用-运算符取反条件",
    "title": "16  查询行",
    "section": "16.8 使用 ~ 运算符取反条件",
    "text": "16.8 使用 ~ 运算符取反条件\n在 query() 中取反条件,我们使用 ~ 运算符(读作“波浪号”)。\n让我们用这个来删除学生受访者:\n\nyao.query('~ (occupation == \"Student\")')\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\n31\nFemale\n66\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n970\n17\nFemale\n67\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo response\nNegative\nNegative\n\n\n\n\n588 rows × 10 columns\n\n\n\n注意,我们必须将条件括在括号中。\n我们也可以将多个条件括在括号中。\n假设我们要发放一种药物,但由于它是强效药物,我们不希望儿童或体重轻(低于 30kg)的受访者服用。首先,我们可以编写查询来选择儿童和这些体重轻的受访者:\n\nyao.query(\"age &lt; 18 | weight_kg &lt; 30\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n5\n17\nFemale\n65\nBriqueterie\nStudent\nFever--Cough--Rhinitis--Nausea or vomiting--Di...\nNon-smoker\nNo\nNegative\nNegative\n\n\n6\n13\nFemale\n65\nBriqueterie\nStudent\nSneezing\nNon-smoker\nNo\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n962\n15\nMale\n44\nTsinga Oliga\nStudent\nFever--Cough--Rhinitis\nNon-smoker\nNaN\nPositive\nNegative\n\n\n970\n17\nFemale\n67\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo response\nNegative\nNegative\n\n\n\n\n291 rows × 10 columns\n\n\n\n现在,要删除这些个体,我们可以用 ~ 取反条件:\n\nyao.query(\"~ (age &lt; 18 | weight_kg &lt; 30)\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n968\n35\nMale\n77\nTsinga Oliga\nInformal worker\nHeadache\nSmoker\nNaN\nPositive\nNegative\n\n\n969\n31\nFemale\n66\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n\n\n680 rows × 10 columns\n\n\n\n这也可以写成:\n\nyao.query(\"age &gt;= 18 & weight_kg &gt;= 30\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n968\n35\nMale\n77\nTsinga Oliga\nInformal worker\nHeadache\nSmoker\nNaN\nPositive\nNegative\n\n\n969\n31\nFemale\n66\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n\n\n680 rows × 10 columns\n\n\n\n但有时取反条件更易读。\n\n\n\n\n\n\n练习\n\n\n\n16.8.1 练习题:删除吸烟者和50岁以上者\n我们希望避免给年长个体和吸烟者发药。 从 yao 中删除那些年龄超过 50 或是吸烟者的受访者。使用 ~ 来取反条件。将结果赋值给一个新的 DataFrame,名为 yao_dropped。您的输出应该有 810 行。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#nan-值",
    "href": "p_untangled_query_rows_cn.html#nan-值",
    "title": "16  查询行",
    "section": "16.9 NaN 值",
    "text": "16.9 NaN 值\n目前介绍的关系运算符不适用于像 NaN 这样的空值。\n例如,is_pregnant 列对于男性包含 (NA) 值。要保留 is_pregnant 值缺失的行,我们可以尝试编写:\n\nyao.query(\"is_pregnant == NaN\")  # does not work\n\n但这不会工作。这是因为 NaN 是一个不存在的值。因此系统无法评估它是否“等于”或“不等于”任何东西。\n相反,我们可以使用 isna() 方法选择缺失值的行:\n\nyao.query(\"is_pregnant.isna()\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n2\n23\nMale\n74\nBriqueterie\nStudent\nNo symptoms\nSmoker\nNaN\nNegative\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n966\n32\nMale\n54\nTsinga Oliga\nInformal worker\nRhinitis--Sneezing--Diarrhoea\nSmoker\nNaN\nNegative\nNegative\n\n\n968\n35\nMale\n77\nTsinga Oliga\nInformal worker\nHeadache\nSmoker\nNaN\nPositive\nNegative\n\n\n\n\n422 rows × 10 columns\n\n\n\n或者使用 notna() 选择非缺失的行:\n\nyao.query(\"is_pregnant.notna()\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n3\n20\nFemale\n70\nBriqueterie\nStudent\nRhinitis--Sneezing--Anosmia or ageusia\nNon-smoker\nNo\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\n31\nFemale\n66\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n970\n17\nFemale\n67\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo response\nNegative\nNegative\n\n\n\n\n549 rows × 10 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n16.9.1 练习题:保留吸烟状态缺失的记录\n从 yao 数据集中,保留所有吸烟状态记录为 NA 的受访者。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#基于字符串模式的查询",
    "href": "p_untangled_query_rows_cn.html#基于字符串模式的查询",
    "title": "16  查询行",
    "section": "16.10 基于字符串模式的查询",
    "text": "16.10 基于字符串模式的查询\n有时,我们需要基于字符串列是否包含某个子字符串来过滤数据。这在处理多选类型变量时特别有用,因为回应可能包含由分隔符分隔的多个值。让我们通过数据集中 occupation 列来探索这一点。\n首先,让我们看一下 occupation 列中的唯一值:\n\nyao.occupation.value_counts().to_dict()\n\n{'Student': 383,\n 'Informal worker': 189,\n 'Trader': 111,\n 'Unemployed': 68,\n 'Home-maker': 65,\n 'Salaried worker': 54,\n 'Retired': 27,\n 'Student--Informal worker': 13,\n 'Other': 13,\n 'No response': 9,\n 'Farmer': 5,\n 'Informal worker--Trader': 4,\n 'Student--Trader': 4,\n 'Trader--Farmer': 4,\n 'Home-maker--Informal worker': 3,\n 'Home-maker--Trader': 3,\n 'Retired--Informal worker': 3,\n 'Informal worker--Other': 2,\n 'Home-maker--Farmer': 2,\n 'Student--Other': 1,\n 'Farmer--Other': 1,\n 'Trader--Unemployed': 1,\n 'Retired--Other': 1,\n 'Informal worker--Unemployed': 1,\n 'Retired--Trader': 1,\n 'Home-maker--Informal worker--Farmer': 1,\n 'Student--Informal worker--Other': 1,\n 'Informal worker--Trader--Farmer--Other': 1}\n\n\n如我们所见,一些受访者有多个职业,用 “–” 分隔。要基于字符串包含进行查询,我们可以在 query() 中使用 str.contains() 方法。\n\n16.10.1 基本的字符串包含\n要找到所有是学生(无论是单独还是与其他职业结合)的受访者,我们可以使用:\n\nyao.query(\"occupation.str.contains('Student')\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n2\n23\nMale\n74\nBriqueterie\nStudent\nNo symptoms\nSmoker\nNaN\nNegative\nNegative\n\n\n3\n20\nFemale\n70\nBriqueterie\nStudent\nRhinitis--Sneezing--Anosmia or ageusia\nNon-smoker\nNo\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n963\n26\nFemale\n63\nTsinga Oliga\nStudent\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n964\n28\nMale\n76\nTsinga Oliga\nStudent--Informal worker\nNo symptoms\nNon-smoker\nNaN\nNegative\nNegative\n\n\n\n\n402 rows × 10 columns\n\n\n\n此查询将返回 occupation 列中包含 “Student” 字样的所有行,无论它是唯一的职业还是多职业条目的一部分。\n\n\n16.10.2 取反字符串包含\n要找到不是学生的受访者(即职业不包含 “Student”),您可以使用 ~ 运算符:\n\nyao.query(\"~occupation.str.contains('Student')\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n0\n45\nFemale\n95\nBriqueterie\nInformal worker\nMuscle pain\nNon-smoker\nNo\nNegative\nNegative\n\n\n1\n55\nMale\n96\nBriqueterie\nSalaried worker\nNo symptoms\nEx-smoker\nNaN\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n969\n31\nFemale\n66\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n970\n17\nFemale\n67\nTsinga Oliga\nUnemployed\nNo symptoms\nNon-smoker\nNo response\nNegative\nNegative\n\n\n\n\n569 rows × 10 columns\n\n\n\n\n\n16.10.3 将 | 与字符串包含一起使用\n要找到是学生或农民的受访者,我们可以使用:\n\nyao.query(\"occupation.str.contains('Student|Farmer')\")\n\n\n\n\n\n\n\n\nage\nsex\nweight_kg\nneighborhood\noccupation\nsymptoms\nis_smoker\nis_pregnant\nigg_result\nigm_result\n\n\n\n\n2\n23\nMale\n74\nBriqueterie\nStudent\nNo symptoms\nSmoker\nNaN\nNegative\nNegative\n\n\n3\n20\nFemale\n70\nBriqueterie\nStudent\nRhinitis--Sneezing--Anosmia or ageusia\nNon-smoker\nNo\nPositive\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n963\n26\nFemale\n63\nTsinga Oliga\nStudent\nNo symptoms\nNon-smoker\nNo\nNegative\nNegative\n\n\n964\n28\nMale\n76\nTsinga Oliga\nStudent--Informal worker\nNo symptoms\nNon-smoker\nNaN\nNegative\nNegative\n\n\n\n\n416 rows × 10 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n16.10.4 练习题:症状\nsymptoms 列包含受访者报告的一系列症状。\n查询 yao 以找到报告 “Cough” 或 “Fever” 作为症状的受访者。您的答案应该有 219 行。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_query_rows_cn.html#总结",
    "href": "p_untangled_query_rows_cn.html#总结",
    "title": "16  查询行",
    "section": "16.11 总结",
    "text": "16.11 总结\n干得好!您已经学会了如何选择特定的列并基于各种条件过滤行。\n这些技能使您能够专注于相关数据,并创建针对性的子集进行分析。\n接下来,我们将探索如何修改和转换数据,进一步扩展您的数据整理工具包。在下一个课程中再见!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>查询行</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html",
    "href": "p_untangled_transform_variables_cn.html",
    "title": "17  pandas 中的变量转换",
    "section": "",
    "text": "17.1 介绍\n在数据分析中,最常见的任务之一是转换数据集中的变量。pandas 库提供了简洁高效的方法来完成这项任务。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#学习目标",
    "href": "p_untangled_transform_variables_cn.html#学习目标",
    "title": "17  pandas 中的变量转换",
    "section": "17.2 学习目标",
    "text": "17.2 学习目标\n\n理解如何在 DataFrame 中创建新变量。\n学习如何修改现有变量。\n处理修改视图上变量的潜在问题。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#导入",
    "href": "p_untangled_transform_variables_cn.html#导入",
    "title": "17  pandas 中的变量转换",
    "section": "17.3 导入",
    "text": "17.3 导入\n首先,让我们导入 pandas 包:\n\nimport pandas as pd\n\n现在我们将设置一个重要选项,这将帮助我们避免后续的一些警告。在课程的后面部分,我们会更详细地讨论这个选项。\n\npd.options.mode.copy_on_write = True",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#数据集",
    "href": "p_untangled_transform_variables_cn.html#数据集",
    "title": "17  pandas 中的变量转换",
    "section": "17.4 数据集",
    "text": "17.4 数据集\n在本课中,我们将使用包含人口和经济数据的美国县的数据集。您可以通过以下链接下载该数据集:https://github.com/the-graph-courses/idap_book/raw/refs/heads/main/data/us_counties_data.zip。\n下载文件后,解压缩并将 us_counties_data.csv 文件放在项目的 data 文件夹中。\n\ncounties = pd.read_csv(\"data/us_counties_data.csv\")\ncounties\n\n\n\n\n\n\n\n\nstate\ncounty\npop_20\narea_sq_miles\nhh_inc_21\necon_type\nunemp_20\nforeign_born_num\npop_change_2010_2020\npct_emp_change_2010_2021\n\n\n\n\n0\nAL\nAutauga, AL\n58877.0\n594.456107\n66444.0\nNonspecialized\n5.4\n1241.0\n7.758700\n9.0\n\n\n1\nAL\nBaldwin, AL\n233140.0\n1589.836014\n65658.0\nRecreation\n6.2\n7938.0\n27.159356\n28.2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3224\nPR\nYabucoa, PR\n30364.0\n55.214614\nNaN\nNaN\nNaN\nNaN\n-19.807069\n0.1\n\n\n3225\nPR\nYauco, PR\n34062.0\n67.711484\nNaN\nNaN\nNaN\nNaN\n-18.721309\n-5.3\n\n\n\n\n3226 rows × 10 columns\n\n\n\n数据集中的变量包括:\n\nstate: 美国州\ncounty: 美国县\npop_20: 2020 年人口估计\narea_sq_miles: 平方英里面积\nhh_inc_21: 2021 年家庭收入中位数\necon_type: 县的经济类型\npop_change_2010_2020: 2010 年至 2020 年人口变化(%)\nunemp_20: 2020 年失业率(%)\npct_emp_change_2010_2021: 2010 年至 2021 年就业变化百分比(%)\nforeign_born_num: 外国出生居民数量\n\n让我们创建一个仅包含面积和人口列的数据集子集作为示例。\n\n# Small subset for illustration\narea_df = counties[[\"county\", \"area_sq_miles\", \"pop_20\"]]\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n\n\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n\n\n\n\n3226 rows × 3 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#创建新变量",
    "href": "p_untangled_transform_variables_cn.html#创建新变量",
    "title": "17  pandas 中的变量转换",
    "section": "17.5 创建新变量",
    "text": "17.5 创建新变量\n假设我们想将面积从平方英里转换为平方公里。由于 1 平方英里约等于 2.59 平方公里,我们可以通过将 area_sq_miles 列乘以 2.59 来创建一个新变量 area_sq_km。\n\narea_df[\"area_sq_km\"] = area_df[\"area_sq_miles\"] * 2.59\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n1539.641317\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n4117.675277\n\n\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n143.005851\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n175.372743\n\n\n\n\n3226 rows × 4 columns\n\n\n\n语法非常易于理解,虽然有点难以输入。\n使用 area_df[\"area_sq_km\"],我们表示要创建一个名为 area_sq_km 的新列,然后 area_df[\"area_sq_miles\"] * 2.59 是计算该新列值的表达式。\n让我们再添加一个变量,这次以公顷为单位。转换因子是 1 平方英里 = 259 公顷。\n\n# Convert area to hectares as well\narea_df[\"area_hectares\"] = area_df[\"area_sq_miles\"] * 259\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\narea_hectares\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n1539.641317\n153964.131747\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n4117.675277\n411767.527703\n\n\n...\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n143.005851\n14300.585058\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n175.372743\n17537.274254\n\n\n\n\n3226 rows × 5 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n17.5.1 练习题:以英亩为单位的面积\n使用 area_df 数据集,通过将 area_sq_miles 变量乘以 640,创建一个名为 area_acres 的新列。将结果存回 area_df 并显示 DataFrame。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#修改现有变量",
    "href": "p_untangled_transform_variables_cn.html#修改现有变量",
    "title": "17  pandas 中的变量转换",
    "section": "17.6 修改现有变量",
    "text": "17.6 修改现有变量\n假设我们想将 area_sq_km 变量四舍五入到小数点后一位。我们可以在 area_sq_km 列上调用 round 方法。\n\narea_df[\"area_sq_km\"] = area_df[\"area_sq_km\"].round(1)\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\narea_hectares\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n1539.6\n153964.131747\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n4117.7\n411767.527703\n\n\n...\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n143.0\n14300.585058\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n175.4\n17537.274254\n\n\n\n\n3226 rows × 5 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n17.6.1 练习题:对 area_acres 进行四舍五入\n使用 area_df 数据集,将 area_acres 变量四舍五入到小数点后一位。更新 DataFrame area_df 并显示它。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#多变量计算",
    "href": "p_untangled_transform_variables_cn.html#多变量计算",
    "title": "17  pandas 中的变量转换",
    "section": "17.7 多变量计算",
    "text": "17.7 多变量计算\n我们可以基于多个现有变量创建新变量。\n例如,让我们计算每平方公里的人口密度。\n\narea_df[\"pop_per_sq_km\"] = area_df[\"pop_20\"] / area_df[\"area_sq_km\"]\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\narea_hectares\npop_per_sq_km\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n1539.6\n153964.131747\n38.241751\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n4117.7\n411767.527703\n56.618986\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n143.0\n14300.585058\n212.335664\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n175.4\n17537.274254\n194.196123\n\n\n\n\n3226 rows × 6 columns\n\n\n\n我们可以将在此输出后添加 round 方法,将结果四舍五入到小数点后一位。\n\narea_df[\"pop_per_sq_km\"] = (area_df[\"pop_20\"] / area_df[\"area_sq_km\"]).round(1)\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\narea_hectares\npop_per_sq_km\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n1539.6\n153964.131747\n38.2\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n4117.7\n411767.527703\n56.6\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n143.0\n14300.585058\n212.3\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n175.4\n17537.274254\n194.2\n\n\n\n\n3226 rows × 6 columns\n\n\n\n或者,如果您愿意,您可以将其分两步完成:\n\narea_df[\"pop_per_sq_km\"] = area_df[\"pop_20\"] / area_df[\"area_sq_km\"]\narea_df[\"pop_per_sq_km\"] = area_df[\"pop_per_sq_km\"].round(1)\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\narea_hectares\npop_per_sq_km\n\n\n\n\n0\nAutauga, AL\n594.456107\n58877.0\n1539.6\n153964.131747\n38.2\n\n\n1\nBaldwin, AL\n1589.836014\n233140.0\n4117.7\n411767.527703\n56.6\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n55.214614\n30364.0\n143.0\n14300.585058\n212.3\n\n\n3225\nYauco, PR\n67.711484\n34062.0\n175.4\n17537.274254\n194.2\n\n\n\n\n3226 rows × 6 columns\n\n\n\n在计算人口密度之后,我们可能希望根据这个新变量对 DataFrame 进行排序。让我们按降序排序。\n\n# Sort by population density in descending order\narea_df = area_df.sort_values(\"pop_per_sq_km\", ascending=False)\narea_df\n\n\n\n\n\n\n\n\ncounty\narea_sq_miles\npop_20\narea_sq_km\narea_hectares\npop_per_sq_km\n\n\n\n\n1863\nNew York, NY\n22.656266\n1687834.0\n58.7\n5867.972888\n28753.6\n\n\n1856\nKings, NY\n69.376570\n2727393.0\n179.7\n17968.531752\n15177.5\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n98\nWrangell-Petersburg, AK\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2921\nBedford, VA\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n3226 rows × 6 columns\n\n\n\n我们看到纽约县在数据集中拥有最高的人口密度。\n\n\n\n\n\n\n练习\n\n\n\n17.7.1 练习题:计算外籍出生人口百分比\n使用 counties 数据集计算每个县的外籍出生居民百分比。变量 foreign_born_num 显示外籍出生居民的数量,pop_20 显示总人口。按外籍出生居民百分比的降序对 DataFrame 进行排序。哪两个县的外籍出生居民比例最高?\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#创建布尔变量",
    "href": "p_untangled_transform_variables_cn.html#创建布尔变量",
    "title": "17  pandas 中的变量转换",
    "section": "17.8 创建布尔变量",
    "text": "17.8 创建布尔变量\n有时创建布尔变量以根据条件对数据进行分类或标记是很有用的。布尔变量是仅取两个值的变量:True 或 False。\n考虑 counties 数据集中的 pop_change_2010_2020 变量,它显示了 2010 年至 2020 年之间的人口百分比变化。\n\nchanges_df = counties[[\"county\", \"pop_change_2010_2020\", \"pct_emp_change_2010_2021\"]]\nchanges_df\n\n\n\n\n\n\n\n\ncounty\npop_change_2010_2020\npct_emp_change_2010_2021\n\n\n\n\n0\nAutauga, AL\n7.758700\n9.0\n\n\n1\nBaldwin, AL\n27.159356\n28.2\n\n\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n-19.807069\n0.1\n\n\n3225\nYauco, PR\n-18.721309\n-5.3\n\n\n\n\n3226 rows × 3 columns\n\n\n\n我们可能想创建一个布尔变量来标记人口是否增加。为此,如果人口增加,我们将 pop_increase 变量设为 True,否则设为 False。\n运行表达式 changes_df[\"pop_change_2010_2020\"] &gt; 0 会返回一系列布尔值:\n\nchanges_df[\"pop_change_2010_2020\"] &gt; 0\n\n0        True\n1        True\n        ...  \n3224    False\n3225    False\nName: pop_change_2010_2020, Length: 3226, dtype: bool\n\n\n我们可以将这一系列布尔值赋给 pop_increase 变量。\n\nchanges_df[\"pop_increase\"] = changes_df[\"pop_change_2010_2020\"] &gt; 0\nchanges_df\n\n\n\n\n\n\n\n\ncounty\npop_change_2010_2020\npct_emp_change_2010_2021\npop_increase\n\n\n\n\n0\nAutauga, AL\n7.758700\n9.0\nTrue\n\n\n1\nBaldwin, AL\n27.159356\n28.2\nTrue\n\n\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n-19.807069\n0.1\nFalse\n\n\n3225\nYauco, PR\n-18.721309\n-5.3\nFalse\n\n\n\n\n3226 rows × 4 columns\n\n\n\n同样,我们可以为就业变化创建布尔变量 emp_increase。\n\nchanges_df[\"emp_increase\"] = changes_df[\"pct_emp_change_2010_2021\"] &gt; 0\nchanges_df\n\n\n\n\n\n\n\n\ncounty\npop_change_2010_2020\npct_emp_change_2010_2021\npop_increase\nemp_increase\n\n\n\n\n0\nAutauga, AL\n7.758700\n9.0\nTrue\nTrue\n\n\n1\nBaldwin, AL\n27.159356\n28.2\nTrue\nTrue\n\n\n...\n...\n...\n...\n...\n...\n\n\n3224\nYabucoa, PR\n-19.807069\n0.1\nFalse\nTrue\n\n\n3225\nYauco, PR\n-18.721309\n-5.3\nFalse\nFalse\n\n\n\n\n3226 rows × 5 columns\n\n\n\n现在,我们可以筛选出人口增加但就业减少的县。\n\n# Counties where population increased but employment decreased\npop_up_emp_down = changes_df.query(\"pop_increase == True & emp_increase == False\")\npop_up_emp_down\n\n\n\n\n\n\n\n\ncounty\npop_change_2010_2020\npct_emp_change_2010_2021\npop_increase\nemp_increase\n\n\n\n\n71\nBethel, AK\n9.716099\n-0.7\nTrue\nFalse\n\n\n75\nDillingham, AK\n0.206313\n-16.1\nTrue\nFalse\n\n\n...\n...\n...\n...\n...\n...\n\n\n3127\nCampbell, WY\n1.935708\n-14.8\nTrue\nFalse\n\n\n3137\nNatrona, WY\n5.970842\n-0.2\nTrue\nFalse\n\n\n\n\n242 rows × 5 columns\n\n\n\n您也可以简写如下:\n\n# Counties where population increased but employment decreased\npop_up_emp_down = changes_df.query(\"pop_increase & ~(emp_increase)\")\npop_up_emp_down\n\n\n\n\n\n\n\n\ncounty\npop_change_2010_2020\npct_emp_change_2010_2021\npop_increase\nemp_increase\n\n\n\n\n71\nBethel, AK\n9.716099\n-0.7\nTrue\nFalse\n\n\n75\nDillingham, AK\n0.206313\n-16.1\nTrue\nFalse\n\n\n...\n...\n...\n...\n...\n...\n\n\n3127\nCampbell, WY\n1.935708\n-14.8\nTrue\nFalse\n\n\n3137\nNatrona, WY\n5.970842\n-0.2\nTrue\nFalse\n\n\n\n\n242 rows × 5 columns\n\n\n\n有几个这样的县,这些县可能值得进一步分析。\n\n\n\n\n\n\n练习\n\n\n\n17.8.1 练习题:按外籍出生人口分类县\n在之前的练习题中,我们计算了每个县的外籍出生居民百分比。现在,创建一个布尔变量 foreign_born_pct_gt_30,如果百分比大于 30%,则为 True。\n完成后,查询 DataFrame 以仅显示 foreign_born_pct_gt_30 为 True 的县。您应该得到 24 行。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#写时复制警告",
    "href": "p_untangled_transform_variables_cn.html#写时复制警告",
    "title": "17  pandas 中的变量转换",
    "section": "17.9 写时复制警告",
    "text": "17.9 写时复制警告\n在本课的前面部分,我们启用了“写时复制”模式。让我们看看当此功能被禁用时会发生什么。\n\npd.set_option(\"mode.copy_on_write\", False)\n\n# Create a small subset of our data\nsubset = counties.query(\"state == 'AL'\")\n\nsubset\n\n\n\n\n\n\n\n\nstate\ncounty\npop_20\narea_sq_miles\nhh_inc_21\necon_type\nunemp_20\nforeign_born_num\npop_change_2010_2020\npct_emp_change_2010_2021\n\n\n\n\n0\nAL\nAutauga, AL\n58877.0\n594.456107\n66444.0\nNonspecialized\n5.4\n1241.0\n7.758700\n9.0\n\n\n1\nAL\nBaldwin, AL\n233140.0\n1589.836014\n65658.0\nRecreation\n6.2\n7938.0\n27.159356\n28.2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n65\nAL\nWilcox, AL\n10518.0\n887.857611\n30071.0\nManufacturing\n16.2\n36.0\n-9.168809\n3.8\n\n\n66\nAL\nWinston, AL\n23491.0\n612.998002\n47176.0\nManufacturing\n5.2\n408.0\n-3.855579\n18.1\n\n\n\n\n67 rows × 10 columns\n\n\n\n当我们尝试修改子集时,会收到一个警告:\n\n# Modify the subset\nsubset['unemp_20'] = subset['unemp_20'].round(0)\n\n/var/folders/vr/shb6ffvj2rl61kh7qqczhrgh0000gp/T/ipykernel_61682/317403666.py:2: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n虽然我们不会深入探讨此警告的技术细节(因为它涉及复杂的 pandas 内部机制),但值得注意的是,该警告包含一个指向 pandas 文档的链接。该文档包含了我们在课程开始时使用的设置。\n如果您需要再次参考此设置,您只需点击警告消息中的链接即可访问文档。文档页面还提供了有关此特定问题的更详细信息。\n另请注意,从 Pandas 3.0(可能在 2025 年发布)开始,将移除此警告,因为默认行为将改为写时复制。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_transform_variables_cn.html#总结",
    "href": "p_untangled_transform_variables_cn.html#总结",
    "title": "17  pandas 中的变量转换",
    "section": "17.10 总结",
    "text": "17.10 总结\n转换数据是任何数据分析工作流程中的基本步骤。pandas 使得使用简单直观的语法在您的 DataFrame 中创建和修改变量变得直接。\n在本课中,您学习了如何:\n\n通过分配给新列创建新变量。\n修改现有变量。\n执行涉及多个变量的计算。\n基于条件创建布尔变量。\n\n祝贺您完成本课!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>pandas 中的变量转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html",
    "href": "p_untangled_conditional_transforms_cn.html",
    "title": "18  变量的条件性转换",
    "section": "",
    "text": "18.1 介绍\n在上一课中,你学习了 pandas 中数据转换的基础知识。\n在本课中,我们将探讨如何使用 replace() 和自定义函数等方法在 pandas 中条件性地转换变量。\n条件性转换在你需要根据特定条件重新编码变量或创建新变量时非常重要。\n让我们开始吧!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#学习目标",
    "href": "p_untangled_conditional_transforms_cn.html#学习目标",
    "title": "18  变量的条件性转换",
    "section": "18.2 学习目标",
    "text": "18.2 学习目标\n完成本课后,你将能够:\n\n使用 replace() 和字典根据条件转换或创建新变量。\n知道如何在 replace() 转换中处理 NaN 值。\n能够定义和应用自定义函数来重新编码变量。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#包",
    "href": "p_untangled_conditional_transforms_cn.html#包",
    "title": "18  变量的条件性转换",
    "section": "18.3 包",
    "text": "18.3 包\n本课将需要 pandas、numpy、plotly.express 和 vega_datasets:\n\nimport pandas as pd\nimport numpy as np\nimport vega_datasets as vd\nimport plotly.express as px",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#replace-简介",
    "href": "p_untangled_conditional_transforms_cn.html#replace-简介",
    "title": "18  变量的条件性转换",
    "section": "18.4 replace() 简介",
    "text": "18.4 replace() 简介\n数据整理中的一个常见任务是根据某些条件替换列中的值。pandas 中的 replace() 方法是一个多功能的工具。\n在 tips 数据集中,day 列包含简写的星期名称:\n\ntips = px.data.tips()\ntips['day'].unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n我们的目标是用完整的星期名称替换这些缩写。\n我们可以创建一个将缩写名称映射到完整名称的字典:\n\nday_mapping = {\n    \"Sun\": \"Sunday\",\n    \"Sat\": \"Saturday\",\n    \"Fri\": \"Friday\",\n    \"Thur\": \"Thursday\"\n}\n\n现在,我们使用带有字典的 replace() 方法:\n\ntips['day_full'] = tips['day'].replace(day_mapping)\ntips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nday_full\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\nSunday\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\nSunday\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\nSunday\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\nSaturday\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\nSaturday\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\nThursday\n\n\n\n\n244 rows × 8 columns\n\n\n\n或者,我们可以在 replace() 方法中直接进行替换,而无需明确地定义字典:\n\ntips['day_full'] = tips['day'].replace({\n    \"Sun\": \"Sunday\",\n    \"Sat\": \"Saturday\",\n    \"Fri\": \"Friday\",\n    \"Thur\": \"Thursday\"\n})\ntips[['day', 'day_full']].head()\n\n\n\n\n\n\n\n\nday\nday_full\n\n\n\n\n0\nSun\nSunday\n\n\n1\nSun\nSunday\n\n\n2\nSun\nSunday\n\n\n3\nSun\nSunday\n\n\n4\nSun\nSunday\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n18.5 练习题:缩写性别\n使用 tips 数据集,将 sex 列中的值缩写性别:\n\n将 \"Female\" 替换为 \"F\"。\n将 \"Male\" 替换为 \"M\"。\n\n将结果赋值给一个名为 sex_abbr 的新列并显示前几行。\n\n# Your code here:",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#练习题缩写性别",
    "href": "p_untangled_conditional_transforms_cn.html#练习题缩写性别",
    "title": "18  变量的条件性转换",
    "section": "18.5 练习题:缩写性别",
    "text": "18.5 练习题:缩写性别\n使用 tips 数据集,将 sex 列中的值缩写性别:\n\n将 \"Female\" 替换为 \"F\"。\n将 \"Male\" 替换为 \"M\"。\n\n将结果赋值给一个名为 sex_abbr 的新列并显示前几行。\n\n# Your code here:",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#使用-replace-处理缺失值",
    "href": "p_untangled_conditional_transforms_cn.html#使用-replace-处理缺失值",
    "title": "18  变量的条件性转换",
    "section": "18.6 使用 replace() 处理缺失值",
    "text": "18.6 使用 replace() 处理缺失值\n有时,你的数据集中可能包含缺失值(NaN 或 None),你希望用占位符或特定值替换它们。replace() 方法可以处理这种情况。\n让我们检查 vega_datasets 中 movies 数据集的 Creative_Type 列:\n\nmovies = vd.data.movies()\nmovies['Creative_Type'].value_counts(dropna=False)\n\nCreative_Type\nContemporary Fiction       1453\nNone                        446\nHistorical Fiction          350\n                           ... \nFactual                      49\nSuper Hero                   49\nMultiple Creative Types       1\nName: count, Length: 10, dtype: int64\n\n\n注意 Creative_Type 列中有一些 None 值。\n让我们将 None 替换为 \"Unknown/Unclear\":\n\nmovies['Creative_Type'] = movies['Creative_Type'].replace({\n    None: \"Unknown/Unclear\", # 👈 在这一行,None 是键\n})\n\n现在,让我们验证替换:\n\nmovies['Creative_Type'].value_counts(dropna=False)\n\nCreative_Type\nContemporary Fiction       1453\nUnknown/Unclear             446\nHistorical Fiction          350\n                           ... \nFactual                      49\nSuper Hero                   49\nMultiple Creative Types       1\nName: count, Length: 10, dtype: int64\n\n\n虽然 None 通常用于表示缺失的字符串,NaN 用于表示缺失的数字。考虑 US_DVD_Sales 列:\n\nmovies.query(\"US_DVD_Sales.isna()\").shape # 检查缺失值的数量\n\n(2637, 16)\n\n\n\nmovies['US_DVD_Sales'].tail(10) # 查看最后 10 个值。有些缺失。\n\n3191     3273039.0\n3192    22025352.0\n3193           NaN\n           ...    \n3198     6679409.0\n3199           NaN\n3200           NaN\nName: US_DVD_Sales, Length: 10, dtype: float64\n\n\n我们可以使用 replace() 将 NaN 替换为 0:\n\nmovies['US_DVD_Sales'] = movies['US_DVD_Sales'].replace({\n    np.nan: 0 # 👈 pandas 中用 `np.nan` 表示 `NaN`\n})\n\n让我们验证替换:\n\nmovies['US_DVD_Sales'].tail(10)\n\n3191     3273039.0\n3192    22025352.0\n3193           0.0\n           ...    \n3198     6679409.0\n3199           0.0\n3200           0.0\nName: US_DVD_Sales, Length: 10, dtype: float64\n\n\n\nmovies.query(\"US_DVD_Sales.isna()\").shape\n\n(0, 16)",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#练习题标准化-mpaa-分级",
    "href": "p_untangled_conditional_transforms_cn.html#练习题标准化-mpaa-分级",
    "title": "18  变量的条件性转换",
    "section": "18.7 练习题:标准化 MPAA 分级",
    "text": "18.7 练习题:标准化 MPAA 分级\n在 movies 数据集中,MPAA_Rating 列包含电影分级。有些条目是 None 或 \"Not Rated\"。将 None 和 \"Not Rated\" 都替换为 \"Unrated\"。\n然后,使用 value_counts() 查看有多少电影未分级。该类别下应该有 699 部电影。\n\n# Your code here:",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#使用自定义函数对数值数据分类",
    "href": "p_untangled_conditional_transforms_cn.html#使用自定义函数对数值数据分类",
    "title": "18  变量的条件性转换",
    "section": "18.8 使用自定义函数对数值数据分类",
    "text": "18.8 使用自定义函数对数值数据分类\n回想我们上一课的内容,我们可以使用带有条件逻辑的自定义函数来转换变量。例如,我们可以根据以下标准将 US_Gross 列分类为三类:\n\n如果值小于 1000 万,类别为 \"Low\"。\n如果值在 1000 万到 5000 万之间,类别为 \"Medium\"。\n如果值大于 5000 万,类别为 \"High\"。\n\n\ndef categ_gross(gross):\n    if gross &lt; 10000000:\n        return \"Low\"\n    elif gross &gt;= 10000000 and gross &lt;= 50000000:\n        return \"Medium\"\n    elif gross &gt; 50000000:\n        return \"High\"\n    else:\n        return None \n\n\ncateg_gross_vec = np.vectorize(categ_gross)\n\n\n\n\n\n\n\n附注\n\n\n\n在上述情况下,np.vectorize 函数将返回 None 作为字符串。为了强制使用 None 类型,你可以使用 otypes 参数:\n\ncateg_gross_vec = np.vectorize(categ_gross, otypes=[object])\n\n\n\n现在我们可以将其应用于整个列:\n\nmovies['Gross_Category'] = categ_gross_vec(movies['US_Gross'])\nmovies['Gross_Category'].value_counts(dropna=False)\n\nGross_Category\nMedium    1241\nLow       1046\nHigh       907\nNone         7\nName: count, dtype: int64\n\n\n这也可以通过 pd.cut()、np.where() 和 np.select() 实现。但自定义函数方法是最灵活的。下面我们将看到如何将其扩展到更复杂的条件。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#使用自定义函数进行复杂转换",
    "href": "p_untangled_conditional_transforms_cn.html#使用自定义函数进行复杂转换",
    "title": "18  变量的条件性转换",
    "section": "18.9 使用自定义函数进行复杂转换",
    "text": "18.9 使用自定义函数进行复杂转换\n自定义函数的灵活性可以轻松扩展到更复杂的条件转换。\n例如,假设我们想根据美国和全球的总收入将超级英雄电影标记为“美国动作电影”或“全球动作电影”。\n\n对于超级英雄电影,如果美国总收入和全球总收入相同(表明销售仅在美国),则电影被标记为美国动作电影。\n对于超级英雄电影,如果全球总收入大于美国总收入,电影被标记为全球动作电影。\n对于所有其他电影,保留空白标记。\n\n我们可以定义一个接受三个参数并返回适当标记的函数:\n\n# 定义根据条件标记电影的函数\ndef flag_movie(movie_type, us, worldwide):\n    if movie_type == 'Super Hero' and us == worldwide:\n        return 'US action movie'\n    elif movie_type == 'Super Hero' and worldwide &gt; us:\n        return 'Global action movie'\n    else:\n        return None\n\n让我们用几个值集来测试它:\n\nprint(flag_movie(movie_type='Super Hero', us=100, worldwide=100))\nprint(flag_movie(movie_type='Super Hero', us=100, worldwide=200))\nprint(flag_movie(movie_type='Comedy', us=100, worldwide=100))\n\nUS action movie\nGlobal action movie\nNone\n\n\n现在,让我们将其向量化:\n\nflag_movie_vec = np.vectorize(flag_movie)\n\n我们现在可以将其应用到列:\n\nmovies['Action_Flag'] = flag_movie_vec(movies['Creative_Type'], movies['US_Gross'], movies['Worldwide_Gross'])\nmovies\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\nGross_Category\nAction_Flag\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\n0.0\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nUnknown/Unclear\nNone\nNaN\n6.1\n1071.0\nLow\nNone\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\n0.0\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nUnknown/Unclear\nNone\nNaN\n6.9\n207.0\nLow\nNone\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\n0.0\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nUnknown/Unclear\nNone\nNaN\n6.8\n865.0\nLow\nNone\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3198\nZoom\n11989328.0\n12506188.0\n6679409.0\n35000000.0\nAug 11 2006\nPG\nNaN\nSony Pictures\nBased on Comic/Graphic Novel\nAdventure\nSuper Hero\nPeter Hewitt\n3.0\n3.4\n7424.0\nMedium\nGlobal action movie\n\n\n3199\nThe Legend of Zorro\n45575336.0\n141475336.0\n0.0\n80000000.0\nOct 28 2005\nPG\n129.0\nSony Pictures\nRemake\nAdventure\nHistorical Fiction\nMartin Campbell\n26.0\n5.7\n21161.0\nMedium\nNone\n\n\n3200\nThe Mask of Zorro\n93828745.0\n233700000.0\n0.0\n65000000.0\nJul 17 1998\nPG-13\n136.0\nSony Pictures\nRemake\nAdventure\nHistorical Fiction\nMartin Campbell\n82.0\n6.7\n4789.0\nHigh\nNone\n\n\n\n\n3201 rows × 18 columns\n\n\n\n要查看基于我们标记的电影类别分布,我们可以使用 value_counts():\n\nmovies['Action_Flag'].value_counts(dropna=False)\n\nAction_Flag\nNone                   3152\nGlobal action movie      42\nUS action movie           7\nName: count, dtype: int64\n\n\n\n18.9.1 练习:根据评分标记电影\n在 movies 数据集中,根据烂番茄(Rotten Tomatoes)和 IMDB 评分将电影标记为影评人友好或商业化。\n\n如果烂番茄评分高于 70% 且 IMDB 评分低于 5,电影被标记为影评人友好。\n如果烂番茄评分低于 50% 且 IMDB 评分高于 7,电影被标记为商业化。\n否则,电影分类为其他。\n统计有多少电影是影评人友好和商业化。应该有 13 部影评人友好电影和 33 部商业化电影。你认识其中的任何电影吗?\n\n\n# Your code here:",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_conditional_transforms_cn.html#总结",
    "href": "p_untangled_conditional_transforms_cn.html#总结",
    "title": "18  变量的条件性转换",
    "section": "18.10 总结",
    "text": "18.10 总结\n在本课中,你学习了如何使用以下方法在 pandas 中有条件地转换变量:\n\n使用带有字典的 replace() 方法来映射和替换特定值。\n在替换过程中处理缺失值(NaN 或 None)。\n定义自定义函数并应用它们来处理复杂条件。\n\n这些技术是数据清洗和预处理的强大工具,使你能够重新塑造数据以满足分析需求。\n下次见!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>变量的条件性转换</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html",
    "href": "p_untangled_groupby_agg_cn.html",
    "title": "19  数据分组和汇总",
    "section": "",
    "text": "19.1 介绍\n在本课程中,我们将探讨两个强大的 pandas 方法:agg() 和 groupby()。这些工具将使您能够轻松提取汇总统计信息并对分组数据执行操作。\n汇总统计量是描述一系列值(通常是数据集中的一列)的单个值(如平均值或中位数)。\n让我们看看如何使用它们!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#学习目标",
    "href": "p_untangled_groupby_agg_cn.html#学习目标",
    "title": "19  数据分组和汇总",
    "section": "19.2 学习目标",
    "text": "19.2 学习目标\n\n您可以使用 pandas.DataFrame.agg() 从数据集中提取汇总统计信息。\n您可以使用 pandas.DataFrame.groupby() 按一个或多个变量对数据进行分组,然后对其执行操作。\n您可以将自定义函数传递给 agg() 以计算汇总统计信息。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#库",
    "href": "p_untangled_groupby_agg_cn.html#库",
    "title": "19  数据分组和汇总",
    "section": "19.3 库",
    "text": "19.3 库\n运行以下代码导入必要的库:\n\nimport pandas as pd\nimport numpy as np",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#雅温得-covid-19-数据集",
    "href": "p_untangled_groupby_agg_cn.html#雅温得-covid-19-数据集",
    "title": "19  数据分组和汇总",
    "section": "19.4 雅温得 COVID-19 数据集",
    "text": "19.4 雅温得 COVID-19 数据集\n在本课程中,我们将再次使用喀麦隆雅温得进行的 COVID-19 血清调查数据的一个子集。\n您可以从此链接下载数据集:yaounde_mini.csv\n\nyao = pd.read_csv(\"data/yaounde_mini.csv\")\nyao\n\n\n\n\n\n\n\n\nage\nage_category_3\nsex\nweight_kg\nheight_cm\nneighborhood\nis_smoker\nis_pregnant\noccupation\ntreatment_combinations\nsymptoms\nn_days_miss_work\nn_bedridden_days\nhighest_education\nigg_result\n\n\n\n\n0\n45\nAdult\nFemale\n95\n169\nBriqueterie\nNon-smoker\nNo\nInformal worker\nParacetamol\nMuscle pain\n0.0\n0.0\nSecondary\nNegative\n\n\n1\n55\nAdult\nMale\n96\n185\nBriqueterie\nEx-smoker\nNaN\nSalaried worker\nNaN\nNo symptoms\nNaN\nNaN\nUniversity\nPositive\n\n\n2\n23\nAdult\nMale\n74\n180\nBriqueterie\nSmoker\nNaN\nStudent\nNaN\nNo symptoms\nNaN\nNaN\nUniversity\nNegative\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n968\n35\nAdult\nMale\n77\n168\nTsinga Oliga\nSmoker\nNaN\nInformal worker\nParacetamol\nHeadache\n0.0\n0.0\nUniversity\nPositive\n\n\n969\n31\nAdult\nFemale\n66\n169\nTsinga Oliga\nNon-smoker\nNo\nUnemployed\nNaN\nNo symptoms\nNaN\nNaN\nSecondary\nNegative\n\n\n970\n17\nChild\nFemale\n67\n162\nTsinga Oliga\nNon-smoker\nNo response\nUnemployed\nNaN\nNo symptoms\nNaN\nNaN\nSecondary\nNegative\n\n\n\n\n971 rows × 15 columns\n\n\n\n您可以在这里了解更多关于该数据集的信息:https://www.nature.com/articles/s41467-021-25946-0",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#介绍-pandas.dataframe.agg",
    "href": "p_untangled_groupby_agg_cn.html#介绍-pandas.dataframe.agg",
    "title": "19  数据分组和汇总",
    "section": "19.5 介绍 pandas.DataFrame.agg()",
    "text": "19.5 介绍 pandas.DataFrame.agg()\n首先,让我们考虑如何在不使用 agg() 的情况下获取简单的汇总统计信息,然后我们将考虑为什么您应该实际使用 agg()。\n假设有人要求您找出 yao 数据框中受访者的平均年龄。您可以通过调用 yao 数据框的 age 列上的 mean() 方法来实现:\n\nyao[[\"age\"]].mean()\n\nage    29.017508\ndtype: float64\n\n\n现在,让我们看看如何使用 agg() 来做到这一点。\n\nyao.agg(mean_age=('age', 'mean'))\n\n\n\n\n\n\n\n\nage\n\n\n\n\nmean_age\n29.017508\n\n\n\n\n\n\n\n这种语法的结构是:\n\ndataframe.agg(summary_name=(\"COLUMN_TO_SUMMARIZE\", \"SUMMARY_FUNCTION\"))\n\n这一部分 (\"COLUMN_TO_SUMMARIZE\", \"SUMMARY_FUNCTION\") 被称为元组。元组的第一个元素是要汇总的列的名称,第二个元素是要应用于该列的汇总函数。\n语法更为复杂,但正如您稍后将看到的,它更加强大,因为它允许您计算多个汇总统计信息,并按组计算统计数据。\n\n让我们看看如何在单个 agg() 语句中计算多个汇总统计信息。如果您想要年龄的平均值和中位数,您可以运行:\n\nyao.agg(mean_age=(\"age\", \"mean\"), median_age=(\"age\", \"median\"))\n\n\n\n\n\n\n\n\nage\n\n\n\n\nmean_age\n29.017508\n\n\nmedian_age\n26.000000\n\n\n\n\n\n\n\n很好,现在试试下面的练习题。\n\n\n\n\n\n\n练习\n\n\n\n19.6 练习题:平均值和中位数体重\n使用 agg() 和相关的汇总函数,从 yao 数据框的 weight_kg 变量中获取受访者体重的平均值和中位数。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#练习题平均值和中位数体重",
    "href": "p_untangled_groupby_agg_cn.html#练习题平均值和中位数体重",
    "title": "19  数据分组和汇总",
    "section": "19.6 练习题:平均值和中位数体重",
    "text": "19.6 练习题:平均值和中位数体重\n使用 agg() 和相关的汇总函数,从 yao 数据框的 weight_kg 变量中获取受访者体重的平均值和中位数。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#使用-pandas.dataframe.groupby-进行分组汇总",
    "href": "p_untangled_groupby_agg_cn.html#使用-pandas.dataframe.groupby-进行分组汇总",
    "title": "19  数据分组和汇总",
    "section": "19.7 使用 pandas.DataFrame.groupby() 进行分组汇总",
    "text": "19.7 使用 pandas.DataFrame.groupby() 进行分组汇总\n现在让我们看看如何使用 groupby() 来获得分组汇总,这是使用 agg() 的主要原因。\n顾名思义,pandas.DataFrame.groupby() 让您可以按变量中的值对数据框进行分组(例如,按性别分组为男性和女性)。然后,您可以执行按这些组拆分的操作。\n让我们尝试按性别对 yao 数据框进行分组,并观察效果:\n\nyao.groupby(\"sex\")\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x12594e2d0&gt;\n\n\n嗯。显然没有发生任何事情。我们只是得到了一个 GroupBy 对象。\n但是,当我们将 groupby() 与前一节中使用的 agg() 调用链式连接时,看看会发生什么:\n\nyao.groupby(\"sex\").agg(mean_age=(\"age\", \"mean\"), median_age=(\"age\", \"median\"))\n\n\n\n\n\n\n\n\nmean_age\nmedian_age\n\n\nsex\n\n\n\n\n\n\nFemale\n29.495446\n26.0\n\n\nMale\n28.395735\n25.0\n\n\n\n\n\n\n\n现在我们为每个组获得了不同的统计数据!女性受访者的平均年龄约为 29.5 岁,而男性受访者的平均年龄约为 28.4 岁。\n如前所述,这种分组汇总是 agg() 函数如此有用的主要原因。\n您可能注意到有两行标题。这是因为输出具有层次索引(在 pandas 中称为 MultiIndex)。虽然在某些情况下这可能有用,但它通常会使进一步的数据操作更加困难。我们可以使用 reset_index() 方法重置索引,将组标签转换回常规列。\n\nyao.groupby(\"sex\").agg(mean_age=(\"age\", \"mean\"), median_age=(\"age\", \"median\")).reset_index()\n\n\n\n\n\n\n\n\nsex\nmean_age\nmedian_age\n\n\n\n\n0\nFemale\n29.495446\n26.0\n\n\n1\nMale\n28.395735\n25.0\n\n\n\n\n\n\n\n您可能会注意到代码行变得相当长。我们可以将每个新的方法调用移到新的一行以提高代码的可读性,但需要将整个链包裹在括号中。\n\n(\n    yao.groupby(\"sex\")\n    .agg(mean_age=(\"age\", \"mean\"), median_age=(\"age\", \"median\"))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nsex\nmean_age\nmedian_age\n\n\n\n\n0\nFemale\n29.495446\n26.0\n\n\n1\nMale\n28.395735\n25.0\n\n\n\n\n\n\n\n\n让我们看一个例子。\n假设您被要求获取不同社区中个体的最大和最小体重,并呈现每个社区中的个体数量。我们可以编写:\n\n(\n    yao.groupby(\"neighborhood\")\n    .agg(\n        max_weight=(\"weight_kg\", \"max\"),\n        min_weight=(\"weight_kg\", \"min\"),\n        count=(\"weight_kg\", \"size\"),  # the size function counts rows per group\n    )\n    .reset_index()\n) \n\n\n\n\n\n\n\n\nneighborhood\nmax_weight\nmin_weight\ncount\n\n\n\n\n0\nBriqueterie\n128\n20\n106\n\n\n1\nCarriere\n129\n14\n236\n\n\n2\nCité Verte\n118\n16\n72\n\n\n...\n...\n...\n...\n...\n\n\n6\nNkomkana\n161\n15\n75\n\n\n7\nTsinga\n105\n15\n81\n\n\n8\nTsinga Oliga\n100\n17\n67\n\n\n\n\n9 rows × 4 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n19.8 练习题:按性别分组的最小和最大身高\n使用 groupby()、agg() 和相关的汇总函数,从 yao 数据框中获取每个性别的最小和最大身高,以及每个性别组中的个体数量。\n您的输出应为如下所示的 DataFrame:\n\n\n\nsex\nmin_height_cm\nmax_height_cm\ncount\n\n\n\n\nFemale\n\n\n\n\n\nMale\n\n\n\n\n\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#练习题按性别分组的最小和最大身高",
    "href": "p_untangled_groupby_agg_cn.html#练习题按性别分组的最小和最大身高",
    "title": "19  数据分组和汇总",
    "section": "19.8 练习题:按性别分组的最小和最大身高",
    "text": "19.8 练习题:按性别分组的最小和最大身高\n使用 groupby()、agg() 和相关的汇总函数,从 yao 数据框中获取每个性别的最小和最大身高,以及每个性别组中的个体数量。\n您的输出应为如下所示的 DataFrame:\n\n\n\nsex\nmin_height_cm\nmax_height_cm\ncount\n\n\n\n\nFemale\n\n\n\n\n\nMale\n\n\n\n\n\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#按多个变量分组嵌套分组",
    "href": "p_untangled_groupby_agg_cn.html#按多个变量分组嵌套分组",
    "title": "19  数据分组和汇总",
    "section": "19.9 按多个变量分组(嵌套分组)",
    "text": "19.9 按多个变量分组(嵌套分组)\n可以按多个变量对数据框进行分组。这有时称为“嵌套”分组。\n假设您想知道每个社区中男性和女性的平均年龄,您可以在 groupby() 语句中同时放入 sex 和 neighborhood:\n\n(\n    yao\n    .groupby(['sex', 'neighborhood'])\n    .agg(mean_age=('age', 'mean'))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nsex\nneighborhood\nmean_age\n\n\n\n\n0\nFemale\nBriqueterie\n31.622951\n\n\n1\nFemale\nCarriere\n28.164286\n\n\n2\nFemale\nCité Verte\n31.750000\n\n\n...\n...\n...\n...\n\n\n15\nMale\nNkomkana\n29.812500\n\n\n16\nMale\nTsinga\n28.820513\n\n\n17\nMale\nTsinga Oliga\n24.297297\n\n\n\n\n18 rows × 3 columns\n\n\n\n从这个输出数据框您可以看出,例如,来自 Briqueterie 的女性的平均年龄为 31.6 岁。\n\n\n\n\n\n\n练习\n\n\n\n19.10 练习题:按年龄和性别组的最小和最大身高\n使用 groupby()、agg() 以及 min() 和 max(),获取 yao 数据框中每个年龄-性别组的最小和最大身高。需要的变量是 age_category_3 和 sex。\n您的输出应为如下所示的 DataFrame:\n\n\n\nage_category_3\nsex\nmin_height\nmax_height\n\n\n\n\nAdult\nFemale\n78\n185\n\n\nAdult\nMale\n147\n196\n\n\nChild\nFemale\n54\n183\n\n\nChild\nMale\n96\n190\n\n\nSenior\nFemale\n143\n174\n\n\nSenior\nMale\n160\n195\n\n\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#练习题按年龄和性别组的最小和最大身高",
    "href": "p_untangled_groupby_agg_cn.html#练习题按年龄和性别组的最小和最大身高",
    "title": "19  数据分组和汇总",
    "section": "19.10 练习题:按年龄和性别组的最小和最大身高",
    "text": "19.10 练习题:按年龄和性别组的最小和最大身高\n使用 groupby()、agg() 以及 min() 和 max(),获取 yao 数据框中每个年龄-性别组的最小和最大身高。需要的变量是 age_category_3 和 sex。\n您的输出应为如下所示的 DataFrame:\n\n\n\nage_category_3\nsex\nmin_height\nmax_height\n\n\n\n\nAdult\nFemale\n78\n185\n\n\nAdult\nMale\n147\n196\n\n\nChild\nFemale\n54\n183\n\n\nChild\nMale\n96\n190\n\n\nSenior\nFemale\n143\n174\n\n\nSenior\nMale\n160\n195\n\n\n\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#agg-中的-nan-值",
    "href": "p_untangled_groupby_agg_cn.html#agg-中的-nan-值",
    "title": "19  数据分组和汇总",
    "section": "19.11 agg() 中的 NaN 值",
    "text": "19.11 agg() 中的 NaN 值\n在使用 agg() 计算分组汇总统计信息时,请注意您关注的组是否包含 NaN 值。\n例如,要按吸烟状态获取平均体重,我们可以编写:\n\n(\n    yao.groupby(\"is_smoker\")\n    .agg(weight_mean=(\"weight_kg\", \"mean\"))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nis_smoker\nweight_mean\n\n\n\n\n0\nEx-smoker\n76.366197\n\n\n1\nNon-smoker\n63.033760\n\n\n2\nSmoker\n72.410256\n\n\n\n\n\n\n\n但这实际上会将一些具有 NaN 吸烟状态的行从汇总表中排除。\n我们可以通过在 groupby() 函数中设置 dropna=False 来将这些个体包含在汇总表中。\n\n(\n    yao.groupby(\"is_smoker\", dropna=False)\n    .agg(weight_mean=(\"weight_kg\", \"mean\"))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nis_smoker\nweight_mean\n\n\n\n\n0\nEx-smoker\n76.366197\n\n\n1\nNon-smoker\n63.033760\n\n\n2\nSmoker\n72.410256\n\n\n3\nNaN\n73.000000\n\n\n\n\n\n\n\n此外,记住您可以使用 size() 函数查看每个吸烟状态组中有多少个体。这通常在您的汇总表中包含此信息很有用,这样您就知道每个汇总统计背后有多少个体。\n\n(\n    yao.groupby(\"is_smoker\", dropna=False)\n    .agg(weight_mean=(\"weight_kg\", \"mean\"), \n         count=(\"weight_kg\", \"size\"))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nis_smoker\nweight_mean\ncount\n\n\n\n\n0\nEx-smoker\n76.366197\n71\n\n\n1\nNon-smoker\n63.033760\n859\n\n\n2\nSmoker\n72.410256\n39\n\n\n3\nNaN\n73.000000\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n19.12 练习题:按怀孕状态的平均体重\n使用 groupby()、agg() 和 mean() 函数,从 yao 数据框中按怀孕状态获取平均体重(公斤)。在汇总表中包含怀孕状态为 NaN 的个体。\n输出的数据框应类似于:\n\n\n\nis_pregnant\nweight_mean\n\n\n\n\nNo\n\n\n\nNo response\n\n\n\nYes\n\n\n\nNaN\n\n\n\n\n\n# your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#练习题按怀孕状态的平均体重",
    "href": "p_untangled_groupby_agg_cn.html#练习题按怀孕状态的平均体重",
    "title": "19  数据分组和汇总",
    "section": "19.12 练习题:按怀孕状态的平均体重",
    "text": "19.12 练习题:按怀孕状态的平均体重\n使用 groupby()、agg() 和 mean() 函数,从 yao 数据框中按怀孕状态获取平均体重(公斤)。在汇总表中包含怀孕状态为 NaN 的个体。\n输出的数据框应类似于:\n\n\n\nis_pregnant\nweight_mean\n\n\n\n\nNo\n\n\n\nNo response\n\n\n\nYes\n\n\n\nNaN\n\n\n\n\n\n# your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#使用-lambda-函数进行自定义汇总统计",
    "href": "p_untangled_groupby_agg_cn.html#使用-lambda-函数进行自定义汇总统计",
    "title": "19  数据分组和汇总",
    "section": "19.13 使用 lambda 函数进行自定义汇总统计",
    "text": "19.13 使用 lambda 函数进行自定义汇总统计\n在深入研究自定义汇总统计之前,让我们简要介绍一下 lambda 函数。Python 中的 lambda 函数是使用 lambda 关键字定义的小型匿名函数。\n例如,考虑一个计算列表的范围(最大值与最小值之差)的函数。您可以使用常规函数如下定义:\n\ndef range_func(x):\n    return max(x) - min(x)\n\nprint(range_func([1, 2, 3, 4]))  # Output: 3\n\n3\n\n\n或者,您可以使用 lambda 函数实现相同的结果:\n\nrange_func = lambda x: max(x) - min(x)\nprint(range_func([1, 2, 3, 4]))  # Output: 3\n\n3\n\n\n现在,让我们看看如何使用 lambda 函数在数据分析中应用自定义汇总统计。\n例如,假设我们想计算每个社区中体重的范围。我们可以使用 range_func 函数来实现:\n\n(\n    yao.groupby(\"neighborhood\")\n    .agg(weight_range=(\"weight_kg\", range_func))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nneighborhood\nweight_range\n\n\n\n\n0\nBriqueterie\n108\n\n\n1\nCarriere\n115\n\n\n2\nCité Verte\n102\n\n\n...\n...\n...\n\n\n6\nNkomkana\n146\n\n\n7\nTsinga\n90\n\n\n8\nTsinga Oliga\n83\n\n\n\n\n9 rows × 2 columns\n\n\n\n注意我们没有将 range_func 放在引号中。只有内置函数才会被放在引号中。\n现在,我们可以在 agg() 调用中直接使用 lambda 函数,而不调用 range_func:\n\n(\n    yao.groupby(\"neighborhood\")\n    .agg(weight_range=(\"weight_kg\", lambda x: max(x) - min(x)))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nneighborhood\nweight_range\n\n\n\n\n0\nBriqueterie\n108\n\n\n1\nCarriere\n115\n\n\n2\nCité Verte\n102\n\n\n...\n...\n...\n\n\n6\nNkomkana\n146\n\n\n7\nTsinga\n90\n\n\n8\nTsinga Oliga\n83\n\n\n\n\n9 rows × 2 columns\n\n\n\n请注意,我们仍然向 agg() 函数提供了一个元组,('weight_kg', lambda x: max(x) - min(x)),但元组的第二个元素是一个 lambda 函数。\n这个 lambda 函数作用于元组中提供的列 weight_kg。\n再看一个例子:计算每个社区内体重的变异系数(CV)。CV 是标准差除以均值,是分布相对可变性的无单位度量。\n\n(\n    yao.groupby(\"neighborhood\")\n    .agg(weight_cv=(\"weight_kg\", lambda x: (np.std(x) / np.mean(x)) * 100))\n    .reset_index()\n)\n\n\n\n\n\n\n\n\nneighborhood\nweight_cv\n\n\n\n\n0\nBriqueterie\n33.531748\n\n\n1\nCarriere\n32.027533\n\n\n2\nCité Verte\n33.255829\n\n\n...\n...\n...\n\n\n6\nNkomkana\n33.187496\n\n\n7\nTsinga\n33.937145\n\n\n8\nTsinga Oliga\n35.894453\n\n\n\n\n9 rows × 2 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n19.14 练习题:按社区年龄的四分位距\n找出每个社区的年龄变量的四分位距(IQR)。IQR 是第 75 和第 25 百分位数之间的差。您的 lambda 如下所示:lambda x: x.quantile(0.75) - x.quantile(0.25)\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#练习题按社区年龄的四分位距",
    "href": "p_untangled_groupby_agg_cn.html#练习题按社区年龄的四分位距",
    "title": "19  数据分组和汇总",
    "section": "19.14 练习题:按社区年龄的四分位距",
    "text": "19.14 练习题:按社区年龄的四分位距\n找出每个社区的年龄变量的四分位距(IQR)。IQR 是第 75 和第 25 百分位数之间的差。您的 lambda 如下所示:lambda x: x.quantile(0.75) - x.quantile(0.25)\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_groupby_agg_cn.html#总结",
    "href": "p_untangled_groupby_agg_cn.html#总结",
    "title": "19  数据分组和汇总",
    "section": "19.15 总结",
    "text": "19.15 总结\n在本课程中,您学会了如何使用 agg() 快速获取数据的汇总统计信息,使用 groupby() 对数据进行分组,并将 groupby() 与 agg() 结合使用以实现强大的数据汇总。\n这些技能对于探索性数据分析和为展示或绘图准备数据至关重要。groupby() 和 agg() 结合使用是 pandas 中最常见和最有用的数据操作技术之一。\n在接下来的课程中,我们将探讨将 groupby() 与其他 pandas 方法结合使用的方法。\n下次见!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>数据分组和汇总</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html",
    "href": "p_untangled_other_grouped_operations_cn.html",
    "title": "20  Pandas中其他分组操作",
    "section": "",
    "text": "20.1 介绍\n在我们之前的课程中,您已经学习了如何使用 groupby() 和 agg() 从分组中提取汇总统计。现在,我们将更进一步,探索一些额外有用的分组数据转换。让我们开始吧。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#学习目标",
    "href": "p_untangled_other_grouped_operations_cn.html#学习目标",
    "title": "20  Pandas中其他分组操作",
    "section": "20.2 学习目标",
    "text": "20.2 学习目标\n在本课程结束时,您将能够:\n\n使用 transform() 将分组级别的汇总统计添加为新列。\n使用 value_counts() 统计组内的值。\n计算组内的累积和。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#导入",
    "href": "p_untangled_other_grouped_operations_cn.html#导入",
    "title": "20  Pandas中其他分组操作",
    "section": "20.3 导入",
    "text": "20.3 导入\n运行以下单元以导入必要的库:\n\nimport pandas as pd\nimport vega_datasets as vd\nimport plotly.express as px\nimport warnings\nimport calendar",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#数据",
    "href": "p_untangled_other_grouped_operations_cn.html#数据",
    "title": "20  Pandas中其他分组操作",
    "section": "20.4 数据",
    "text": "20.4 数据\n我们将使用 weather 数据集作为例子。\n\nweather_raw = vd.data.seattle_weather()\n\n# 使用 query 选择2012年的数据,并添加一个月份列\nweather = weather_raw.query(\"date.dt.year == 2012\")\nweather[\"month\"] = pd.Categorical(\n    weather[\"date\"].dt.strftime(\"%B\"),\n    categories=list(calendar.month_name[1:]),\n    ordered=True,\n)\nweather\n\n/var/folders/vr/shb6ffvj2rl61kh7qqczhrgh0000gp/T/ipykernel_61702/375086048.py:5: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\nmonth\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\nJanuary\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\nJanuary\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\nJanuary\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\nJanuary\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\nJanuary\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\n4.1\n7.8\n3.3\n3.2\nrain\nDecember\n\n\n362\n2012-12-28\n0.0\n8.3\n3.9\n1.7\nrain\nDecember\n\n\n363\n2012-12-29\n1.5\n5.0\n3.3\n1.7\nrain\nDecember\n\n\n364\n2012-12-30\n0.0\n4.4\n0.0\n1.8\ndrizzle\nDecember\n\n\n365\n2012-12-31\n0.0\n3.3\n-1.1\n2.0\ndrizzle\nDecember\n\n\n\n\n366 rows × 7 columns\n\n\n\n现在让我们设置本课程其余部分的显示选项:\n\npd.options.display.max_rows = 20\n\n并且让我们忽略在使用当前版本的 pandas 处理分类数据时出现的警告:\n\nwarnings.filterwarnings(\n    \"ignore\"\n)  ## 有一类关于使用当前版本 pandas 处理分类数据时出现的警告,我们可以忽略",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#使用-transform-添加汇总统计",
    "href": "p_untangled_other_grouped_operations_cn.html#使用-transform-添加汇总统计",
    "title": "20  Pandas中其他分组操作",
    "section": "20.5 使用 transform() 添加汇总统计",
    "text": "20.5 使用 transform() 添加汇总统计\n在上一课中,您学习了如何使用 agg() 计算平均值、中位数或标准差等汇总统计。\n例如,要计算每个月的平均降水量(雨+雪),您可以使用:\n\nweather.groupby('month').agg(mean_precip = ('precipitation', 'mean'))\n\n\n\n\n\n\n\n\nmean_precip\n\n\nmonth\n\n\n\n\n\nJanuary\n5.590323\n\n\nFebruary\n3.182759\n\n\nMarch\n5.903226\n\n\nApril\n2.270000\n\n\nMay\n1.683871\n\n\n...\n...\n\n\nAugust\n0.000000\n\n\nSeptember\n0.030000\n\n\nOctober\n5.493548\n\n\nNovember\n7.016667\n\n\nDecember\n5.612903\n\n\n\n\n12 rows × 1 columns\n\n\n\n有时,我们希望将这些组级别的统计添加为原始 DataFrame 的新列。我们无法直接使用 agg() 的输出来实现:\n\n# 无法工作\nweather['mean_precip'] = weather.groupby('month').agg(mean_precip = ('precipitation', 'mean'))\nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\nmonth\nmean_precip\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\nJanuary\nNaN\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\nJanuary\nNaN\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\nJanuary\nNaN\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\nJanuary\nNaN\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\nJanuary\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\n4.1\n7.8\n3.3\n3.2\nrain\nDecember\nNaN\n\n\n362\n2012-12-28\n0.0\n8.3\n3.9\n1.7\nrain\nDecember\nNaN\n\n\n363\n2012-12-29\n1.5\n5.0\n3.3\n1.7\nrain\nDecember\nNaN\n\n\n364\n2012-12-30\n0.0\n4.4\n0.0\n1.8\ndrizzle\nDecember\nNaN\n\n\n365\n2012-12-31\n0.0\n3.3\n-1.1\n2.0\ndrizzle\nDecember\nNaN\n\n\n\n\n366 rows × 8 columns\n\n\n\n但我们可以使用 transform() 来实现。transform() 将输出重新整形以匹配原始 DataFrame 的形状,允许我们将组级别的统计添加为新列。\n\nweather['mean_precip_month'] = weather.groupby('month')['precipitation'].transform('mean')\nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\nmonth\nmean_precip\nmean_precip_month\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\nJanuary\nNaN\n5.590323\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\nJanuary\nNaN\n5.590323\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\nJanuary\nNaN\n5.590323\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\nJanuary\nNaN\n5.590323\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\nJanuary\nNaN\n5.590323\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\n4.1\n7.8\n3.3\n3.2\nrain\nDecember\nNaN\n5.612903\n\n\n362\n2012-12-28\n0.0\n8.3\n3.9\n1.7\nrain\nDecember\nNaN\n5.612903\n\n\n363\n2012-12-29\n1.5\n5.0\n3.3\n1.7\nrain\nDecember\nNaN\n5.612903\n\n\n364\n2012-12-30\n0.0\n4.4\n0.0\n1.8\ndrizzle\nDecember\nNaN\n5.612903\n\n\n365\n2012-12-31\n0.0\n3.3\n-1.1\n2.0\ndrizzle\nDecember\nNaN\n5.612903\n\n\n\n\n366 rows × 9 columns\n\n\n\n您可以以类似方式计算其他统计。例如,要计算每个月的降水中位数,您可以使用:\n\nweather['prep_median_month'] = weather.groupby('month')['precipitation'].transform('median')    \nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\nmonth\nmean_precip\nmean_precip_month\nprep_median_month\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\nJanuary\nNaN\n5.590323\n3.0\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\nJanuary\nNaN\n5.590323\n3.0\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\nJanuary\nNaN\n5.590323\n3.0\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\nJanuary\nNaN\n5.590323\n3.0\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\nJanuary\nNaN\n5.590323\n3.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\n4.1\n7.8\n3.3\n3.2\nrain\nDecember\nNaN\n5.612903\n3.3\n\n\n362\n2012-12-28\n0.0\n8.3\n3.9\n1.7\nrain\nDecember\nNaN\n5.612903\n3.3\n\n\n363\n2012-12-29\n1.5\n5.0\n3.3\n1.7\nrain\nDecember\nNaN\n5.612903\n3.3\n\n\n364\n2012-12-30\n0.0\n4.4\n0.0\n1.8\ndrizzle\nDecember\nNaN\n5.612903\n3.3\n\n\n365\n2012-12-31\n0.0\n3.3\n-1.1\n2.0\ndrizzle\nDecember\nNaN\n5.612903\n3.3\n\n\n\n\n366 rows × 10 columns\n\n\n\n或者计算每个月的降水总和:\n\nweather['precip_sum_month'] = weather.groupby('month')['precipitation'].transform('sum')\nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\nmonth\nmean_precip\nmean_precip_month\nprep_median_month\nprecip_sum_month\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\nJanuary\nNaN\n5.590323\n3.0\n173.3\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\n4.1\n7.8\n3.3\n3.2\nrain\nDecember\nNaN\n5.612903\n3.3\n174.0\n\n\n362\n2012-12-28\n0.0\n8.3\n3.9\n1.7\nrain\nDecember\nNaN\n5.612903\n3.3\n174.0\n\n\n363\n2012-12-29\n1.5\n5.0\n3.3\n1.7\nrain\nDecember\nNaN\n5.612903\n3.3\n174.0\n\n\n364\n2012-12-30\n0.0\n4.4\n0.0\n1.8\ndrizzle\nDecember\nNaN\n5.612903\n3.3\n174.0\n\n\n365\n2012-12-31\n0.0\n3.3\n-1.1\n2.0\ndrizzle\nDecember\nNaN\n5.612903\n3.3\n174.0\n\n\n\n\n366 rows × 11 columns\n\n\n\n有了总和,我们可以轻松计算该月降水量在每天中所占的比例:\n\nweather[\"precip_month_prop\"] = weather[\"precipitation\"] / weather[\"precip_sum_month\"]\nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\nmonth\nmean_precip\nmean_precip_month\nprep_median_month\nprecip_sum_month\nprecip_month_prop\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\nJanuary\nNaN\n5.590323\n3.0\n173.3\n0.000000\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n0.062897\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n0.004616\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n0.117138\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\nJanuary\nNaN\n5.590323\n3.0\n173.3\n0.007501\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\n4.1\n7.8\n3.3\n3.2\nrain\nDecember\nNaN\n5.612903\n3.3\n174.0\n0.023563\n\n\n362\n2012-12-28\n0.0\n8.3\n3.9\n1.7\nrain\nDecember\nNaN\n5.612903\n3.3\n174.0\n0.000000\n\n\n363\n2012-12-29\n1.5\n5.0\n3.3\n1.7\nrain\nDecember\nNaN\n5.612903\n3.3\n174.0\n0.008621\n\n\n364\n2012-12-30\n0.0\n4.4\n0.0\n1.8\ndrizzle\nDecember\nNaN\n5.612903\n3.3\n174.0\n0.000000\n\n\n365\n2012-12-31\n0.0\n3.3\n-1.1\n2.0\ndrizzle\nDecember\nNaN\n5.612903\n3.3\n174.0\n0.000000\n\n\n\n\n366 rows × 12 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n20.6 练习题:每日小费比例\n使用 tips 数据集,计算: 1. 一个包含每天总小费的新列 daily_total_tips 2. 一个显示每位顾客该日总小费的比例的新列 tip_proportion\n\n# Your code here:\ntips = px.data.tips()\ntips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n您的输出数据的前几行应类似于:\ntotal_bill    tip     sex      smoker    day    time      size    daily_total_tips    tip_proportion\n16.99         1.01    Female   No        Sun    Dinner    2       247.39              0.004083\n10.34         1.66    Male     No        Sun    Dinner    3       247.39              0.006710\n21.01         3.50    Male     No        Sun    Dinner    3       247.39              0.014148\n23.68         3.31    Male     No        Sun    Dinner    2       247.39              0.013380\n\n\n让我们重新初始化 weather DataFrame 为一个较小的列集合,用于本课程的其余部分:\n\nweather = weather[['date', 'month', 'precipitation', 'wind', 'weather']]\nweather\n\n\n\n\n\n\n\n\ndate\nmonth\nprecipitation\nwind\nweather\n\n\n\n\n0\n2012-01-01\nJanuary\n0.0\n4.7\ndrizzle\n\n\n1\n2012-01-02\nJanuary\n10.9\n4.5\nrain\n\n\n2\n2012-01-03\nJanuary\n0.8\n2.3\nrain\n\n\n3\n2012-01-04\nJanuary\n20.3\n4.7\nrain\n\n\n4\n2012-01-05\nJanuary\n1.3\n6.1\nrain\n\n\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\nDecember\n4.1\n3.2\nrain\n\n\n362\n2012-12-28\nDecember\n0.0\n1.7\nrain\n\n\n363\n2012-12-29\nDecember\n1.5\n1.7\nrain\n\n\n364\n2012-12-30\nDecember\n0.0\n1.8\ndrizzle\n\n\n365\n2012-12-31\nDecember\n0.0\n2.0\ndrizzle\n\n\n\n\n366 rows × 5 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#练习题每日小费比例",
    "href": "p_untangled_other_grouped_operations_cn.html#练习题每日小费比例",
    "title": "20  Pandas中其他分组操作",
    "section": "20.6 练习题:每日小费比例",
    "text": "20.6 练习题:每日小费比例\n使用 tips 数据集,计算: 1. 一个包含每天总小费的新列 daily_total_tips 2. 一个显示每位顾客该日总小费的比例的新列 tip_proportion\n\n# Your code here:\ntips = px.data.tips()\ntips\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n您的输出数据的前几行应类似于:\ntotal_bill    tip     sex      smoker    day    time      size    daily_total_tips    tip_proportion\n16.99         1.01    Female   No        Sun    Dinner    2       247.39              0.004083\n10.34         1.66    Male     No        Sun    Dinner    3       247.39              0.006710\n21.01         3.50    Male     No        Sun    Dinner    3       247.39              0.014148\n23.68         3.31    Male     No        Sun    Dinner    2       247.39              0.013380",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#使用-value_counts-统计组内的值",
    "href": "p_untangled_other_grouped_operations_cn.html#使用-value_counts-统计组内的值",
    "title": "20  Pandas中其他分组操作",
    "section": "20.7 使用 value_counts() 统计组内的值",
    "text": "20.7 使用 value_counts() 统计组内的值\n统计分类变量在组内的出现次数可以揭示有趣的模式,通常需要在使用 groupby() 后进行。\n首先,让我们回顾一下 value_counts() 在整个 DataFrame 上的工作方式。\n\n# 天气类型的计数\nweather[\"weather\"].value_counts()\n\nweather\nrain       191\nsun        118\ndrizzle     31\nsnow        21\nfog          5\nName: count, dtype: int64\n\n\n我们可以添加 normalize=True 来获得比例:\n\nweather['weather'].value_counts(normalize=True)\n\nweather\nrain       0.521858\nsun        0.322404\ndrizzle    0.084699\nsnow       0.057377\nfog        0.013661\nName: proportion, dtype: float64\n\n\n现在,要统计每个月的天气类型,我们首先按 month 分组,然后选择 weather 列并应用 value_counts()。\n\n# 每个月天气类型的计数\nweather.groupby('month')['weather'].value_counts()\n\nmonth     weather\nJanuary   rain       18\n          snow        7\n          sun         4\n          drizzle     2\n          fog         0\n                     ..\nDecember  rain       23\n          snow        5\n          drizzle     2\n          sun         1\n          fog         0\nName: count, Length: 60, dtype: int64\n\n\n这将返回一个具有多重索引的 Series,可以使用 reset_index() 转换为常规的 DataFrame:\n\nweather.groupby('month')['weather'].value_counts().reset_index()\n\n\n\n\n\n\n\n\nmonth\nweather\ncount\n\n\n\n\n0\nJanuary\nrain\n18\n\n\n1\nJanuary\nsnow\n7\n\n\n2\nJanuary\nsun\n4\n\n\n3\nJanuary\ndrizzle\n2\n\n\n4\nJanuary\nfog\n0\n\n\n...\n...\n...\n...\n\n\n55\nDecember\nrain\n23\n\n\n56\nDecember\nsnow\n5\n\n\n57\nDecember\ndrizzle\n2\n\n\n58\nDecember\nsun\n1\n\n\n59\nDecember\nfog\n0\n\n\n\n\n60 rows × 3 columns\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n20.8 练习题:按日统计吸烟者和非吸烟者人数\n使用 tips 数据集,统计每一天吸烟者和非吸烟者的数量。\n\ntips = px.data.tips()\ntips\n\n# Your code here:\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n您的结果的前几行应类似于:\nday smoker  count\nFri Yes 15\nFri No  4\nSat No  45",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#练习题按日统计吸烟者和非吸烟者人数",
    "href": "p_untangled_other_grouped_operations_cn.html#练习题按日统计吸烟者和非吸烟者人数",
    "title": "20  Pandas中其他分组操作",
    "section": "20.8 练习题:按日统计吸烟者和非吸烟者人数",
    "text": "20.8 练习题:按日统计吸烟者和非吸烟者人数\n使用 tips 数据集,统计每一天吸烟者和非吸烟者的数量。\n\ntips = px.data.tips()\ntips\n\n# Your code here:\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns\n\n\n\n您的结果的前几行应类似于:\nday smoker  count\nFri Yes 15\nFri No  4\nSat No  45",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#在组内计算累积和",
    "href": "p_untangled_other_grouped_operations_cn.html#在组内计算累积和",
    "title": "20  Pandas中其他分组操作",
    "section": "20.9 在组内计算累积和",
    "text": "20.9 在组内计算累积和\n累积和有助于跟踪组内的运行总计。这是一种常用的操作。让我们看看如何对分组数据执行此操作。\n回顾一下,以下是如何计算整个 DataFrame 的降水累积和:\n\n# 降水的累积和\nweather[\"precip_cumul\"] = weather[\"precipitation\"].cumsum()\nweather\n\n\n\n\n\n\n\n\ndate\nmonth\nprecipitation\nwind\nweather\nprecip_cumul\n\n\n\n\n0\n2012-01-01\nJanuary\n0.0\n4.7\ndrizzle\n0.0\n\n\n1\n2012-01-02\nJanuary\n10.9\n4.5\nrain\n10.9\n\n\n2\n2012-01-03\nJanuary\n0.8\n2.3\nrain\n11.7\n\n\n3\n2012-01-04\nJanuary\n20.3\n4.7\nrain\n32.0\n\n\n4\n2012-01-05\nJanuary\n1.3\n6.1\nrain\n33.3\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\nDecember\n4.1\n3.2\nrain\n1224.5\n\n\n362\n2012-12-28\nDecember\n0.0\n1.7\nrain\n1224.5\n\n\n363\n2012-12-29\nDecember\n1.5\n1.7\nrain\n1226.0\n\n\n364\n2012-12-30\nDecember\n0.0\n1.8\ndrizzle\n1226.0\n\n\n365\n2012-12-31\nDecember\n0.0\n2.0\ndrizzle\n1226.0\n\n\n\n\n366 rows × 6 columns\n\n\n\n要计算每个月的降水累积和,我们可以使用 groupby() 和 cumsum():\n\n# 每个月的降水累积和\nweather[\"precip_cumul\"] = weather.groupby(\"month\")[\"precipitation\"].cumsum()\nweather\n\n\n\n\n\n\n\n\ndate\nmonth\nprecipitation\nwind\nweather\nprecip_cumul\n\n\n\n\n0\n2012-01-01\nJanuary\n0.0\n4.7\ndrizzle\n0.0\n\n\n1\n2012-01-02\nJanuary\n10.9\n4.5\nrain\n10.9\n\n\n2\n2012-01-03\nJanuary\n0.8\n2.3\nrain\n11.7\n\n\n3\n2012-01-04\nJanuary\n20.3\n4.7\nrain\n32.0\n\n\n4\n2012-01-05\nJanuary\n1.3\n6.1\nrain\n33.3\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n2012-12-27\nDecember\n4.1\n3.2\nrain\n172.5\n\n\n362\n2012-12-28\nDecember\n0.0\n1.7\nrain\n172.5\n\n\n363\n2012-12-29\nDecember\n1.5\n1.7\nrain\n174.0\n\n\n364\n2012-12-30\nDecember\n0.0\n1.8\ndrizzle\n174.0\n\n\n365\n2012-12-31\nDecember\n0.0\n2.0\ndrizzle\n174.0\n\n\n\n\n366 rows × 6 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#练习题按日累积小费金额",
    "href": "p_untangled_other_grouped_operations_cn.html#练习题按日累积小费金额",
    "title": "20  Pandas中其他分组操作",
    "section": "20.10 练习题:按日累积小费金额",
    "text": "20.10 练习题:按日累积小费金额\n使用 tips 数据集,计算每个 day 的 total_bill 累积和,添加一个新列 cumul_total_bill_day。然后添加另一列 cumul_tip_day,包含每个 day 的 tip 累积和。\n\ntips = px.data.tips()\ntips = tips.sort_values('day')\ntips\n# Your code here:\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n96\n27.28\n4.00\nMale\nYes\nFri\nDinner\n2\n\n\n101\n15.38\n3.00\nFemale\nYes\nFri\nDinner\n2\n\n\n98\n21.01\n3.00\nMale\nYes\nFri\nDinner\n2\n\n\n97\n12.03\n1.50\nMale\nYes\nFri\nDinner\n2\n\n\n95\n40.17\n4.73\nMale\nYes\nFri\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n132\n11.17\n1.50\nFemale\nNo\nThur\nLunch\n2\n\n\n131\n20.27\n2.83\nFemale\nNo\nThur\nLunch\n2\n\n\n130\n19.08\n1.50\nMale\nNo\nThur\nLunch\n2\n\n\n128\n11.38\n2.00\nFemale\nNo\nThur\nLunch\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_other_grouped_operations_cn.html#总结",
    "href": "p_untangled_other_grouped_operations_cn.html#总结",
    "title": "20  Pandas中其他分组操作",
    "section": "20.11 总结",
    "text": "20.11 总结\n在本课程中,您学习了 pandas 中几个强大的 分组级数据转换:\n\n添加汇总统计:使用 transform() 将分组级别的计算添加为新列\n组内计数:使用 value_counts() 统计组内的出现次数\n计算累积和:跟踪组内的运行总计\n\n这些技术使您能够分析数据中特定子集中的模式和统计信息。继续练习不同的数据集,以提升您的数据操作技能!\n下次见!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Pandas中其他分组操作</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html",
    "href": "p_untangled_joining_1_cn.html",
    "title": "21  数据集连接介绍",
    "section": "",
    "text": "21.1 数据与包\n请运行下面的代码以加载我们将在本课程中使用的包和数据集。\nimport pandas as pd\n\n\n# TB incidence in Africa\ntb_2019_africa = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/tb_incidence_2019.csv\"\n) \n\n# Health expenditure data\nhealth_exp_2019 = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/health_expend_per_cap_2019.csv\"\n)\n\n# Highest expenditure countries\nhighest_exp = health_exp_2019.sort_values(\"expend_usd\", ascending=False).head(70)\n\n# TB cases in children\ntb_cases_children = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/tb_cases_children_2012.csv\"\n).dropna()\n\n# Country continents data\ncountry_continents = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/country_continents.csv\"\n)\n\n# people data\npeople = pd.DataFrame({\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"age\": [25, 32, 45]})\n\n# Test information\ntest_info = pd.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"test_date\": [\"2023-06-05\", \"2023-08-10\", \"2023-07-15\"],\n        \"result\": [\"Negative\", \"Positive\", \"Negative\"],\n    }\n)\n\n# Disordered test information\ntest_info_disordered = pd.DataFrame(\n    {\n        \"name\": [\"Bob\", \"Alice\", \"Charlie\"],  # Bob in first row\n        \"test_date\": [\"2023-08-10\", \"2023-06-05\", \"2023-07-15\"],\n        \"result\": [\"Positive\", \"Negative\", \"Negative\"],\n    }\n)\n\n# Multiple test information\ntest_info_multiple = pd.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Alice\", \"Bob\", \"Charlie\"],\n        \"test_date\": [\"2023-06-05\", \"2023-06-06\", \"2023-08-10\", \"2023-07-15\"],\n        \"result\": [\"Negative\", \"Negative\", \"Positive\", \"Negative\"],\n    }\n)\n\n# Test information with different name\ntest_info_different_name = pd.DataFrame(\n    {\n        \"first_name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"test_date\": [\"2023-06-05\", \"2023-08-10\", \"2023-07-15\"],\n        \"result\": [\"Negative\", \"Positive\", \"Negative\"],\n    }\n)\n\n# Test information including Xavier\ntest_info_xavier = pd.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Xavier\"],\n        \"test_date\": [\"2023-06-05\", \"2023-08-10\", \"2023-05-02\"],\n        \"result\": [\"Negative\", \"Positive\", \"Negative\"],\n    }\n)\n\n# Students data\nstudents = pd.DataFrame(\n    {\"student_id\": [1, 2, 3], \"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"age\": [20, 22, 21]}\n)\n\n# Exam dates data\nexam_dates = pd.DataFrame(\n    {\"student_id\": [1, 3], \"exam_date\": [\"2023-05-20\", \"2023-05-22\"]}\n)\n\n# Employee details\nemployee_details = pd.DataFrame(\n    {\n        \"id_number\": [\"E001\", \"E002\", \"E003\"],\n        \"full_name\": [\"Emily\", \"Frank\", \"Grace\"],\n        \"department\": [\"HR\", \"IT\", \"Marketing\"],\n    }\n)\n\n# Performance reviews\nperformance_reviews = pd.DataFrame(\n    {\n        \"employee_code\": [\"E001\", \"E002\", \"E003\"],\n        \"review_type\": [\"Annual\", \"Mid-year\", \"Annual\"],\n        \"review_date\": [\"2022-05-10\", \"2023-09-01\", \"2021-12-15\"],\n    }\n)\n\n# Sales data\nsales_data = pd.DataFrame(\n    {\n        \"salesperson_id\": [1, 4, 8],\n        \"product\": [\"Laptop\", \"Smartphone\", \"Tablet\"],\n        \"date_of_sale\": [\"2023-01-15\", \"2023-03-05\", \"2023-02-20\"],\n    }\n)\n\n# Salesperson peoples\nsalesperson_peoples = pd.DataFrame(\n    {\n        \"salesperson_id\": [1, 2, 3, 5, 8],\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"],\n        \"age\": [28, 45, 32, 55, 40],\n        \"gender\": [\"Female\", \"Male\", \"Male\", \"Female\", \"Female\"],\n    }\n)\n\n# Total sales data\ntotal_sales = pd.DataFrame(\n    {\n        \"product\": [\n            \"Laptop\",\n            \"Desktop\",\n            \"Tablet\",\n            \"Smartphone\",\n            \"Smartwatch\",\n            \"Headphones\",\n            \"Monitor\",\n            \"Keyboard\",\n            \"Mouse\",\n            \"Printer\",\n        ],\n        \"total_units_sold\": [9751, 136, 8285, 2478, 3642, 5231, 1892, 4267, 3891, 982],\n    }\n)\n\n# Product feedback data\nproduct_feedback = pd.DataFrame(\n    {\n        \"product\": [\n            \"Laptop\",\n            \"Desktop\",\n            \"Tablet\",\n            \"Smartphone\",\n            \"Smartwatch\",\n            \"Headphones\",\n            \"Monitor\",\n            \"Gaming Console\",\n            \"Camera\",\n            \"Speaker\",\n        ],\n        \"n_positive_reviews\": [1938, 128, 842, 1567, 723, 956, 445, 582, 234, 678],\n        \"n_negative_reviews\": [42, 30, 56, 89, 34, 28, 15, 11, 8, 25],\n    }\n)\n\n# Sales incidence data\nsales = pd.DataFrame(\n    {\n        \"year\": [2010, 2011, 2014, 2016, 2017],\n        \"sales_count\": [69890, 66507, 59831, 58704, 59151],\n    }\n)\n\n# Customer complaints data\ncustomer_complaints = pd.DataFrame(\n    {\n        \"year\": [2011, 2013, 2015, 2016, 2019],\n        \"complaints_count\": [1292, 1100, 1011, 940, 895],\n    }\n)\n\n\nemployees = pd.DataFrame(\n    {\"employee_id\": [1, 2, 3], \"name\": [\"John\", \"Joy\", \"Khan\"], \"age\": [32, 28, 40]}\n)\n\ntraining_sessions = pd.DataFrame(\n    {\n        \"employee_id\": [1, 2, 3],\n        \"training_date\": [\"2023-01-20\", \"2023-02-20\", \"2023-05-15\"],\n    }\n)\n\ncustomer_details = pd.DataFrame(\n    {\n        \"id_number\": [\"A001\", \"B002\", \"C003\"],\n        \"full_name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"address\": [\"123 Elm St\", \"456 Maple Dr\", \"789 Oak Blvd\"],\n    }\n)\n\n# Order Records\norder_records = pd.DataFrame(\n    {\n        \"customer_code\": [\"A001\", \"B002\", \"C003\"],\n        \"product_type\": [\"Electronics\", \"Books\", \"Clothing\"],\n        \"order_date\": [\"2022-05-10\", \"2023-09-01\", \"2021-12-15\"],\n    }\n)",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#简介",
    "href": "p_untangled_joining_1_cn.html#简介",
    "title": "21  数据集连接介绍",
    "section": "21.2 简介",
    "text": "21.2 简介\n连接是处理数据时的关键技能,因为它允许您从多个来源组合关于相同实体的信息,从而进行更全面和有洞察力的分析。在本课程中,您将学习如何使用 Python 的 pandas 库使用不同的连接技术。让我们开始吧!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#学习目标",
    "href": "p_untangled_joining_1_cn.html#学习目标",
    "title": "21  数据集连接介绍",
    "section": "21.3 学习目标",
    "text": "21.3 学习目标\n\n理解不同连接的工作原理:左连接、右连接、内连接和外连接。\n能够使用 pd.merge() 函数将简单的数据集连接在一起。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#我们为什么需要连接",
    "href": "p_untangled_joining_1_cn.html#我们为什么需要连接",
    "title": "21  数据集连接介绍",
    "section": "21.4 我们为什么需要连接?",
    "text": "21.4 我们为什么需要连接?\n为了说明连接的实用性,让我们从一个简单的例子开始。考虑以下两个数据集。第一个 people 包含三个人的姓名和年龄:\n\npeople\n\n\n\n\n\n\n\n\nname\nage\n\n\n\n\n0\nAlice\n25\n\n\n1\nBob\n32\n\n\n2\nCharlie\n45\n\n\n\n\n\n\n\n第二个 test_info 包含这些人的测试日期和结果:\n\ntest_info\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n我们希望将这些数据一起分析,因此我们需要一种将它们组合起来的方法。\n我们可以考虑的一个选项是使用 pd.concat() 将数据框水平拼接:\n\npd.concat([people, test_info], axis=1)\n\n\n\n\n\n\n\n\nname\nage\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n32\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n这成功地合并了数据集,但并不非常智能。该函数基本上是“粘贴”或“订书”这两个表。因此,您会注意到“name”列出现了两次。这并不理想,并且会对分析造成问题。\n另一个问题是,如果两个数据集中的行未对齐。此时,使用 pd.concat() 将数据不正确地组合在一起。考虑 test_info_disordered 数据集,现在第一行是 Bob:\n\ntest_info_disordered\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nBob\n2023-08-10\nPositive\n\n\n1\nAlice\n2023-06-05\nNegative\n\n\n2\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n如果我们将其与原始 people 数据集拼接,其中 Bob 在第二行,会发生什么?\n\npd.concat([people, test_info_disordered], axis=1)\n\n\n\n\n\n\n\n\nname\nage\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\nBob\n2023-08-10\nPositive\n\n\n1\nBob\n32\nAlice\n2023-06-05\nNegative\n\n\n2\nCharlie\n45\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\nAlice 的个人详情现在错误地与 Bob 的测试信息对齐了!\n第三个问题是当一个实体在一个数据集中出现多次时。也许 Alice 进行了多次测试:\n\ntest_info_multiple\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nAlice\n2023-06-06\nNegative\n\n\n2\nBob\n2023-08-10\nPositive\n\n\n3\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n如果我们尝试将其与 people 数据集拼接,由于行数不同,我们会得到不匹配的数据:\n\npd.concat([people, test_info_multiple], axis=1)\n\n\n\n\n\n\n\n\nname\nage\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n25.0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n32.0\nAlice\n2023-06-06\nNegative\n\n\n2\nCharlie\n45.0\nBob\n2023-08-10\nPositive\n\n\n3\nNaN\nNaN\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n这会导致 NaN 值和数据对不齐。\n\n\n\n\n\n\n附注\n\n\n\n我们这里所拥有的是一种 一对多 关系——在人员数据中有一个 Alice,但在测试数据中有多行 Alice,因为她进行了多次测试。在这种情况下的连接将在第二个连接课程中详细介绍。\n\n\n\n显然,我们需要比拼接更智能的方式来组合数据集;我们需要进入连接的世界。在 pandas 中,执行连接的函数是 pd.merge()。\n它适用于简单的情况,并且不会重复名称列:\n\npd.merge(people, test_info)\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\n2023-07-15\nNegative\n\n\n\n\n\n\n\n它适用于数据集未按相同顺序排列的情况:\n\npd.merge(people, test_info_disordered)\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\n2023-07-15\nNegative\n\n\n\n\n\n\n\n如您所见,Alice 的详情现在正确地与她的测试结果对齐。\n并且当每个个体有多个测试记录时,它也能正常工作:\n\npd.merge(people, test_info_multiple)\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nAlice\n25\n2023-06-06\nNegative\n\n\n2\nBob\n32\n2023-08-10\nPositive\n\n\n3\nCharlie\n45\n2023-07-15\nNegative\n\n\n\n\n\n\n\n在这种情况下,pd.merge() 函数正确地为 Alice 的每次测试重复了她的详情。\n简单而优雅!",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#pd.merge-语法",
    "href": "p_untangled_joining_1_cn.html#pd.merge-语法",
    "title": "21  数据集连接介绍",
    "section": "21.5 pd.merge() 语法",
    "text": "21.5 pd.merge() 语法\n现在我们了解了 为什么 需要连接,让我们来看一下它们的基本语法。\n连接将两个数据框作为前两个参数:left(左数据框)和 right(右数据框)。在 pandas 中,您可以将它们作为位置参数或关键字参数提供:\n\n# left and right\npd.merge(left=people, right=test_info)  # keyword arguments\npd.merge(people, test_info)  # positional arguments\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\n2023-07-15\nNegative\n\n\n\n\n\n\n\n另一个关键参数是 on,它指示用于连接表的列或 键。我们并不总是需要提供这个参数;它可以从数据集中 推断 出来。例如,在我们最初的例子中,people 和 test_info 中唯一共同的列是 “name”。因此,合并函数假定 on='name':\n\n# on argument is optional if the column key is the same in both dataframes\npd.merge(people, test_info)\npd.merge(people, test_info, on=\"name\")\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\n2023-07-15\nNegative\n\n\n\n\n\n\n\n\n\n\n\n\n\n词汇\n\n\n\n用于在连接操作中匹配两个数据框行的列被称为 键。在 pandas 的 merge() 函数中,键在 on 参数中指定,如 pd.merge(people, test_info, on='name') 中所示。\n\n\n如果两个数据集中的键名称不同,会发生什么呢?考虑 test_info_different_name 数据集,其中 “name” 列更改为 “first_name”:\n\ntest_info_different_name\n\n\n\n\n\n\n\n\nfirst_name\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n如果我们尝试将 test_info_different_name 与原始 people 数据集连接,我们将遇到错误:\n\npd.merge(people, test_info_different_name)\n\nMergeError: No common columns to perform merge on. Merge options: left_on=None, right_on=None, left_index=False, right_index=False\n错误表明没有共同的变量,因此无法进行连接。\n在这种情况下,您有两个选择:您可以将第二个数据框中的列重命名以匹配第一个数据框,或者更简单地,使用 left_on 和 right_on 指定要连接的列。\n以下是如何操作:\n\npd.merge(people, test_info_different_name, left_on='name', right_on='first_name')\n\n\n\n\n\n\n\n\nname\nage\nfirst_name\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n32\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\nCharlie\n2023-07-15\nNegative\n\n\n\n\n\n\n\n这种语法基本上表示,“因为它们代表相同的数据,所以将左数据框中的 name 连接到右数据框中的 first_name”。\n\n\n\n\n\n\n\n词汇\n\n\n\n键:在连接操作中用于匹配两个数据框行的列或列的集合。\n左连接:一种连接类型,保留左数据框中的所有行,并添加右数据框中匹配的行。如果没有匹配,右侧的结果为 NaN。\n\n\n\n\n\n\n\n\n练习\n\n\n\n21.6 练习题:连接员工和培训课程\n考虑以下两个数据集,一个包含员工详情,另一个包含这些员工的培训课程日期。\n\nemployees\n\n\n\n\n\n\n\n\nemployee_id\nname\nage\n\n\n\n\n0\n1\nJohn\n32\n\n\n1\n2\nJoy\n28\n\n\n2\n3\nKhan\n40\n\n\n\n\n\n\n\n\ntraining_sessions\n\n\n\n\n\n\n\n\nemployee_id\ntraining_date\n\n\n\n\n0\n1\n2023-01-20\n\n\n1\n2\n2023-02-20\n\n\n2\n3\n2023-05-15\n\n\n\n\n\n\n\n在连接这两个数据集后,您预计会有多少行和多少列?\n现在连接这两个数据集并检查您的答案。\n\n# Your code here\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n21.7 练习题:使用 on 参数进行连接\n以下是两个数据集,一个包含客户详情,另一个包含这些客户的订单记录。\n\ncustomer_details\n\n\n\n\n\n\n\n\nid_number\nfull_name\naddress\n\n\n\n\n0\nA001\nAlice\n123 Elm St\n\n\n1\nB002\nBob\n456 Maple Dr\n\n\n2\nC003\nCharlie\n789 Oak Blvd\n\n\n\n\n\n\n\n\norder_records\n\n\n\n\n\n\n\n\ncustomer_code\nproduct_type\norder_date\n\n\n\n\n0\nA001\nElectronics\n2022-05-10\n\n\n1\nB002\nBooks\n2023-09-01\n\n\n2\nC003\nClothing\n2021-12-15\n\n\n\n\n\n\n\n将 customer_details 和 order_records 数据集连接起来。由于客户标识列名称不同,您需要使用 left_on 和 right_on 参数。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#练习题连接员工和培训课程",
    "href": "p_untangled_joining_1_cn.html#练习题连接员工和培训课程",
    "title": "21  数据集连接介绍",
    "section": "21.6 练习题:连接员工和培训课程",
    "text": "21.6 练习题:连接员工和培训课程\n考虑以下两个数据集,一个包含员工详情,另一个包含这些员工的培训课程日期。\n\nemployees\n\n\n\n\n\n\n\n\nemployee_id\nname\nage\n\n\n\n\n0\n1\nJohn\n32\n\n\n1\n2\nJoy\n28\n\n\n2\n3\nKhan\n40\n\n\n\n\n\n\n\n\ntraining_sessions\n\n\n\n\n\n\n\n\nemployee_id\ntraining_date\n\n\n\n\n0\n1\n2023-01-20\n\n\n1\n2\n2023-02-20\n\n\n2\n3\n2023-05-15\n\n\n\n\n\n\n\n在连接这两个数据集后,您预计会有多少行和多少列?\n现在连接这两个数据集并检查您的答案。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#练习题使用-on-参数进行连接",
    "href": "p_untangled_joining_1_cn.html#练习题使用-on-参数进行连接",
    "title": "21  数据集连接介绍",
    "section": "21.7 练习题:使用 on 参数进行连接",
    "text": "21.7 练习题:使用 on 参数进行连接\n以下是两个数据集,一个包含客户详情,另一个包含这些客户的订单记录。\n\ncustomer_details\n\n\n\n\n\n\n\n\nid_number\nfull_name\naddress\n\n\n\n\n0\nA001\nAlice\n123 Elm St\n\n\n1\nB002\nBob\n456 Maple Dr\n\n\n2\nC003\nCharlie\n789 Oak Blvd\n\n\n\n\n\n\n\n\norder_records\n\n\n\n\n\n\n\n\ncustomer_code\nproduct_type\norder_date\n\n\n\n\n0\nA001\nElectronics\n2022-05-10\n\n\n1\nB002\nBooks\n2023-09-01\n\n\n2\nC003\nClothing\n2021-12-15\n\n\n\n\n\n\n\n将 customer_details 和 order_records 数据集连接起来。由于客户标识列名称不同,您需要使用 left_on 和 right_on 参数。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#连接类型",
    "href": "p_untangled_joining_1_cn.html#连接类型",
    "title": "21  数据集连接介绍",
    "section": "21.8 连接类型",
    "text": "21.8 连接类型\n到目前为止的简单示例涉及可以完美匹配的数据集——一个数据集中的每一行在另一个数据集中都有对应的行。\n现实世界中的数据通常更为复杂。通常,第一个表中会有一些条目在第二个表中没有对应的条目,反之亦然。\n为了处理这些不完美匹配的情况,不同的连接类型具有特定的行为:left、right、inner 和 outer。在接下来的章节中,我们将通过示例了解每种连接类型如何处理不完美匹配的数据集。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#left-连接",
    "href": "p_untangled_joining_1_cn.html#left-连接",
    "title": "21  数据集连接介绍",
    "section": "21.9 left 连接",
    "text": "21.9 left 连接\n让我们从 left 连接开始。为了看看它如何处理不匹配的行,我们将尝试将原始 people 数据集与修改后的 test_info 数据集连接起来。\n作为提醒,这里是包含 Alice、Bob 和 Charlie 的 people 数据集:\n\npeople\n\n\n\n\n\n\n\n\nname\nage\n\n\n\n\n0\nAlice\n25\n\n\n1\nBob\n32\n\n\n2\nCharlie\n45\n\n\n\n\n\n\n\n对于测试信息,我们将删除 Charlie,并添加一个新个体 Xavier 及其测试数据:\n\ntest_info_xavier\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nXavier\n2023-05-02\nNegative\n\n\n\n\n\n\n\n我们可以使用 how 参数指定连接类型:\n\npd.merge(people, test_info_xavier, how='left')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\nNaN\nNaN\n\n\n\n\n\n\n\n正如您所见,使用 左 连接时,左 数据框(people)的所有记录都会被保留。因此,即使 Charlie 在 test_info_xavier 数据集中没有匹配,他仍包含在输出中。(但由于他的测试信息在 test_info_xavier 中不可用,这些值被设置为 NaN。)\n另一方面,仅存在于右数据框中的 Xavier 会被删除。\n下图展示了此连接的工作方式:\n\n\n\nLeft Join\n\n\n如果我们颠倒数据框的顺序会怎样?让我们看看当 test_info_xavier 是左数据框,people 是右数据框时的结果:\n\npd.merge(test_info_xavier, people, on='name', how='left')\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\nage\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n25.0\n\n\n1\nBob\n2023-08-10\nPositive\n32.0\n\n\n2\nXavier\n2023-05-02\nNegative\nNaN\n\n\n\n\n\n\n\n同样,left 连接保留了 左 数据框(现在是 test_info_xavier)的所有行。这意味着这次 Xavier 的数据被包含在内。另一方面,Charlie 被排除在外。\n\n\n\n\n\n\n关键点\n\n\n\n主数据集:在连接的上下文中,主数据集指的是操作中的主要或优先数据集。在左连接中,左数据框被视为主数据集,因为其所有行都会保留在输出中,无论它们是否在另一个数据框中有匹配的行。\n\n\n\n\n\n\n\n\n练习\n\n\n\n21.10 练习题:左连接学生和考试日期\n考虑以下两个数据集,一个包含学生详情,另一个包含部分学生的考试日期。\n\nstudents\n\n\n\n\n\n\n\n\nstudent_id\nname\nage\n\n\n\n\n0\n1\nAlice\n20\n\n\n1\n2\nBob\n22\n\n\n2\n3\nCharlie\n21\n\n\n\n\n\n\n\n\nexam_dates\n\n\n\n\n\n\n\n\nstudent_id\nexam_date\n\n\n\n\n0\n1\n2023-05-20\n\n\n1\n3\n2023-05-22\n\n\n\n\n\n\n\n使用左连接将 students 数据集与 exam_dates 数据集连接起来。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#练习题左连接学生和考试日期",
    "href": "p_untangled_joining_1_cn.html#练习题左连接学生和考试日期",
    "title": "21  数据集连接介绍",
    "section": "21.10 练习题:左连接学生和考试日期",
    "text": "21.10 练习题:左连接学生和考试日期\n考虑以下两个数据集,一个包含学生详情,另一个包含部分学生的考试日期。\n\nstudents\n\n\n\n\n\n\n\n\nstudent_id\nname\nage\n\n\n\n\n0\n1\nAlice\n20\n\n\n1\n2\nBob\n22\n\n\n2\n3\nCharlie\n21\n\n\n\n\n\n\n\n\nexam_dates\n\n\n\n\n\n\n\n\nstudent_id\nexam_date\n\n\n\n\n0\n1\n2023-05-20\n\n\n1\n3\n2023-05-22\n\n\n\n\n\n\n\n使用左连接将 students 数据集与 exam_dates 数据集连接起来。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#分析非洲结核病发病率与健康支出",
    "href": "p_untangled_joining_1_cn.html#分析非洲结核病发病率与健康支出",
    "title": "21  数据集连接介绍",
    "section": "21.11 分析非洲结核病发病率与健康支出",
    "text": "21.11 分析非洲结核病发病率与健康支出\n让我们尝试另一个示例,这次使用更实际的一组数据。\n首先,我们有一些非洲国家每 10 万人中的结核病发病率数据,来自世卫组织:\n\ntb_2019_africa\n\n\n\n\n\n\n\n\ncountry\ncases\nconf_int_95\n\n\n\n\n0\nBurundi\n107\n[69 – 153]\n\n\n1\nSao Tome and Principe\n114\n[45 – 214]\n\n\n2\nSenegal\n117\n[83 – 156]\n\n\n3\nMauritius\n12\n[9 – 15]\n\n\n4\nCôte d’Ivoire\n137\n[88 – 197]\n\n\n5\nEthiopia\n140\n[98 – 188]\n\n\n6\nChad\n142\n[92 – 202]\n\n\n7\nGhana\n144\n[70 – 244]\n\n\n8\nMalawi\n146\n[78 – 235]\n\n\n9\nSeychelles\n15\n[13 – 18]\n\n\n10\nGambia\n158\n[117 – 204]\n\n\n11\nGuinea\n176\n[114 – 251]\n\n\n12\nCameroon\n179\n[116 – 255]\n\n\n13\nZimbabwe\n199\n[147 – 258]\n\n\n14\nUganda\n200\n[117 – 303]\n\n\n15\nNigeria\n219\n[143 – 311]\n\n\n16\nSouth Sudan\n227\n[147 – 324]\n\n\n17\nMadagascar\n233\n[151 – 333]\n\n\n18\nUnited Republic of Tanzania\n237\n[112 – 408]\n\n\n19\nBotswana\n253\n[195 – 317]\n\n\n20\nKenya\n267\n[163 – 396]\n\n\n21\nEquatorial Guinea\n286\n[185 – 408]\n\n\n22\nSierra Leone\n295\n[190 – 422]\n\n\n23\nLiberia\n308\n[199 – 440]\n\n\n24\nDemocratic Republic of the Congo\n320\n[207 – 457]\n\n\n25\nZambia\n333\n[216 – 474]\n\n\n26\nComoros\n35\n[23 – 50]\n\n\n27\nAngola\n351\n[227 – 501]\n\n\n28\nMozambique\n361\n[223 – 532]\n\n\n29\nGuinea-Bissau\n361\n[234 – 516]\n\n\n30\nEswatini\n363\n[228 – 527]\n\n\n31\nTogo\n37\n[30 – 45]\n\n\n32\nCongo\n373\n[237 – 541]\n\n\n33\nCabo Verde\n46\n[35 – 58]\n\n\n34\nBurkina Faso\n47\n[30 – 67]\n\n\n35\nNamibia\n486\n[348 – 647]\n\n\n36\nMali\n52\n[34 – 74]\n\n\n37\nGabon\n521\n[337 – 744]\n\n\n38\nCentral African Republic\n540\n[349 – 771]\n\n\n39\nBenin\n55\n[36 – 79]\n\n\n40\nRwanda\n57\n[44 – 72]\n\n\n41\nAlgeria\n61\n[46 – 77]\n\n\n42\nSouth Africa\n615\n[427 – 835]\n\n\n43\nLesotho\n654\n[406 – 959]\n\n\n44\nNiger\n84\n[54 – 120]\n\n\n45\nEritrea\n86\n[40 – 151]\n\n\n46\nMauritania\n89\n[58 – 127]\n\n\n\n\n\n\n\n我们希望分析非洲国家的结核病发病率如何随着人均政府卫生支出的变化而变化。为此,我们有来自世卫组织的按人均美元计的健康支出数据,涵盖所有大洲的国家:\n\nhealth_exp_2019\n\n\n\n\n\n\n\n\ncountry\nexpend_usd\n\n\n\n\n0\nNigeria\n10.97\n\n\n1\nBahamas\n1002.00\n\n\n2\nUnited Arab Emirates\n1015.00\n\n\n3\nNauru\n1038.00\n\n\n4\nSlovakia\n1058.00\n\n\n...\n...\n...\n\n\n180\nMyanmar\n9.64\n\n\n181\nMalawi\n9.78\n\n\n182\nCuba\n901.80\n\n\n183\nTunisia\n97.75\n\n\n184\nNicaragua\n99.73\n\n\n\n\n185 rows × 2 columns\n\n\n\n我们应该使用哪个数据集作为连接的左数据框?\n由于我们的目标是分析非洲国家,我们应该使用 tb_2019_africa 作为左数据框。这将确保在最终的连接数据集中保留所有非洲国家。\n让我们连接它们:\n\ntb_health_exp_joined = pd.merge(tb_2019_africa, health_exp_2019, on='country', how='left')\ntb_health_exp_joined\n\n\n\n\n\n\n\n\ncountry\ncases\nconf_int_95\nexpend_usd\n\n\n\n\n0\nBurundi\n107\n[69 – 153]\n6.07\n\n\n1\nSao Tome and Principe\n114\n[45 – 214]\n47.64\n\n\n2\nSenegal\n117\n[83 – 156]\n15.47\n\n\n3\nMauritius\n12\n[9 – 15]\nNaN\n\n\n4\nCôte d’Ivoire\n137\n[88 – 197]\n22.25\n\n\n5\nEthiopia\n140\n[98 – 188]\n5.93\n\n\n6\nChad\n142\n[92 – 202]\n4.76\n\n\n7\nGhana\n144\n[70 – 244]\n30.01\n\n\n8\nMalawi\n146\n[78 – 235]\n9.78\n\n\n9\nSeychelles\n15\n[13 – 18]\n572.00\n\n\n10\nGambia\n158\n[117 – 204]\n9.40\n\n\n11\nGuinea\n176\n[114 – 251]\n9.61\n\n\n12\nCameroon\n179\n[116 – 255]\n6.26\n\n\n13\nZimbabwe\n199\n[147 – 258]\n7.82\n\n\n14\nUganda\n200\n[117 – 303]\n5.05\n\n\n15\nNigeria\n219\n[143 – 311]\n10.97\n\n\n16\nSouth Sudan\n227\n[147 – 324]\nNaN\n\n\n17\nMadagascar\n233\n[151 – 333]\n6.26\n\n\n18\nUnited Republic of Tanzania\n237\n[112 – 408]\n16.02\n\n\n19\nBotswana\n253\n[195 – 317]\n292.10\n\n\n20\nKenya\n267\n[163 – 396]\n39.57\n\n\n21\nEquatorial Guinea\n286\n[185 – 408]\n47.30\n\n\n22\nSierra Leone\n295\n[190 – 422]\n6.28\n\n\n23\nLiberia\n308\n[199 – 440]\n8.38\n\n\n24\nDemocratic Republic of the Congo\n320\n[207 – 457]\n3.14\n\n\n25\nZambia\n333\n[216 – 474]\n27.09\n\n\n26\nComoros\n35\n[23 – 50]\nNaN\n\n\n27\nAngola\n351\n[227 – 501]\n28.59\n\n\n28\nMozambique\n361\n[223 – 532]\n9.35\n\n\n29\nGuinea-Bissau\n361\n[234 – 516]\n3.90\n\n\n30\nEswatini\n363\n[228 – 527]\n131.50\n\n\n31\nTogo\n37\n[30 – 45]\n7.56\n\n\n32\nCongo\n373\n[237 – 541]\n25.82\n\n\n33\nCabo Verde\n46\n[35 – 58]\n111.50\n\n\n34\nBurkina Faso\n47\n[30 – 67]\n17.17\n\n\n35\nNamibia\n486\n[348 – 647]\n204.30\n\n\n36\nMali\n52\n[34 – 74]\n11.03\n\n\n37\nGabon\n521\n[337 – 744]\n125.60\n\n\n38\nCentral African Republic\n540\n[349 – 771]\n3.58\n\n\n39\nBenin\n55\n[36 – 79]\n6.33\n\n\n40\nRwanda\n57\n[44 – 72]\n20.20\n\n\n41\nAlgeria\n61\n[46 – 77]\n163.00\n\n\n42\nSouth Africa\n615\n[427 – 835]\n321.70\n\n\n43\nLesotho\n654\n[406 – 959]\n53.02\n\n\n44\nNiger\n84\n[54 – 120]\n11.14\n\n\n45\nEritrea\n86\n[40 – 151]\n4.45\n\n\n46\nMauritania\n89\n[58 – 127]\n22.40\n\n\n\n\n\n\n\n现在在连接的数据集中,我们只有非洲国家,这正是我们想要的。\n左数据框 tb_2019_africa 的所有行都被保留,而 health_exp_2019 中的非洲国家被丢弃。\n我们可以通过过滤 NaN 值来检查 tb_2019_africa 中是否有任何行在 health_exp_2019 中没有匹配:\n\ntb_health_exp_joined.query(\"expend_usd.isna()\")\n\n\n\n\n\n\n\n\ncountry\ncases\nconf_int_95\nexpend_usd\n\n\n\n\n3\nMauritius\n12\n[9 – 15]\nNaN\n\n\n16\nSouth Sudan\n227\n[147 – 324]\nNaN\n\n\n26\nComoros\n35\n[23 – 50]\nNaN\n\n\n\n\n\n\n\n这显示有 3 个国家——毛里求斯、南苏丹和科摩罗——在 health_exp_2019 中没有支出数据。但由于它们存在于 tb_2019_africa 中,而 tb_2019_africa 是左数据框,它们仍被包含在连接数据中。\n\n\n\n\n\n\n练习\n\n\n\n21.12 练习题:左连接结核病例和大洲\n第一个数据集 tb_cases_children 包含 2012 年各国 15 岁以下的结核病例数:\n\ntb_cases_children\n\n\n\n\n\n\n\n\ncountry\ntb_cases_smear_0_14\n\n\n\n\n0\nAfghanistan\n588.0\n\n\n1\nAlbania\n0.0\n\n\n2\nAlgeria\n89.0\n\n\n4\nAndorra\n0.0\n\n\n5\nAngola\n982.0\n\n\n...\n...\n...\n\n\n211\nViet Nam\n142.0\n\n\n213\nWest Bank and Gaza Strip\n0.0\n\n\n214\nYemen\n105.0\n\n\n215\nZambia\n321.0\n\n\n216\nZimbabwe\n293.0\n\n\n\n\n200 rows × 2 columns\n\n\n\ncountry_continents 列出了所有国家及其对应的区域和大洲:\n\ncountry_continents\n\n\n\n\n\n\n\n\ncountry.name.en\ncontinent\nregion\n\n\n\n\n0\nAfghanistan\nAsia\nSouth Asia\n\n\n1\nAlbania\nEurope\nEurope & Central Asia\n\n\n2\nAlgeria\nAfrica\nMiddle East & North Africa\n\n\n3\nAmerican Samoa\nOceania\nEast Asia & Pacific\n\n\n4\nAndorra\nEurope\nEurope & Central Asia\n\n\n...\n...\n...\n...\n\n\n286\nYugoslavia\nNaN\nEurope & Central Asia\n\n\n287\nZambia\nAfrica\nSub-Saharan Africa\n\n\n288\nZanzibar\nNaN\nSub-Saharan Africa\n\n\n289\nZimbabwe\nAfrica\nSub-Saharan Africa\n\n\n290\nÅland Islands\nEurope\nEurope & Central Asia\n\n\n\n\n291 rows × 3 columns\n\n\n\n您的目标是将大洲和区域数据添加到结核病例数据集中。\n哪个数据框应该放在左侧?哪个应该放在右侧?一旦决定,使用左连接适当地连接数据集。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#练习题左连接结核病例和大洲",
    "href": "p_untangled_joining_1_cn.html#练习题左连接结核病例和大洲",
    "title": "21  数据集连接介绍",
    "section": "21.12 练习题:左连接结核病例和大洲",
    "text": "21.12 练习题:左连接结核病例和大洲\n第一个数据集 tb_cases_children 包含 2012 年各国 15 岁以下的结核病例数:\n\ntb_cases_children\n\n\n\n\n\n\n\n\ncountry\ntb_cases_smear_0_14\n\n\n\n\n0\nAfghanistan\n588.0\n\n\n1\nAlbania\n0.0\n\n\n2\nAlgeria\n89.0\n\n\n4\nAndorra\n0.0\n\n\n5\nAngola\n982.0\n\n\n...\n...\n...\n\n\n211\nViet Nam\n142.0\n\n\n213\nWest Bank and Gaza Strip\n0.0\n\n\n214\nYemen\n105.0\n\n\n215\nZambia\n321.0\n\n\n216\nZimbabwe\n293.0\n\n\n\n\n200 rows × 2 columns\n\n\n\ncountry_continents 列出了所有国家及其对应的区域和大洲:\n\ncountry_continents\n\n\n\n\n\n\n\n\ncountry.name.en\ncontinent\nregion\n\n\n\n\n0\nAfghanistan\nAsia\nSouth Asia\n\n\n1\nAlbania\nEurope\nEurope & Central Asia\n\n\n2\nAlgeria\nAfrica\nMiddle East & North Africa\n\n\n3\nAmerican Samoa\nOceania\nEast Asia & Pacific\n\n\n4\nAndorra\nEurope\nEurope & Central Asia\n\n\n...\n...\n...\n...\n\n\n286\nYugoslavia\nNaN\nEurope & Central Asia\n\n\n287\nZambia\nAfrica\nSub-Saharan Africa\n\n\n288\nZanzibar\nNaN\nSub-Saharan Africa\n\n\n289\nZimbabwe\nAfrica\nSub-Saharan Africa\n\n\n290\nÅland Islands\nEurope\nEurope & Central Asia\n\n\n\n\n291 rows × 3 columns\n\n\n\n您的目标是将大洲和区域数据添加到结核病例数据集中。\n哪个数据框应该放在左侧?哪个应该放在右侧?一旦决定,使用左连接适当地连接数据集。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#right-连接",
    "href": "p_untangled_joining_1_cn.html#right-连接",
    "title": "21  数据集连接介绍",
    "section": "21.13 right 连接",
    "text": "21.13 right 连接\nright 连接可以被视为 left 连接的镜像。其机制相同,但现在保留 右 数据框的所有行,同时仅保留在右数据框中找到匹配的左数据框行。\n让我们通过一个例子来理解这一点。我们将使用原始的 people 和修改后的 test_info_xavier 数据集:\n\npeople\ntest_info_xavier\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nXavier\n2023-05-02\nNegative\n\n\n\n\n\n\n\n现在让我们尝试进行右连接,将 people 作为右数据框:\n\npd.merge(test_info_xavier, people, on='name', how='right')\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\nage\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n25\n\n\n1\nBob\n2023-08-10\nPositive\n32\n\n\n2\nCharlie\nNaN\nNaN\n45\n\n\n\n\n\n\n\n希望您已经掌握了这一点,并能预测输出!由于 people 是 右 数据框,并且我们使用的是 右 连接,people 中的所有行都会被保留——Alice、Bob 和 Charlie——但仅保留与 test_info_xavier 中匹配的记录。\n下图说明了这一过程:\n\n\n\nRight Join\n\n\n一个重要的点——相同的最终数据框可以通过 left 连接或 right 连接创建;这仅取决于您将数据框提供给这些函数的顺序:\n\n# Here, right join prioritizes the right dataframe, people\npd.merge(test_info_xavier, people, on='name', how='right')\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\nage\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n25\n\n\n1\nBob\n2023-08-10\nPositive\n32\n\n\n2\nCharlie\nNaN\nNaN\n45\n\n\n\n\n\n\n\n\n# Here, left join prioritizes the left dataframe, again people\npd.merge(people, test_info_xavier, on='name', how='left')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\nNaN\nNaN\n\n\n\n\n\n\n\n如前所述,数据科学家通常倾向于使用 left 连接而不是 right 连接。这使得首先指定主要数据集在左侧更加合理。选择使用 left 连接是一种常见的最佳实践,因为其逻辑更清晰,出错的可能性更低。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#inner-连接",
    "href": "p_untangled_joining_1_cn.html#inner-连接",
    "title": "21  数据集连接介绍",
    "section": "21.14 inner 连接",
    "text": "21.14 inner 连接\ninner 连接的独特之处在于,只有在 两个 数据框中都存在连接值的行才会被保留。让我们回到个体及其测试结果的示例。作为提醒,这里是我们的数据集:\n\npeople\n\n\n\n\n\n\n\n\nname\nage\n\n\n\n\n0\nAlice\n25\n\n\n1\nBob\n32\n\n\n2\nCharlie\n45\n\n\n\n\n\n\n\n\ntest_info_xavier\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nXavier\n2023-05-02\nNegative\n\n\n\n\n\n\n\n现在我们对连接的工作原理有了更好的理解,如果我们对上述两个数据框使用 inner 连接,可以预见最终的数据框会是什么样子。如果仅保留两个数据框中 都存在 的连接值的行,并且 people 和 test_info_xavier 中唯一都存在的个体是 Alice 和 Bob,那么他们应该是我们最终数据集中唯一的个体!让我们试试。\n\npd.merge(people, test_info_xavier, on='name', how='inner')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n\n\n\n\n\n完美,这正是我们预期的!这里,Charlie 仅存在于 people 数据集中,Xavier 仅存在于 test_info_xavier 数据集中,因此他们都被移除了。下图显示了这种连接的工作方式:\n\n\n\nInner Join\n\n\n请注意,默认的连接类型是 inner。因此,如果您不指定 how='inner',实际上您正在执行内连接!试试看:\n\npd.merge(people, test_info_xavier)\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n21.15 练习题:内连接产品\n以下是 2019 年产品销售和客户反馈的数据。\n\ntotal_sales\n\n\n\n\n\n\n\n\nproduct\ntotal_units_sold\n\n\n\n\n0\nLaptop\n9751\n\n\n1\nDesktop\n136\n\n\n2\nTablet\n8285\n\n\n3\nSmartphone\n2478\n\n\n4\nSmartwatch\n3642\n\n\n5\nHeadphones\n5231\n\n\n6\nMonitor\n1892\n\n\n7\nKeyboard\n4267\n\n\n8\nMouse\n3891\n\n\n9\nPrinter\n982\n\n\n\n\n\n\n\n\nproduct_feedback\n\n\n\n\n\n\n\n\nproduct\nn_positive_reviews\nn_negative_reviews\n\n\n\n\n0\nLaptop\n1938\n42\n\n\n1\nDesktop\n128\n30\n\n\n2\nTablet\n842\n56\n\n\n3\nSmartphone\n1567\n89\n\n\n4\nSmartwatch\n723\n34\n\n\n5\nHeadphones\n956\n28\n\n\n6\nMonitor\n445\n15\n\n\n7\nGaming Console\n582\n11\n\n\n8\nCamera\n234\n8\n\n\n9\nSpeaker\n678\n25\n\n\n\n\n\n\n\n使用 inner 连接合并这些数据集。\n两个数据集共有多少个产品?\n哪个产品的正面评价与销售单位的比率最高?(应该是桌面电脑)",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#练习题内连接产品",
    "href": "p_untangled_joining_1_cn.html#练习题内连接产品",
    "title": "21  数据集连接介绍",
    "section": "21.15 练习题:内连接产品",
    "text": "21.15 练习题:内连接产品\n以下是 2019 年产品销售和客户反馈的数据。\n\ntotal_sales\n\n\n\n\n\n\n\n\nproduct\ntotal_units_sold\n\n\n\n\n0\nLaptop\n9751\n\n\n1\nDesktop\n136\n\n\n2\nTablet\n8285\n\n\n3\nSmartphone\n2478\n\n\n4\nSmartwatch\n3642\n\n\n5\nHeadphones\n5231\n\n\n6\nMonitor\n1892\n\n\n7\nKeyboard\n4267\n\n\n8\nMouse\n3891\n\n\n9\nPrinter\n982\n\n\n\n\n\n\n\n\nproduct_feedback\n\n\n\n\n\n\n\n\nproduct\nn_positive_reviews\nn_negative_reviews\n\n\n\n\n0\nLaptop\n1938\n42\n\n\n1\nDesktop\n128\n30\n\n\n2\nTablet\n842\n56\n\n\n3\nSmartphone\n1567\n89\n\n\n4\nSmartwatch\n723\n34\n\n\n5\nHeadphones\n956\n28\n\n\n6\nMonitor\n445\n15\n\n\n7\nGaming Console\n582\n11\n\n\n8\nCamera\n234\n8\n\n\n9\nSpeaker\n678\n25\n\n\n\n\n\n\n\n使用 inner 连接合并这些数据集。\n两个数据集共有多少个产品?\n哪个产品的正面评价与销售单位的比率最高?(应该是桌面电脑)",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#outer-连接",
    "href": "p_untangled_joining_1_cn.html#outer-连接",
    "title": "21  数据集连接介绍",
    "section": "21.16 outer 连接",
    "text": "21.16 outer 连接\nouter 连接的特点是它保留 所有 记录,无论两个数据框之间是否存在匹配。在最终的数据集中存在缺失信息的地方,单元格会被设置为 NaN,就像我们在 left 和 right 连接中看到的那样。让我们看一下 people 和 test_info_xavier 数据集来说明这一点。\n这里是我们的数据集的提醒:\n\npeople\ntest_info_xavier\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nXavier\n2023-05-02\nNegative\n\n\n\n\n\n\n\n现在让我们执行 outer 连接:\n\npd.merge(people, test_info_xavier, on='name', how='outer')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25.0\n2023-06-05\nNegative\n\n\n1\nBob\n32.0\n2023-08-10\nPositive\n\n\n2\nCharlie\n45.0\nNaN\nNaN\n\n\n3\nXavier\nNaN\n2023-05-02\nNegative\n\n\n\n\n\n\n\n正如我们所见,所有行都被保留,因此信息没有丢失!下图说明了这个过程:\n\n\n\nOuter Join\n\n\n正如我们上面所看到的,原始两个数据框的所有数据都保留了,任何缺失的信息都被设置为 NaN。\n\n\n\n\n\n\n练习\n\n\n\n21.17 练习题:连接销售数据\n以下数据框包含来自不同年份的全球销售和全球客户投诉数据。\n\nsales\n\n\n\n\n\n\n\n\nyear\nsales_count\n\n\n\n\n0\n2010\n69890\n\n\n1\n2011\n66507\n\n\n2\n2014\n59831\n\n\n3\n2016\n58704\n\n\n4\n2017\n59151\n\n\n\n\n\n\n\n\ncustomer_complaints\n\n\n\n\n\n\n\n\nyear\ncomplaints_count\n\n\n\n\n0\n2011\n1292\n\n\n1\n2013\n1100\n\n\n2\n2015\n1011\n\n\n3\n2016\n940\n\n\n4\n2019\n895\n\n\n\n\n\n\n\n使用适当的连接类型连接上述表格,以保留两个数据集的所有信息。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#练习题连接销售数据",
    "href": "p_untangled_joining_1_cn.html#练习题连接销售数据",
    "title": "21  数据集连接介绍",
    "section": "21.17 练习题:连接销售数据",
    "text": "21.17 练习题:连接销售数据\n以下数据框包含来自不同年份的全球销售和全球客户投诉数据。\n\nsales\n\n\n\n\n\n\n\n\nyear\nsales_count\n\n\n\n\n0\n2010\n69890\n\n\n1\n2011\n66507\n\n\n2\n2014\n59831\n\n\n3\n2016\n58704\n\n\n4\n2017\n59151\n\n\n\n\n\n\n\n\ncustomer_complaints\n\n\n\n\n\n\n\n\nyear\ncomplaints_count\n\n\n\n\n0\n2011\n1292\n\n\n1\n2013\n1100\n\n\n2\n2015\n1011\n\n\n3\n2016\n940\n\n\n4\n2019\n895\n\n\n\n\n\n\n\n使用适当的连接类型连接上述表格,以保留两个数据集的所有信息。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_1_cn.html#总结",
    "href": "p_untangled_joining_1_cn.html#总结",
    "title": "21  数据集连接介绍",
    "section": "21.18 总结!",
    "text": "21.18 总结!\n做得好,您现在了解了连接的基础知识!下图中的维恩图对不同的连接类型及其保留的信息进行了有用的总结。保存这张图片以供将来参考可能会很有帮助!\n\n\n\nJoin Types",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>数据集连接介绍</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html",
    "href": "p_untangled_joining_2_cn.html",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "",
    "text": "22.1 包\nimport pandas as pd\nimport country_converter as cc",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#数据",
    "href": "p_untangled_joining_2_cn.html#数据",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.2 数据",
    "text": "22.2 数据\n运行以下代码以加载和定义本课程中使用的数据集。\n\n# 加载数据集\noil_consumption = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/oil_consumption.csv\"\n)\ntidyr_population = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/tidyr_population.csv\"\n)\ncountry_regions = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/country_continent_data.csv\"\n)\n\n\noil_2012 = (\n    oil_consumption[oil_consumption[\"year\"] == 2012].copy().drop(columns=[\"year\"])\n)\n\n# 人员数据\npeople = pd.DataFrame({\"name\": [\"Alice\", \"Bob\", \"Charlie\"], \"age\": [25, 32, 45]})\n\ntest_info_many = pd.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Alice\", \"Bob\", \"Bob\", \"Charlie\", \"Charlie\"],\n        \"test_date\": [\n            \"2023-06-05\",\n            \"2023-06-10\",\n            \"2023-08-10\",\n            \"2023-05-02\",\n            \"2023-05-12\",\n            \"2023-05-15\",\n        ],\n        \"result\": [\n            \"Negative\",\n            \"Positive\",\n            \"Positive\",\n            \"Negative\",\n            \"Negative\",\n            \"Negative\",\n        ],\n    }\n)\n\nfarm_info = pd.DataFrame(\n    {\n        \"farm_id\": [1, 2, 3],\n        \"farm_name\": [\"Green Acres\", \"Harvest Hill\", \"Golden Fields\"],\n        \"location\": [\"County A\", \"County B\", \"County A\"],\n    }\n)\n\ncrop_yields = pd.DataFrame(\n    {\n        \"farm_id\": [1, 1, 2, 3, 3],\n        \"crop\": [\"Wheat\", \"Corn\", \"Soybeans\", \"Wheat\", \"Barley\"],\n        \"yield_tons\": [50, 60, 45, 55, 30],\n    }\n)\n\ntraffic_flow = pd.DataFrame(\n    {\n        \"street_name\": [\n            \"Main St\",\n            \"Main St\",\n            \"Broadway\",\n            \"Broadway\",\n            \"Elm St\",\n            \"Elm St\",\n        ],\n        \"time_of_day\": [\"9am\", \"2pm\", \"9am\", \"2pm\", \"9am\", \"2pm\"],\n        \"vehicle_count\": [1200, 900, 1500, 1100, 700, 600],\n    }\n)\n\npollution_levels = pd.DataFrame(\n    {\n        \"street_name\": [\n            \"Main St\",\n            \"Main St\",\n            \"Broadway\",\n            \"Broadway\",\n            \"Elm St\",\n            \"Elm St\",\n        ],\n        \"time_of_day\": [\"9am\", \"2pm\", \"9am\", \"2pm\", \"9am\", \"2pm\"],\n        \"pm_2_5_level\": [35.5, 42.1, 40.3, 48.2, 25.7, 30.9],\n    }\n)\n\ntest_info_diff = pd.DataFrame(\n    {\n        \"name\": [\"alice\", \"Bob\", \"Charlie \"],\n        \"test_date\": [\"2023-06-05\", \"2023-08-10\", \"2023-05-02\"],\n        \"result\": [\"Negative\", \"Positive\", \"Negative\"],\n    }\n)\n\nasia_countries = pd.DataFrame(\n    {\n        \"Country\": [\"India\", \"Indonesia\", \"Philippines\"],\n        \"Capital\": [\"New Delhi\", \"Jakarta\", \"Manila\"],\n    }\n)\n\nasia_population = pd.DataFrame(\n    {\n        \"Country\": [\"India\", \"indonesia\", \"Philipines\"],\n        \"Population\": [1393000000, 273500000, 113000000],\n        \"Life_Expectancy\": [69.7, 71.7, 72.7],\n    }\n)",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#介绍",
    "href": "p_untangled_joining_2_cn.html#介绍",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.3 介绍",
    "text": "22.3 介绍\n现在我们对不同类型的连接及其工作原理有了扎实的掌握,我们可以看看如何管理更复杂的连接和更混乱的数据。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#学习目标",
    "href": "p_untangled_joining_2_cn.html#学习目标",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.4 学习目标",
    "text": "22.4 学习目标\n\n您了解一对多连接的概念\n您知道如何在多个键列上进行连接\n您知道如何检查数据框之间的不匹配值",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#一对多连接",
    "href": "p_untangled_joining_2_cn.html#一对多连接",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.5 一对多连接",
    "text": "22.5 一对多连接\n到目前为止,我们主要研究了一对一连接,其中一个数据框中的一个观测值对应另一个数据框中的仅一个观测值。在一对多连接中,一个数据框中的一个观测值对应另一个数据框中的多个观测值。\n为了说明一对多连接,让我们回到患者及其 COVID 测试数据。假设在我们的数据集中,Alice 和 Xavier 多次接受了 COVID 测试。我们可以在 test_info 数据框中添加两行他们的新测试信息:\n\npeople\n\n\n\n\n\n\n\n\nname\nage\n\n\n\n\n0\nAlice\n25\n\n\n1\nBob\n32\n\n\n2\nCharlie\n45\n\n\n\n\n\n\n\n\ntest_info_many\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nAlice\n2023-06-10\nPositive\n\n\n2\nBob\n2023-08-10\nPositive\n\n\n3\nBob\n2023-05-02\nNegative\n\n\n4\nCharlie\n2023-05-12\nNegative\n\n\n5\nCharlie\n2023-05-15\nNegative\n\n\n\n\n\n\n\n接下来,让我们看看当我们使用 people 作为左数据框进行 merge() 时会发生什么:\n\npd.merge(people, test_info_many, on=\"name\", how=\"left\")\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nAlice\n25\n2023-06-10\nPositive\n\n\n2\nBob\n32\n2023-08-10\nPositive\n\n\n3\nBob\n32\n2023-05-02\nNegative\n\n\n4\nCharlie\n45\n2023-05-12\nNegative\n\n\n5\nCharlie\n45\n2023-05-15\nNegative\n\n\n\n\n\n\n\n上面发生了什么?基本上,当您执行一对多连接时,“一”方的数据会为“多”方的每个匹配行重复。\n\n\n\n\n\n\n练习\n\n\n\n22.6 练习题:合并一对多农作物产量\n运行以下代码以打印两个小数据框:\n\nfarm_info\n\n\n\n\n\n\n\n\nfarm_id\nfarm_name\nlocation\n\n\n\n\n0\n1\nGreen Acres\nCounty A\n\n\n1\n2\nHarvest Hill\nCounty B\n\n\n2\n3\nGolden Fields\nCounty A\n\n\n\n\n\n\n\n\ncrop_yields\n\n\n\n\n\n\n\n\nfarm_id\ncrop\nyield_tons\n\n\n\n\n0\n1\nWheat\n50\n\n\n1\n1\nCorn\n60\n\n\n2\n2\nSoybeans\n45\n\n\n3\n3\nWheat\n55\n\n\n4\n3\nBarley\n30\n\n\n\n\n\n\n\n如果您使用 merge() 来连接这些数据集,最终的数据框中将有多少行?试着计算一下,然后执行连接以查看答案是否正确。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#练习题合并一对多农作物产量",
    "href": "p_untangled_joining_2_cn.html#练习题合并一对多农作物产量",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.6 练习题:合并一对多农作物产量",
    "text": "22.6 练习题:合并一对多农作物产量\n运行以下代码以打印两个小数据框:\n\nfarm_info\n\n\n\n\n\n\n\n\nfarm_id\nfarm_name\nlocation\n\n\n\n\n0\n1\nGreen Acres\nCounty A\n\n\n1\n2\nHarvest Hill\nCounty B\n\n\n2\n3\nGolden Fields\nCounty A\n\n\n\n\n\n\n\n\ncrop_yields\n\n\n\n\n\n\n\n\nfarm_id\ncrop\nyield_tons\n\n\n\n\n0\n1\nWheat\n50\n\n\n1\n1\nCorn\n60\n\n\n2\n2\nSoybeans\n45\n\n\n3\n3\nWheat\n55\n\n\n4\n3\nBarley\n30\n\n\n\n\n\n\n\n如果您使用 merge() 来连接这些数据集,最终的数据框中将有多少行?试着计算一下,然后执行连接以查看答案是否正确。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#多键列",
    "href": "p_untangled_joining_2_cn.html#多键列",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.7 多键列",
    "text": "22.7 多键列\n有时我们有不止一个列可以唯一标识我们想要匹配的观测值。例如,假设我们有三条街道在两个不同时间点(上午 9 点和下午 2 点)的交通流量数据。\n\ntraffic_flow\n\n\n\n\n\n\n\n\nstreet_name\ntime_of_day\nvehicle_count\n\n\n\n\n0\nMain St\n9am\n1200\n\n\n1\nMain St\n2pm\n900\n\n\n2\nBroadway\n9am\n1500\n\n\n3\nBroadway\n2pm\n1100\n\n\n4\nElm St\n9am\n700\n\n\n5\nElm St\n2pm\n600\n\n\n\n\n\n\n\n现在,假设我们有另一组针对相同三条街道在同一时间点记录的空气污染水平(以颗粒物 PM2.5 衡量)数据。\n\npollution_levels\n\n\n\n\n\n\n\n\nstreet_name\ntime_of_day\npm_2_5_level\n\n\n\n\n0\nMain St\n9am\n35.5\n\n\n1\nMain St\n2pm\n42.1\n\n\n2\nBroadway\n9am\n40.3\n\n\n3\nBroadway\n2pm\n48.2\n\n\n4\nElm St\n9am\n25.7\n\n\n5\nElm St\n2pm\n30.9\n\n\n\n\n\n\n\n我们想要连接这两个数据集,使每条街道有两行:一行对应上午 9 点,一行对应下午 2 点。为此,我们的第一个直觉可能是仅在 street_name 上进行连接。让我们试一下,看看会发生什么:\n\npd.merge(traffic_flow, pollution_levels, on=\"street_name\", how=\"left\")\n\n\n\n\n\n\n\n\nstreet_name\ntime_of_day_x\nvehicle_count\ntime_of_day_y\npm_2_5_level\n\n\n\n\n0\nMain St\n9am\n1200\n9am\n35.5\n\n\n1\nMain St\n9am\n1200\n2pm\n42.1\n\n\n2\nMain St\n2pm\n900\n9am\n35.5\n\n\n3\nMain St\n2pm\n900\n2pm\n42.1\n\n\n4\nBroadway\n9am\n1500\n9am\n40.3\n\n\n5\nBroadway\n9am\n1500\n2pm\n48.2\n\n\n6\nBroadway\n2pm\n1100\n9am\n40.3\n\n\n7\nBroadway\n2pm\n1100\n2pm\n48.2\n\n\n8\nElm St\n9am\n700\n9am\n25.7\n\n\n9\nElm St\n9am\n700\n2pm\n30.9\n\n\n10\nElm St\n2pm\n600\n9am\n25.7\n\n\n11\nElm St\n2pm\n600\n2pm\n30.9\n\n\n\n\n\n\n\n如我们所见,这完全不是我们想要的结果!我们得到了重复的行——每条街道现在有四行。\n我们想要的是同时匹配 street_name 和 time_of_day。为此,我们需要通过在列表中指定两个列名,告诉 Python 要在两列上匹配。\n\npd.merge(traffic_flow, pollution_levels, on=[\"street_name\", \"time_of_day\"])\n\n\n\n\n\n\n\n\nstreet_name\ntime_of_day\nvehicle_count\npm_2_5_level\n\n\n\n\n0\nMain St\n9am\n1200\n35.5\n\n\n1\nMain St\n2pm\n900\n42.1\n\n\n2\nBroadway\n9am\n1500\n40.3\n\n\n3\nBroadway\n2pm\n1100\n48.2\n\n\n4\nElm St\n9am\n700\n25.7\n\n\n5\nElm St\n2pm\n600\n30.9\n\n\n\n\n\n\n\n现在我们有了正确的行数!我们可以直接看到每条街道在每个时间点的车辆数量和 PM2.5 水平。\n\n\n\n\n\n\n练习\n\n\n\n22.8 练习题:计算人均油耗\n我们有两个包含国家信息的数据集:\n\noil_consumption:包含年度油耗(吨)\ntidyr_population:包含年度人口数据\n\n\n# 查看数据集\noil_consumption.sort_values(by=[\"country\", \"year\"])\n\n\n\n\n\n\n\n\ncountry\nyear\noil_consump\n\n\n\n\n19\nAlgeria\n1995\n8430000\n\n\n98\nAlgeria\n1996\n8060000\n\n\n177\nAlgeria\n1997\n7990000\n\n\n256\nAlgeria\n1998\n8220000\n\n\n335\nAlgeria\n1999\n8110000\n\n\n...\n...\n...\n...\n\n\n1183\nVietnam\n2009\n14200000\n\n\n1262\nVietnam\n2010\n15300000\n\n\n1341\nVietnam\n2011\n16700000\n\n\n1420\nVietnam\n2012\n17000000\n\n\n1499\nVietnam\n2013\n18200000\n\n\n\n\n1501 rows × 3 columns\n\n\n\n\ntidyr_population.sort_values(by=[\"country\", \"year\"])\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\n0\nAfghanistan\n1995\n17586073\n\n\n1\nAfghanistan\n1996\n18415307\n\n\n2\nAfghanistan\n1997\n19021226\n\n\n3\nAfghanistan\n1998\n19496836\n\n\n4\nAfghanistan\n1999\n19987071\n\n\n...\n...\n...\n...\n\n\n4040\nZimbabwe\n2009\n12888918\n\n\n4041\nZimbabwe\n2010\n13076978\n\n\n4042\nZimbabwe\n2011\n13358738\n\n\n4043\nZimbabwe\n2012\n13724317\n\n\n4044\nZimbabwe\n2013\n14149648\n\n\n\n\n4045 rows × 3 columns\n\n\n\n\n使用左连接的 merge() 连接这些数据集。由于我们想匹配国家和年份,您需要在多个列上进行连接。(您可能会注意到并非所有行都匹配。您可以暂时忽略这一点。)\n连接后,创建一个名为 consumption_per_capita 的新列,计算每人的年度油耗(吨)。\n1995 年哪个国家的人均油耗最高?",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#练习题计算人均油耗",
    "href": "p_untangled_joining_2_cn.html#练习题计算人均油耗",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.8 练习题:计算人均油耗",
    "text": "22.8 练习题:计算人均油耗\n我们有两个包含国家信息的数据集:\n\noil_consumption:包含年度油耗(吨)\ntidyr_population:包含年度人口数据\n\n\n# 查看数据集\noil_consumption.sort_values(by=[\"country\", \"year\"])\n\n\n\n\n\n\n\n\ncountry\nyear\noil_consump\n\n\n\n\n19\nAlgeria\n1995\n8430000\n\n\n98\nAlgeria\n1996\n8060000\n\n\n177\nAlgeria\n1997\n7990000\n\n\n256\nAlgeria\n1998\n8220000\n\n\n335\nAlgeria\n1999\n8110000\n\n\n...\n...\n...\n...\n\n\n1183\nVietnam\n2009\n14200000\n\n\n1262\nVietnam\n2010\n15300000\n\n\n1341\nVietnam\n2011\n16700000\n\n\n1420\nVietnam\n2012\n17000000\n\n\n1499\nVietnam\n2013\n18200000\n\n\n\n\n1501 rows × 3 columns\n\n\n\n\ntidyr_population.sort_values(by=[\"country\", \"year\"])\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\n0\nAfghanistan\n1995\n17586073\n\n\n1\nAfghanistan\n1996\n18415307\n\n\n2\nAfghanistan\n1997\n19021226\n\n\n3\nAfghanistan\n1998\n19496836\n\n\n4\nAfghanistan\n1999\n19987071\n\n\n...\n...\n...\n...\n\n\n4040\nZimbabwe\n2009\n12888918\n\n\n4041\nZimbabwe\n2010\n13076978\n\n\n4042\nZimbabwe\n2011\n13358738\n\n\n4043\nZimbabwe\n2012\n13724317\n\n\n4044\nZimbabwe\n2013\n14149648\n\n\n\n\n4045 rows × 3 columns\n\n\n\n\n使用左连接的 merge() 连接这些数据集。由于我们想匹配国家和年份,您需要在多个列上进行连接。(您可能会注意到并非所有行都匹配。您可以暂时忽略这一点。)\n连接后,创建一个名为 consumption_per_capita 的新列,计算每人的年度油耗(吨)。\n1995 年哪个国家的人均油耗最高?",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#键不匹配",
    "href": "p_untangled_joining_2_cn.html#键不匹配",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.9 键不匹配",
    "text": "22.9 键不匹配\n在从不同来源提取数据后,您通常需要预先清理数据,才能进行连接。这是因为记录值的方式可能存在不一致。\n举例来说,让我们回到第一课的模拟患者数据。如果您还记得,我们有两个数据框,一个名为 people,另一个名为 test_info。我们可以重新创建这些数据集,但将 test_info_diff 数据集中的 Alice 更改为 alice,并保持所有其他值不变。\n\npeople\n\n\n\n\n\n\n\n\nname\nage\n\n\n\n\n0\nAlice\n25\n\n\n1\nBob\n32\n\n\n2\nCharlie\n45\n\n\n\n\n\n\n\n\ntest_info_diff\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nalice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n2023-05-02\nNegative\n\n\n\n\n\n\n\n现在让我们尝试对这两个数据集进行 merge()。\n\npeople.merge(test_info_diff, on='name', how='left')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\nNaN\nNaN\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\nNaN\nNaN\n\n\n\n\n\n\n\n\npd.merge(people, test_info_diff, on=\"name\", how=\"inner\")\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nBob\n32\n2023-08-10\nPositive\n\n\n\n\n\n\n\n如我们所见,Python 没有将 Alice 和 alice 识别为同一个人,并且它也无法匹配 Charlie 和 Charlie!因此,在左连接中我们失去了 Alice 和 Charlie,在内连接中它们被删除了。\n我们如何解决这个问题?我们需要确保两个数据集中的名称格式相同。为此,我们可以使用 str.title() 将每个名称的首字母大写。\n\ntest_info_diff['name'] = test_info_diff['name'].str.title()\ntest_info_diff\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n2023-05-02\nNegative\n\n\n\n\n\n\n\n\npeople.merge(test_info_diff, on='name', how='inner')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n\n\n\n\n\n嗯,Charlie 仍然没有匹配。从打印输出中很难看出,但 test_info_diff 中的字符串 Charlie 在末尾有一个额外的空格。\n我们可以通过使用 .unique() 将其转换为数组来更好地发现这一点:\n\ntest_info_diff['name'].unique()\n\narray(['Alice', 'Bob', 'Charlie '], dtype=object)\n\n\n我们可以使用 str.strip() 来移除额外的空格。\n\ntest_info_diff['name'] = test_info_diff['name'].str.strip()\ntest_info_diff\n\n\n\n\n\n\n\n\nname\ntest_date\nresult\n\n\n\n\n0\nAlice\n2023-06-05\nNegative\n\n\n1\nBob\n2023-08-10\nPositive\n\n\n2\nCharlie\n2023-05-02\nNegative\n\n\n\n\n\n\n\n现在我们可以连接这两个数据集:\n\npeople.merge(test_info_diff, on='name', how='inner')\n\n\n\n\n\n\n\n\nname\nage\ntest_date\nresult\n\n\n\n\n0\nAlice\n25\n2023-06-05\nNegative\n\n\n1\nBob\n32\n2023-08-10\nPositive\n\n\n2\nCharlie\n45\n2023-05-02\nNegative\n\n\n\n\n\n\n\n完美!\n\n\n\n\n\n\n练习\n\n\n\n22.10 练习题:内连接国家\n以下两个数据集包含印度、印度尼西亚和菲律宾的数据。然而,这些数据集的 inner 连接仅返回 1 行。\n\nasia_countries\n\n\n\n\n\n\n\n\nCountry\nCapital\n\n\n\n\n0\nIndia\nNew Delhi\n\n\n1\nIndonesia\nJakarta\n\n\n2\nPhilippines\nManila\n\n\n\n\n\n\n\n\nasia_population\n\n\n\n\n\n\n\n\nCountry\nPopulation\nLife_Expectancy\n\n\n\n\n0\nIndia\n1393000000\n69.7\n\n\n1\nindonesia\n273500000\n71.7\n\n\n2\nPhilipines\n113000000\n72.7\n\n\n\n\n\n\n\n\npd.merge(asia_countries, asia_population)\n\n\n\n\n\n\n\n\nCountry\nCapital\nPopulation\nLife_Expectancy\n\n\n\n\n0\nIndia\nNew Delhi\n1393000000\n69.7\n\n\n\n\n\n\n\n键列中的值有哪些差异需要在连接数据集之前进行更改?请注意大小写和拼写。\n现在,修复 Country 列中不匹配的值,然后再次尝试连接。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#练习题内连接国家",
    "href": "p_untangled_joining_2_cn.html#练习题内连接国家",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.10 练习题:内连接国家",
    "text": "22.10 练习题:内连接国家\n以下两个数据集包含印度、印度尼西亚和菲律宾的数据。然而,这些数据集的 inner 连接仅返回 1 行。\n\nasia_countries\n\n\n\n\n\n\n\n\nCountry\nCapital\n\n\n\n\n0\nIndia\nNew Delhi\n\n\n1\nIndonesia\nJakarta\n\n\n2\nPhilippines\nManila\n\n\n\n\n\n\n\n\nasia_population\n\n\n\n\n\n\n\n\nCountry\nPopulation\nLife_Expectancy\n\n\n\n\n0\nIndia\n1393000000\n69.7\n\n\n1\nindonesia\n273500000\n71.7\n\n\n2\nPhilipines\n113000000\n72.7\n\n\n\n\n\n\n\n\npd.merge(asia_countries, asia_population)\n\n\n\n\n\n\n\n\nCountry\nCapital\nPopulation\nLife_Expectancy\n\n\n\n\n0\nIndia\nNew Delhi\n1393000000\n69.7\n\n\n\n\n\n\n\n键列中的值有哪些差异需要在连接数据集之前进行更改?请注意大小写和拼写。\n现在,修复 Country 列中不匹配的值,然后再次尝试连接。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#键不匹配油耗示例",
    "href": "p_untangled_joining_2_cn.html#键不匹配油耗示例",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.11 键不匹配:油耗示例",
    "text": "22.11 键不匹配:油耗示例\n现在让我们看一个键不匹配如何导致问题的更现实的例子。\n\noil_consumption\n\n\n\n\n\n\n\n\ncountry\nyear\noil_consump\n\n\n\n\n0\nUnited Arab Emirates\n1995\n20800000\n\n\n1\nArgentina\n1995\n20300000\n\n\n2\nAustralia\n1995\n36500000\n\n\n3\nAustria\n1995\n11300000\n\n\n4\nAzerbaijan\n1995\n6580000\n\n\n...\n...\n...\n...\n\n\n1496\nUSA\n2013\n791000000\n\n\n1497\nUzbekistan\n2013\n2860000\n\n\n1498\nVenezuela\n2013\n36800000\n\n\n1499\nVietnam\n2013\n18200000\n\n\n1500\nSouth Africa\n2013\n26700000\n\n\n\n\n1501 rows × 3 columns\n\n\n\n\ntidyr_population\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\n0\nAfghanistan\n1995\n17586073\n\n\n1\nAfghanistan\n1996\n18415307\n\n\n2\nAfghanistan\n1997\n19021226\n\n\n3\nAfghanistan\n1998\n19496836\n\n\n4\nAfghanistan\n1999\n19987071\n\n\n...\n...\n...\n...\n\n\n4040\nZimbabwe\n2009\n12888918\n\n\n4041\nZimbabwe\n2010\n13076978\n\n\n4042\nZimbabwe\n2011\n13358738\n\n\n4043\nZimbabwe\n2012\n13724317\n\n\n4044\nZimbabwe\n2013\n14149648\n\n\n\n\n4045 rows × 3 columns\n\n\n\n尝试进行连接后,我们发现一些国家没有匹配,例如越南。\n\npd.merge(\n    oil_consumption, tidyr_population, on=[\"country\", \"year\"], how=\"left\"\n).sort_values([\"country\", \"year\"])\n\n\n\n\n\n\n\n\ncountry\nyear\noil_consump\npopulation\n\n\n\n\n19\nAlgeria\n1995\n8430000\n29315463.0\n\n\n98\nAlgeria\n1996\n8060000\n29845208.0\n\n\n177\nAlgeria\n1997\n7990000\n30345466.0\n\n\n256\nAlgeria\n1998\n8220000\n30820435.0\n\n\n335\nAlgeria\n1999\n8110000\n31276295.0\n\n\n...\n...\n...\n...\n...\n\n\n1183\nVietnam\n2009\n14200000\nNaN\n\n\n1262\nVietnam\n2010\n15300000\nNaN\n\n\n1341\nVietnam\n2011\n16700000\nNaN\n\n\n1420\nVietnam\n2012\n17000000\nNaN\n\n\n1499\nVietnam\n2013\n18200000\nNaN\n\n\n\n\n1501 rows × 4 columns\n\n\n\n这是因为两个数据集中的国家名称格式不一致。\n在尝试连接这些数据集之前,最好检查键列中的不匹配。这可以帮助您识别可能阻止成功连接的任何差异。\n首先,让我们识别两个数据集中唯一的国家名称。\n\noil_countries = set(oil_consumption['country'].unique())\npop_countries = set(tidyr_population['country'].unique())\n\n现在,要查找在 oil_consumption 中但不在 tidyr_population 中的国家,我们可以使用集合运算:\n\nmissing_in_pop = oil_countries - pop_countries\nmissing_in_pop\n\n{'Hong Kong, China',\n 'Iran',\n 'North Macedonia',\n 'Russia',\n 'Slovak Republic',\n 'South Korea',\n 'Taiwan',\n 'UK',\n 'USA',\n 'Venezuela',\n 'Vietnam'}\n\n\n以及在 tidyr_population 中但不在 oil_consumption 中的国家:\n\nmissing_in_oil = pop_countries - oil_countries\nmissing_in_oil\n\n{'Afghanistan',\n 'Albania',\n 'American Samoa',\n 'Andorra',\n 'Angola',\n 'Anguilla',\n 'Antigua and Barbuda',\n 'Armenia',\n 'Aruba',\n 'Bahamas',\n 'Bahrain',\n 'Barbados',\n 'Belize',\n 'Benin',\n 'Bermuda',\n 'Bhutan',\n 'Bolivia (Plurinational State of)',\n 'Bonaire, Saint Eustatius and Saba',\n 'Bosnia and Herzegovina',\n 'Botswana',\n 'British Virgin Islands',\n 'Brunei Darussalam',\n 'Burkina Faso',\n 'Burundi',\n 'Cabo Verde',\n 'Cambodia',\n 'Cameroon',\n 'Cayman Islands',\n 'Central African Republic',\n 'Chad',\n 'China, Hong Kong SAR',\n 'China, Macao SAR',\n 'Comoros',\n 'Congo',\n 'Cook Islands',\n 'Costa Rica',\n 'Cuba',\n 'Curaçao',\n \"Côte d'Ivoire\",\n \"Democratic People's Republic of Korea\",\n 'Democratic Republic of the Congo',\n 'Djibouti',\n 'Dominica',\n 'Dominican Republic',\n 'El Salvador',\n 'Equatorial Guinea',\n 'Eritrea',\n 'Ethiopia',\n 'Fiji',\n 'French Polynesia',\n 'Gabon',\n 'Gambia',\n 'Georgia',\n 'Ghana',\n 'Greenland',\n 'Grenada',\n 'Guam',\n 'Guatemala',\n 'Guinea',\n 'Guinea-Bissau',\n 'Guyana',\n 'Haiti',\n 'Honduras',\n 'Iran (Islamic Republic of)',\n 'Jamaica',\n 'Jordan',\n 'Kenya',\n 'Kiribati',\n 'Kyrgyzstan',\n \"Lao People's Democratic Republic\",\n 'Lebanon',\n 'Lesotho',\n 'Liberia',\n 'Libya',\n 'Madagascar',\n 'Malawi',\n 'Maldives',\n 'Mali',\n 'Malta',\n 'Marshall Islands',\n 'Mauritania',\n 'Mauritius',\n 'Micronesia (Federated States of)',\n 'Monaco',\n 'Mongolia',\n 'Montenegro',\n 'Montserrat',\n 'Mozambique',\n 'Myanmar',\n 'Namibia',\n 'Nauru',\n 'Nepal',\n 'New Caledonia',\n 'Nicaragua',\n 'Niger',\n 'Nigeria',\n 'Niue',\n 'Northern Mariana Islands',\n 'Palau',\n 'Panama',\n 'Papua New Guinea',\n 'Paraguay',\n 'Puerto Rico',\n 'Republic of Korea',\n 'Republic of Moldova',\n 'Russian Federation',\n 'Rwanda',\n 'Saint Kitts and Nevis',\n 'Saint Lucia',\n 'Saint Vincent and the Grenadines',\n 'Samoa',\n 'San Marino',\n 'Sao Tome and Principe',\n 'Senegal',\n 'Serbia',\n 'Seychelles',\n 'Sierra Leone',\n 'Sint Maarten (Dutch part)',\n 'Slovakia',\n 'Solomon Islands',\n 'Somalia',\n 'South Sudan',\n 'Sudan',\n 'Suriname',\n 'Swaziland',\n 'Syrian Arab Republic',\n 'Tajikistan',\n 'The Former Yugoslav Republic of Macedonia',\n 'Timor-Leste',\n 'Togo',\n 'Tokelau',\n 'Tonga',\n 'Tunisia',\n 'Turks and Caicos Islands',\n 'Tuvalu',\n 'US Virgin Islands',\n 'Uganda',\n 'United Kingdom of Great Britain and Northern Ireland',\n 'United Republic of Tanzania',\n 'United States of America',\n 'Uruguay',\n 'Vanuatu',\n 'Venezuela (Bolivarian Republic of)',\n 'Viet Nam',\n 'Wallis and Futuna Islands',\n 'West Bank and Gaza Strip',\n 'Yemen',\n 'Zambia',\n 'Zimbabwe'}\n\n\n这些差异表明键列中存在不匹配,需要在连接之前解决。\n您可能会尝试手动检查。例如,我们可以看到越南在一个数据集中写作 Vietnam,在另一个数据集中写作 Viet Nam。\n然而,对于国家来说,还有一个更好的解决方案:使用国家代码!我们将在下一节中看到如何做到这一点。\n\n\n\n\n\n\n旁注\n\n\n\n22.12 集合运算\n对于不熟悉的人来说,快速介绍一下集合运算。\n考虑两个数字集合 1:5 和 2:4。\n\nset_1 = set([1, 2, 3, 4, 5])\nset_2 = set([2, 3, 4])\n\n我们可以通过集合运算检查 set_1 中不在 set_2 中的值:\n\nset_1 - set_2\n\n{1, 5}\n\n\n以及使用以下方法检查 set_2 中不在 set_1 中的值:\n\nset_2 - set_1\n\nset()\n\n\n\n\n\n22.12.1 使用国家代码进行合并\n为了避免国家不匹配,通常使用国家代码而不是国家名称作为键会很有用。\n现在,让我们向两个数据集中添加国家代码并再次尝试连接。\n\n# 如何使用 country_converter\ncc.convert(\"Nigeria\", to='ISO3')\n\n'NGA'\n\n\n\noil_consumption['country_code'] = cc.convert(oil_consumption['country'], to='ISO3')\ntidyr_population['country_code'] = cc.convert(tidyr_population['country'], to='ISO3')\n\n\noil_pop_code = oil_consumption.merge(tidyr_population, on=['country_code', 'year'], how='left')\n\n\n\n22.12.2 识别剩余的不匹配\n让我们看看哪些国家仍未找到匹配:\n\nset(oil_pop_code['country_code'].unique()) - set(tidyr_population['country_code'].unique())\n\n{'TWN'}\n\n\n似乎 ‘TWN’(台湾)未能找到匹配。我们可以手动查看 tidyr_population 数据集,看看是否能找到它。\n\ntidyr_population.query(\"country.str.contains('Taiwan')\")\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\ncountry_code\n\n\n\n\n\n\n\n\n\n为了防止大小写不匹配,我们还可以检查 ‘taiwan’:\n\ntidyr_population.query(\"country.str.contains('taiwan')\")\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\ncountry_code\n\n\n\n\n\n\n\n\n\n我们还可以检查 ‘China’,因为目前关于台湾是否属于中国存在争议。\n\ntidyr_population.query(\"country.str.contains('China')\")\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\ncountry_code\n\n\n\n\n783\nChina\n1995\n1237531429\nCHN\n\n\n784\nChina\n1996\n1247897092\nCHN\n\n\n785\nChina\n1997\n1257021784\nCHN\n\n\n786\nChina\n1998\n1265222536\nCHN\n\n\n787\nChina\n1999\n1272915272\nCHN\n\n\n788\nChina\n2000\n1280428583\nCHN\n\n\n789\nChina\n2001\n1287890449\nCHN\n\n\n790\nChina\n2002\n1295322020\nCHN\n\n\n791\nChina\n2003\n1302810258\nCHN\n\n\n792\nChina\n2004\n1310414386\nCHN\n\n\n793\nChina\n2005\n1318176835\nCHN\n\n\n794\nChina\n2006\n1326146433\nCHN\n\n\n795\nChina\n2007\n1334343509\nCHN\n\n\n796\nChina\n2008\n1342732604\nCHN\n\n\n797\nChina\n2009\n1351247555\nCHN\n\n\n798\nChina\n2010\n1359821465\nCHN\n\n\n799\nChina\n2011\n1368440300\nCHN\n\n\n800\nChina\n2012\n1377064907\nCHN\n\n\n801\nChina\n2013\n1385566537\nCHN\n\n\n802\nChina, Hong Kong SAR\n1995\n6144498\nHKG\n\n\n803\nChina, Hong Kong SAR\n1996\n6275363\nHKG\n\n\n804\nChina, Hong Kong SAR\n1997\n6430651\nHKG\n\n\n805\nChina, Hong Kong SAR\n1998\n6591717\nHKG\n\n\n806\nChina, Hong Kong SAR\n1999\n6732627\nHKG\n\n\n807\nChina, Hong Kong SAR\n2000\n6835301\nHKG\n\n\n808\nChina, Hong Kong SAR\n2001\n6892752\nHKG\n\n\n809\nChina, Hong Kong SAR\n2002\n6912079\nHKG\n\n\n810\nChina, Hong Kong SAR\n2003\n6906631\nHKG\n\n\n811\nChina, Hong Kong SAR\n2004\n6896523\nHKG\n\n\n812\nChina, Hong Kong SAR\n2005\n6896686\nHKG\n\n\n813\nChina, Hong Kong SAR\n2006\n6910671\nHKG\n\n\n814\nChina, Hong Kong SAR\n2007\n6934748\nHKG\n\n\n815\nChina, Hong Kong SAR\n2008\n6967866\nHKG\n\n\n816\nChina, Hong Kong SAR\n2009\n7006930\nHKG\n\n\n817\nChina, Hong Kong SAR\n2010\n7049514\nHKG\n\n\n818\nChina, Hong Kong SAR\n2011\n7096359\nHKG\n\n\n819\nChina, Hong Kong SAR\n2012\n7148493\nHKG\n\n\n820\nChina, Hong Kong SAR\n2013\n7203836\nHKG\n\n\n821\nChina, Macao SAR\n1995\n398459\nMAC\n\n\n822\nChina, Macao SAR\n1996\n405231\nMAC\n\n\n823\nChina, Macao SAR\n1997\n412031\nMAC\n\n\n824\nChina, Macao SAR\n1998\n418810\nMAC\n\n\n825\nChina, Macao SAR\n1999\n425448\nMAC\n\n\n826\nChina, Macao SAR\n2000\n431907\nMAC\n\n\n827\nChina, Macao SAR\n2001\n438080\nMAC\n\n\n828\nChina, Macao SAR\n2002\n444150\nMAC\n\n\n829\nChina, Macao SAR\n2003\n450711\nMAC\n\n\n830\nChina, Macao SAR\n2004\n458542\nMAC\n\n\n831\nChina, Macao SAR\n2005\n468149\nMAC\n\n\n832\nChina, Macao SAR\n2006\n479808\nMAC\n\n\n833\nChina, Macao SAR\n2007\n493206\nMAC\n\n\n834\nChina, Macao SAR\n2008\n507528\nMAC\n\n\n835\nChina, Macao SAR\n2009\n521617\nMAC\n\n\n836\nChina, Macao SAR\n2010\n534626\nMAC\n\n\n837\nChina, Macao SAR\n2011\n546278\nMAC\n\n\n838\nChina, Macao SAR\n2012\n556783\nMAC\n\n\n839\nChina, Macao SAR\n2013\n566375\nMAC\n\n\n\n\n\n\n\n似乎台湾不在 tidyr_population 数据集中。\n在这种情况下,您可能会尝试找到包含台湾人口数据的数据集,并将其添加到 tidyr_population 数据集中。但我们留给您自行解决。\n\n\n\n\n\n\n练习\n\n\n\n22.13 练习题:将油耗与地理数据合并\n运行代码查看这两个数据集。\n第一个数据集 oil_2012 记录了 2012 年的油耗:\n\noil_2012\n\n\n\n\n\n\n\n\ncountry\noil_consump\n\n\n\n\n1343\nUnited Arab Emirates\n35200000\n\n\n1344\nArgentina\n28600000\n\n\n1345\nAustralia\n46100000\n\n\n1346\nAustria\n11900000\n\n\n1347\nAzerbaijan\n4170000\n\n\n...\n...\n...\n\n\n1417\nUSA\n778000000\n\n\n1418\nUzbekistan\n3030000\n\n\n1419\nVenezuela\n37200000\n\n\n1420\nVietnam\n17000000\n\n\n1421\nSouth Africa\n26300000\n\n\n\n\n79 rows × 2 columns\n\n\n\n而 country_regions 列出了国家及其相应的地区和大陆:\n\ncountry_regions\n\n\n\n\n\n\n\n\ncountry_name\ncountry_code\ncontinent\n\n\n\n\n0\nAfghanistan\nAFG\nAsia\n\n\n1\nAlbania\nALB\nEurope\n\n\n2\nAlgeria\nDZA\nAfrica\n\n\n3\nAmerican Samoa\nASM\nOceania\n\n\n4\nAndorra\nAND\nEurope\n\n\n...\n...\n...\n...\n\n\n237\nWestern Sahara\nESH\nAfrica\n\n\n238\nYemen\nYEM\nAsia\n\n\n239\nZambia\nZMB\nAfrica\n\n\n240\nZimbabwe\nZWE\nAfrica\n\n\n241\nÅland Islands\nALA\nEurope\n\n\n\n\n242 rows × 3 columns\n\n\n\n使用国家代码作为键连接这两个数据集。然后找出每个大陆油耗最高的国家。作为合理性检查,您的答案应包括美国和中国。\n\noil_2012['country_code'] = cc.convert(oil_2012['country'], to='ISO3')\n\noil_2012_regions = oil_2012.merge(country_regions, on='country_code', how='left')\n\nmax_oil_by_continent = oil_2012_regions.loc[\n    oil_2012_regions.groupby('continent')['oil_consump'].idxmax()\n]\n\nmax_oil_by_continent[['country', 'continent', 'oil_consump']]\n\n\n\n\n\n\n\n\ncountry\ncontinent\noil_consump\n\n\n\n\n21\nEgypt\nAfrica\n35300000\n\n\n74\nUSA\nAmericas\n778000000\n\n\n13\nChina\nAsia\n484000000\n\n\n62\nRussia\nEurope\n145000000\n\n\n2\nAustralia\nOceania\n46100000",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#集合运算",
    "href": "p_untangled_joining_2_cn.html#集合运算",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.12 集合运算",
    "text": "22.12 集合运算\n对于不熟悉的人来说,快速介绍一下集合运算。\n考虑两个数字集合 1:5 和 2:4。\n\nset_1 = set([1, 2, 3, 4, 5])\nset_2 = set([2, 3, 4])\n\n我们可以通过集合运算检查 set_1 中不在 set_2 中的值:\n\nset_1 - set_2\n\n{1, 5}\n\n\n以及使用以下方法检查 set_2 中不在 set_1 中的值:\n\nset_2 - set_1\n\nset()",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_joining_2_cn.html#练习题将油耗与地理数据合并",
    "href": "p_untangled_joining_2_cn.html#练习题将油耗与地理数据合并",
    "title": "22  连接 2:一对多、多键连接与键不匹配",
    "section": "22.13 练习题:将油耗与地理数据合并",
    "text": "22.13 练习题:将油耗与地理数据合并\n运行代码查看这两个数据集。\n第一个数据集 oil_2012 记录了 2012 年的油耗:\n\noil_2012\n\n\n\n\n\n\n\n\ncountry\noil_consump\n\n\n\n\n1343\nUnited Arab Emirates\n35200000\n\n\n1344\nArgentina\n28600000\n\n\n1345\nAustralia\n46100000\n\n\n1346\nAustria\n11900000\n\n\n1347\nAzerbaijan\n4170000\n\n\n...\n...\n...\n\n\n1417\nUSA\n778000000\n\n\n1418\nUzbekistan\n3030000\n\n\n1419\nVenezuela\n37200000\n\n\n1420\nVietnam\n17000000\n\n\n1421\nSouth Africa\n26300000\n\n\n\n\n79 rows × 2 columns\n\n\n\n而 country_regions 列出了国家及其相应的地区和大陆:\n\ncountry_regions\n\n\n\n\n\n\n\n\ncountry_name\ncountry_code\ncontinent\n\n\n\n\n0\nAfghanistan\nAFG\nAsia\n\n\n1\nAlbania\nALB\nEurope\n\n\n2\nAlgeria\nDZA\nAfrica\n\n\n3\nAmerican Samoa\nASM\nOceania\n\n\n4\nAndorra\nAND\nEurope\n\n\n...\n...\n...\n...\n\n\n237\nWestern Sahara\nESH\nAfrica\n\n\n238\nYemen\nYEM\nAsia\n\n\n239\nZambia\nZMB\nAfrica\n\n\n240\nZimbabwe\nZWE\nAfrica\n\n\n241\nÅland Islands\nALA\nEurope\n\n\n\n\n242 rows × 3 columns\n\n\n\n使用国家代码作为键连接这两个数据集。然后找出每个大陆油耗最高的国家。作为合理性检查,您的答案应包括美国和中国。\n\noil_2012['country_code'] = cc.convert(oil_2012['country'], to='ISO3')\n\noil_2012_regions = oil_2012.merge(country_regions, on='country_code', how='left')\n\nmax_oil_by_continent = oil_2012_regions.loc[\n    oil_2012_regions.groupby('continent')['oil_consump'].idxmax()\n]\n\nmax_oil_by_continent[['country', 'continent', 'oil_consump']]\n\n\n\n\n\n\n\n\ncountry\ncontinent\noil_consump\n\n\n\n\n21\nEgypt\nAfrica\n35300000\n\n\n74\nUSA\nAmericas\n778000000\n\n\n13\nChina\nAsia\n484000000\n\n\n62\nRussia\nEurope\n145000000\n\n\n2\nAustralia\nOceania\n46100000",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>连接 2:一对多、多键连接与键不匹配</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html",
    "href": "p_untangled_pivoting_cn.html",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "",
    "text": "23.1 软件包\nimport pandas as pd\nimport plotly.express as px",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#数据",
    "href": "p_untangled_pivoting_cn.html#数据",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.2 数据",
    "text": "23.2 数据\n运行下面的代码以加载和定义将在本课中使用的数据集。\n\n# Temperatures dataset\ntemperatures = pd.DataFrame(\n    {\n        \"country\": [\"Sweden\", \"Denmark\", \"Norway\"],\n        \"1994\": [1, 2, 3],\n        \"1995\": [3, 4, 5],\n        \"1996\": [5, 6, 7],\n    }\n)\n\n# Fuels Wide dataset\nfuels_wide = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/oil_per_capita_wide.csv\"\n)\n\n# Eurostat Births Wide dataset\neuro_births_wide = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/euro_births_wide.csv\"\n)\n\n# Contracts dataset\ncontracts = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/chicago_contracts_20_23.csv\"\n)\n\n# Population dataset\npopulation = pd.read_csv(\n    \"https://raw.githubusercontent.com/the-graph-courses/idap_book/main/data/tidyr_population.csv\"\n)",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#介绍",
    "href": "p_untangled_pivoting_cn.html#介绍",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.3 介绍",
    "text": "23.3 介绍\n重塑是一种数据操作技术,涉及重新定位数据集的行和列。这通常是为了使数据更易于分析或理解所需。\n在本课中,我们将介绍如何使用 pandas 函数有效地重塑数据。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#学习目标",
    "href": "p_untangled_pivoting_cn.html#学习目标",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.4 学习目标",
    "text": "23.4 学习目标\n\n理解宽数据格式和长数据格式的区别。\n学习如何使用 melt() 将宽数据重塑为长数据。\n学习如何使用 pivot() 将长数据重塑为宽数据。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#宽和长意味着什么",
    "href": "p_untangled_pivoting_cn.html#宽和长意味着什么",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.5 “宽”和“长”意味着什么?",
    "text": "23.5 “宽”和“长”意味着什么?\n“宽”和“长”这两个术语最好在示例数据集的上下文中理解。现在让我们看看一些示例。\n想象一下,你有三种产品,收集了这三个月的销售数据。\n宽格式:\n\n\n\n产品\n一月\n二月\n三月\n\n\n\n\nA\n100\n120\n110\n\n\nB\n90\n95\n100\n\n\nC\n80\n85\n90\n\n\n\n\n长格式:\n\n\n\n产品\n月份\n销售\n\n\n\n\nA\n一月\n100\n\n\nA\n二月\n120\n\n\nA\n三月\n110\n\n\nB\n一月\n90\n\n\nB\n二月\n95\n\n\nB\n三月\n100\n\n\nC\n一月\n80\n\n\nC\n二月\n85\n\n\nC\n三月\n90\n\n\n\n花一分钟时间研究这两个数据集,以确保你理解它们之间的关系。\n在宽数据集中,每个观测单位(每个产品)只占一行,每个测量(1月、2月、3月的销售)在单独的列中。\n而在长数据集中,每个观测单位(每个产品)占多行,每个测量有一行。\n\n这是另一个使用模拟数据的示例,其中观测单位是国家:\n长格式:\n\n\n\n国家\n年份\nGDP\n\n\n\n\nUSA\n2020\n21433\n\n\nUSA\n2021\n22940\n\n\nChina\n2020\n14723\n\n\nChina\n2021\n17734\n\n\n\n宽格式:\n\n\n\n国家\nGDP_2020\nGDP_2021\n\n\n\n\nUSA\n21433\n22940\n\n\nChina\n14723\n17734\n\n\n\n\n上述示例都是时间序列数据集,因为测量值在时间上重复。但宽和长的概念也与其他类型的数据相关。\n考虑下面的例子,显示三个公司的不同部门的员工数量:\n宽格式:\n\n\n\n公司\n人力资源\n销售\nIT\n\n\n\n\nA\n10\n20\n15\n\n\nB\n8\n25\n20\n\n\nC\n12\n18\n22\n\n\n\n长格式:\n\n\n\n公司\n部门\n员工数量\n\n\n\n\nA\n人力资源\n10\n\n\nA\n销售\n20\n\n\nA\nIT\n15\n\n\nB\n人力资源\n8\n\n\nB\n销售\n25\n\n\nB\nIT\n20\n\n\nC\n人力资源\n12\n\n\nC\n销售\n18\n\n\nC\nIT\n22\n\n\n\n在宽数据集中,每个观测单位(每个公司)只占一行,重复的测量值(不同部门的员工数量)分布在多列中。\n在长数据集中,每个观测单位分布在多行中。\n\n\n\n\n\n\n词汇\n\n\n\n观测单位,有时称为统计单位,是数据集描述的主要实体或项目。\n在第一个示例中,观测单位是产品;在第二个示例中是国家;在第三个示例中是公司。\n\n\n\n\n\n\n\n\n练习\n\n\n\n23.6 练习题:宽还是长?\n考虑前面创建的 temperatures 数据集:\n\ntemperatures\n\n\n\n\n\n\n\n\ncountry\n1994\n1995\n1996\n\n\n\n\n0\nSweden\n1\n3\n5\n\n\n1\nDenmark\n2\n4\n6\n\n\n2\nNorway\n3\n5\n7\n\n\n\n\n\n\n\n这些数据是宽格式还是长格式?",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题宽还是长",
    "href": "p_untangled_pivoting_cn.html#练习题宽还是长",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.6 练习题:宽还是长?",
    "text": "23.6 练习题:宽还是长?\n考虑前面创建的 temperatures 数据集:\n\ntemperatures\n\n\n\n\n\n\n\n\ncountry\n1994\n1995\n1996\n\n\n\n\n0\nSweden\n1\n3\n5\n\n\n1\nDenmark\n2\n4\n6\n\n\n2\nNorway\n3\n5\n7\n\n\n\n\n\n\n\n这些数据是宽格式还是长格式?",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#何时应该使用宽数据和长数据",
    "href": "p_untangled_pivoting_cn.html#何时应该使用宽数据和长数据",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.7 何时应该使用宽数据和长数据?",
    "text": "23.7 何时应该使用宽数据和长数据?\n事实上,这取决于你想做什么!宽格式非常适合 展示数据,因为这样便于视觉比较数值。长数据最适合一些数据分析任务,如分组和制图。\n了解如何轻松地在这两种格式之间切换是至关重要的。从宽格式切换到长格式,或反之,则称为重塑。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#使用-melt-从宽到长",
    "href": "p_untangled_pivoting_cn.html#使用-melt-从宽到长",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.8 使用 melt() 从宽到长",
    "text": "23.8 使用 melt() 从宽到长\n为了练习从宽到长的重塑,我们将考虑《世界数据》中关于人均化石燃料消费的数据。你可以在这里找到这些数据。\n下面,我们查看人均化石燃料消费的数据:\n\nfuels_wide\n\n\n\n\n\n\n\n\nEntity\nCode\ny_1970\ny_1980\ny_1990\ny_2000\ny_2010\ny_2020\n\n\n\n\n0\nAlgeria\nDZA\n1764.8470\n3532.7976\n4381.6636\n3351.2180\n5064.9863\n4877.2680\n\n\n1\nArgentina\nARG\n11677.9680\n10598.3990\n7046.2485\n7146.8154\n7966.7827\n6399.2114\n\n\n2\nAustralia\nAUS\n23040.4550\n25007.4380\n23046.9510\n23976.3550\n23584.3070\n20332.4100\n\n\n3\nAustria\nAUT\n14338.8090\n19064.0920\n16595.1930\n18189.0920\n18424.1170\n14934.0650\n\n\n4\nAzerbaijan\nAZE\nNaN\nNaN\n13516.0190\n9119.3470\n4031.9407\n5615.1157\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n76\nUnited States\nUSA\n40813.9530\n42365.6500\n37525.5160\n37730.1600\n31791.3070\n26895.4770\n\n\n77\nUzbekistan\nUZB\nNaN\nNaN\n6324.8677\n3197.1330\n1880.1338\n1859.1548\n\n\n78\nVenezuela\nVEN\n11138.2210\n16234.0960\n12404.5570\n11239.9260\n14948.3070\n4742.6226\n\n\n79\nVietnam\nVNM\n1757.6117\n439.9465\n523.2565\n1280.3065\n2296.7590\n2927.7446\n\n\n80\nWorld\nOWID_WRL\n7217.8340\n8002.0854\n7074.2583\n6990.4272\n6879.6110\n6216.8060\n\n\n\n\n81 rows × 8 columns\n\n\n\n我们观察到,每个观测单位(每个国家)只占一行,重复的测量值(以千瓦时当量计的化石燃料消费)分布在多列中。因此,该数据集为宽格式。\n为了将其转换为长格式,我们可以使用方便的 melt 函数。在 melt 中,可以定义不想重塑的 id 变量,如下所示:\n\nfuels_long = fuels_wide.melt(id_vars=[\"Entity\", \"Code\"])\nfuels_long\n\n\n\n\n\n\n\n\nEntity\nCode\nvariable\nvalue\n\n\n\n\n0\nAlgeria\nDZA\ny_1970\n1764.8470\n\n\n1\nArgentina\nARG\ny_1970\n11677.9680\n\n\n2\nAustralia\nAUS\ny_1970\n23040.4550\n\n\n3\nAustria\nAUT\ny_1970\n14338.8090\n\n\n4\nAzerbaijan\nAZE\ny_1970\nNaN\n\n\n...\n...\n...\n...\n...\n\n\n481\nUnited States\nUSA\ny_2020\n26895.4770\n\n\n482\nUzbekistan\nUZB\ny_2020\n1859.1548\n\n\n483\nVenezuela\nVEN\ny_2020\n4742.6226\n\n\n484\nVietnam\nVNM\ny_2020\n2927.7446\n\n\n485\nWorld\nOWID_WRL\ny_2020\n6216.8060\n\n\n\n\n486 rows × 4 columns\n\n\n\n非常简单!\n让我们排序一下,使其更易读:\n\nfuels_long = fuels_long.sort_values(by=['Entity', 'variable'])\nfuels_long\n\n\n\n\n\n\n\n\nEntity\nCode\nvariable\nvalue\n\n\n\n\n0\nAlgeria\nDZA\ny_1970\n1764.8470\n\n\n81\nAlgeria\nDZA\ny_1980\n3532.7976\n\n\n162\nAlgeria\nDZA\ny_1990\n4381.6636\n\n\n243\nAlgeria\nDZA\ny_2000\n3351.2180\n\n\n324\nAlgeria\nDZA\ny_2010\n5064.9863\n\n\n...\n...\n...\n...\n...\n\n\n161\nWorld\nOWID_WRL\ny_1980\n8002.0854\n\n\n242\nWorld\nOWID_WRL\ny_1990\n7074.2583\n\n\n323\nWorld\nOWID_WRL\ny_2000\n6990.4272\n\n\n404\nWorld\nOWID_WRL\ny_2010\n6879.6110\n\n\n485\nWorld\nOWID_WRL\ny_2020\n6216.8060\n\n\n\n\n486 rows × 4 columns\n\n\n\n年份现在在 variable 变量中表示,所有的消费值占据单一变量 value。我们可能希望将 variable 列重命名为 year,将 value 列重命名为 oil_consumption。这可以直接在 melt 函数中完成:\n\nfuels_long = fuels_wide.melt(\n    id_vars=['Entity', 'Code'],\n    var_name='year',\n    value_name='oil_consumption'\n).sort_values(by=['Entity', 'year'])\nfuels_long\n\n\n\n\n\n\n\n\nEntity\nCode\nyear\noil_consumption\n\n\n\n\n0\nAlgeria\nDZA\ny_1970\n1764.8470\n\n\n81\nAlgeria\nDZA\ny_1980\n3532.7976\n\n\n162\nAlgeria\nDZA\ny_1990\n4381.6636\n\n\n243\nAlgeria\nDZA\ny_2000\n3351.2180\n\n\n324\nAlgeria\nDZA\ny_2010\n5064.9863\n\n\n...\n...\n...\n...\n...\n\n\n161\nWorld\nOWID_WRL\ny_1980\n8002.0854\n\n\n242\nWorld\nOWID_WRL\ny_1990\n7074.2583\n\n\n323\nWorld\nOWID_WRL\ny_2000\n6990.4272\n\n\n404\nWorld\nOWID_WRL\ny_2010\n6879.6110\n\n\n485\nWorld\nOWID_WRL\ny_2020\n6216.8060\n\n\n\n\n486 rows × 4 columns\n\n\n\n你还可能希望去掉每个年份前的 y_。这可以通过字符串操作实现。\n\nfuels_long['year'] = fuels_long['year'].str.replace('y_', '').astype(int)\nfuels_long\n\n\n\n\n\n\n\n\nEntity\nCode\nyear\noil_consumption\n\n\n\n\n0\nAlgeria\nDZA\n1970\n1764.8470\n\n\n81\nAlgeria\nDZA\n1980\n3532.7976\n\n\n162\nAlgeria\nDZA\n1990\n4381.6636\n\n\n243\nAlgeria\nDZA\n2000\n3351.2180\n\n\n324\nAlgeria\nDZA\n2010\n5064.9863\n\n\n...\n...\n...\n...\n...\n\n\n161\nWorld\nOWID_WRL\n1980\n8002.0854\n\n\n242\nWorld\nOWID_WRL\n1990\n7074.2583\n\n\n323\nWorld\nOWID_WRL\n2000\n6990.4272\n\n\n404\nWorld\nOWID_WRL\n2010\n6879.6110\n\n\n485\nWorld\nOWID_WRL\n2020\n6216.8060\n\n\n\n\n486 rows × 4 columns\n\n\n\n以下是我们上面所做的事情:\n\n使用 str.replace() 去除每个年份前的 y_ 前缀。\n使用 astype(int) 将 year 列转换为整数。\n使用 sort_values() 按 “Entity” 和 “year” 对数据进行排序。\n\n\n\n\n\n\n\n练习\n\n\n\n23.9 练习题:将 Temperatures 数据集转换为长格式\n将下面显示的 temperatures 数据集转换为长格式。你的答案应包含以下列名:“country”, “year”, 和 “avg_temp”。\n\n# Your code here\ntemperatures\n\n\n\n\n\n\n\n\ncountry\n1994\n1995\n1996\n\n\n\n\n0\nSweden\n1\n3\n5\n\n\n1\nDenmark\n2\n4\n6\n\n\n2\nNorway\n3\n5\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n23.10 练习题:将 Eurostat 的出生数据转换为长格式\n在本练习题中,你将使用来自 Eurostat 的 euro_births_wide 数据集。它显示了 50 个欧洲国家的年度出生人数:\n\neuro_births_wide.head()\n\n\n\n\n\n\n\n\ncountry\nx2015\nx2016\nx2017\nx2018\nx2019\nx2020\nx2021\n\n\n\n\n0\nBelgium\n122274.0\n121896.0\n119690.0\n118319.0\n117695.0\n114350.0\n118349.0\n\n\n1\nBulgaria\n65950.0\n64984.0\n63955.0\n62197.0\n61538.0\n59086.0\n58678.0\n\n\n2\nCzechia\n110764.0\n112663.0\n114405.0\n114036.0\n112231.0\n110200.0\n111793.0\n\n\n3\nDenmark\n58205.0\n61614.0\n61397.0\n61476.0\n61167.0\n60937.0\n63473.0\n\n\n4\nGermany\n737575.0\n792141.0\n784901.0\n787523.0\n778090.0\n773144.0\n795492.0\n\n\n\n\n\n\n\n数据是宽格式。将其转换为长格式的 DataFrame,包含以下列名:“country”, “year”, 和 “births_count”。\n去掉年份列名的 x 前缀,并将它们转换为整数。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题将-temperatures-数据集转换为长格式",
    "href": "p_untangled_pivoting_cn.html#练习题将-temperatures-数据集转换为长格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.9 练习题:将 Temperatures 数据集转换为长格式",
    "text": "23.9 练习题:将 Temperatures 数据集转换为长格式\n将下面显示的 temperatures 数据集转换为长格式。你的答案应包含以下列名:“country”, “year”, 和 “avg_temp”。\n\n# Your code here\ntemperatures\n\n\n\n\n\n\n\n\ncountry\n1994\n1995\n1996\n\n\n\n\n0\nSweden\n1\n3\n5\n\n\n1\nDenmark\n2\n4\n6\n\n\n2\nNorway\n3\n5\n7",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题将-eurostat-的出生数据转换为长格式",
    "href": "p_untangled_pivoting_cn.html#练习题将-eurostat-的出生数据转换为长格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.10 练习题:将 Eurostat 的出生数据转换为长格式",
    "text": "23.10 练习题:将 Eurostat 的出生数据转换为长格式\n在本练习题中,你将使用来自 Eurostat 的 euro_births_wide 数据集。它显示了 50 个欧洲国家的年度出生人数:\n\neuro_births_wide.head()\n\n\n\n\n\n\n\n\ncountry\nx2015\nx2016\nx2017\nx2018\nx2019\nx2020\nx2021\n\n\n\n\n0\nBelgium\n122274.0\n121896.0\n119690.0\n118319.0\n117695.0\n114350.0\n118349.0\n\n\n1\nBulgaria\n65950.0\n64984.0\n63955.0\n62197.0\n61538.0\n59086.0\n58678.0\n\n\n2\nCzechia\n110764.0\n112663.0\n114405.0\n114036.0\n112231.0\n110200.0\n111793.0\n\n\n3\nDenmark\n58205.0\n61614.0\n61397.0\n61476.0\n61167.0\n60937.0\n63473.0\n\n\n4\nGermany\n737575.0\n792141.0\n784901.0\n787523.0\n778090.0\n773144.0\n795492.0\n\n\n\n\n\n\n\n数据是宽格式。将其转换为长格式的 DataFrame,包含以下列名:“country”, “year”, 和 “births_count”。\n去掉年份列名的 x 前缀,并将它们转换为整数。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#使用长数据进行分析",
    "href": "p_untangled_pivoting_cn.html#使用长数据进行分析",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.11 使用长数据进行分析",
    "text": "23.11 使用长数据进行分析\n让我们看看为什么长数据通常更适合分析。\n再次考虑 fuels_wide 数据集:\n\nfuels_wide.head()\n\n\n\n\n\n\n\n\nEntity\nCode\ny_1970\ny_1980\ny_1990\ny_2000\ny_2010\ny_2020\n\n\n\n\n0\nAlgeria\nDZA\n1764.847\n3532.7976\n4381.6636\n3351.2180\n5064.9863\n4877.2680\n\n\n1\nArgentina\nARG\n11677.968\n10598.3990\n7046.2485\n7146.8154\n7966.7827\n6399.2114\n\n\n2\nAustralia\nAUS\n23040.455\n25007.4380\n23046.9510\n23976.3550\n23584.3070\n20332.4100\n\n\n3\nAustria\nAUT\n14338.809\n19064.0920\n16595.1930\n18189.0920\n18424.1170\n14934.0650\n\n\n4\nAzerbaijan\nAZE\nNaN\nNaN\n13516.0190\n9119.3470\n4031.9407\n5615.1157\n\n\n\n\n\n\n\n\nfuels_long.head()\n\n\n\n\n\n\n\n\nEntity\nCode\nyear\noil_consumption\n\n\n\n\n0\nAlgeria\nDZA\n1970\n1764.8470\n\n\n81\nAlgeria\nDZA\n1980\n3532.7976\n\n\n162\nAlgeria\nDZA\n1990\n4381.6636\n\n\n243\nAlgeria\nDZA\n2000\n3351.2180\n\n\n324\nAlgeria\nDZA\n2010\n5064.9863\n\n\n\n\n\n\n\n如果我们想要找到每个国家的平均化石燃料消费,使用长格式非常容易:\n\nfuels_long.groupby('Entity')['oil_consumption'].mean()\n\nEntity\nAlgeria           3828.796750\nArgentina         8472.570833\nAustralia        23164.652667\nAustria          16924.228000\nAzerbaijan        8070.605600\n                     ...     \nUnited States    36187.010500\nUzbekistan        3315.322325\nVenezuela        11784.621600\nVietnam           1537.604133\nWorld             7063.503650\nName: oil_consumption, Length: 81, dtype: float64\n\n\n但使用宽格式,这就不那么容易了:\n\nfuels_wide[['y_1970', 'y_1980', 'y_1990', 'y_2000', 'y_2010', 'y_2020']].mean(axis=1)\n\n0      3828.796750\n1      8472.570833\n2     23164.652667\n3     16924.228000\n4      8070.605600\n          ...     \n76    36187.010500\n77     3315.322325\n78    11784.621600\n79     1537.604133\n80     7063.503650\nLength: 81, dtype: float64\n\n\n想象一下如果你有 100 年的数据!\n而均值是一个相当简单的操作。你如何计算每个国家的化石燃料消费标准差?\n\n长数据对于制图也非常有用。\n例如,要绘制每个国家随时间变化的平均化石燃料消费,我们可以使用以下代码:\n\nsubset = fuels_long.query('Entity in [\"Peru\", \"Iran\", \"China\"]')\npx.line(subset, x='year', y='oil_consumption', color='Entity', title='Average Fossil Fuel Consumption per Country')\n\n                                                \n\n\n使用宽格式无法直接创建类似的图,因为你要绘制的数据散布在多个列中。\n因此,如你所见,虽然宽数据适合展示,但长数据对于分析和制图非常有用。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#从长到宽",
    "href": "p_untangled_pivoting_cn.html#从长到宽",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.12 从长到宽",
    "text": "23.12 从长到宽\n现在你已经知道如何使用 melt() 将宽格式重塑为长格式。那么如何从长格式转换为宽格式呢?为此,你可以使用 pivot() 函数。\n但在我们看到如何使用这个函数来操作长数据之前,先考虑你可能在哪里会遇到长数据。\n虽然宽数据往往来自外部来源(如上所示),但长数据则可能是在数据处理过程中由你创建的,特别是在分组聚合的过程中。\n现在让我们看一个例子。\n我们将使用芝加哥市从 2020 年到 2023 年授予的合同数据集。你可以在这里找到更多关于数据的信息。\n\ncontracts\n\n\n\n\n\n\n\n\nyear\napproval_date\ndescription\ncontract_num\nrevision_num\nspecification_num\ncontract_type\nstart_date\nend_date\ndepartment\nvendor_name\nvendor_id\naddress_1\naddress_2\ncity\nstate\nzip\naward_amount\nprocurement_type\ncontract_pdf\n\n\n\n\n0\n2020\n2020-01-02\nLEASE\n24406\n32\n96136\nPROPERTY LEASE\nNaN\nNaN\nNaN\n8700 BUILDING LLC\n89123305A\n7300 S NARRAGANSETT\nNaN\nBEDFORD PARK\nIllinois\n60638\n321.1\nNaN\nNaN\n\n\n1\n2020\n2020-01-03\nDFSS-HHS-CS-CEL:\n113798\n0\n1070196\nDELEGATE AGENCY\n12/01/2019\n11/30/2022\nDEPT OF FAMILY AND SUPPORT SERVICES\nCATHOLIC CHARITIES OF THE ARCHDIOCESE OF CHICAGO\n102484615A\n1 E BANKS ST\nNaN\nCHICAGO\nIllinois\n60670\n17692515.0\nNaN\nNaN\n\n\n2\n2020\n2020-01-03\nDFSS-HHS-CS-CEL:\n113819\n0\n1070196\nDELEGATE AGENCY\n12/01/2019\n11/30/2022\nDEPT OF FAMILY AND SUPPORT SERVICES\nKIMBALL DAYCARE CENTER & KINDERGARTEN INC\n105458567Z\n1636-1638 N KIMBALL AVE\nNaN\nCHICAGO\nIllinois\n60647\n11461500.0\nNaN\nhttp://ecm.cityofchicago.org/eSMARTContracts/s...\n\n\n3\n2020\n2020-01-03\nDFSS-HHS-CS-CEL:\n113818\n0\n1070196\nDELEGATE AGENCY\n12/01/2019\n11/30/2022\nDEPT OF FAMILY AND SUPPORT SERVICES\nJUDAH INTERNATIONAL OUTREACH MINISTRIES, INC\n94219962X\n856 N PULASKI RD\nNaN\nCHICAGO\nIllinois\n60651\n2356515.0\nNaN\nhttp://ecm.cityofchicago.org/eSMARTContracts/s...\n\n\n4\n2020\n2020-01-03\nDFSS-HHS-CS-CEL:\n113820\n0\n1070196\nDELEGATE AGENCY\n12/01/2019\n11/30/2022\nDEPT OF FAMILY AND SUPPORT SERVICES\nMarillac St. Vincent Family Services Inc DBA S...\n97791861L\n212 S FRANCISCO AVENUE EFT\nNaN\nCHICAGO\nIllinois\n60612\n3666015.0\nNaN\nhttp://ecm.cityofchicago.org/eSMARTContracts/s...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n28823\n2023\n2023-12-29\nDFSS-CORP-HL-PSH:\n220413\n3\n1221503\nDELEGATE AGENCY\nNaN\nNaN\nDEPT OF FAMILY AND SUPPORT SERVICES\nINNER VOICE INC.\n6231926M\n1621 W WALNUT ST FL 1ST\nNaN\nCHICAGO\nIllinois\n60612\n0.0\nNaN\nNaN\n\n\n28824\n2023\n2023-12-29\nDFSS-CORP-YS-OST:\n253846\n0\n1247493\nDELEGATE AGENCY\nNaN\nNaN\nDEPT OF FAMILY AND SUPPORT SERVICES\nAFTER-SCHOOL MATTERS, INC.|CLEANED-UP\n72580818P\n66 E RANDOLPH ST FL 1ST\nNaN\nCHICAGO\nIllinois\n60601\n32000.0\nNaN\nNaN\n\n\n28825\n2023\n2023-12-29\nDFSS-IDHS-HL-INTHS:\n253843\n0\n1235949\nDELEGATE AGENCY\nNaN\nNaN\nDEPT OF FAMILY AND SUPPORT SERVICES\nBREAKTHROUGH URBAN MINISTRIES, INC.\n94722896V\n402 N ST LOUIS AVENUE EFT\nNaN\nCHICAGO\nIllinois\n60624\n14400.0\nNaN\nNaN\n\n\n28826\n2023\n2023-12-29\nCDPH-RW-PA: ESS-HRSA PO 116685 CHICAGO HOUSE A...\n192085\n1\n1095441\nDELEGATE AGENCY\nNaN\nNaN\nDEPARTMENT OF HEALTH\nCHICAGO HOUSE & SOCIAL SERVICE AGENCY\n105470138T\n2229 S MICHIGAN AVE 304 EFT\nNaN\nCHICAGO\nIllinois\n60616\n-32025.2\nNaN\nNaN\n\n\n28827\n2023\n2023-12-29\nDFSS-HHS-CS-CEL:\n222199\n1\n1070196\nDELEGATE AGENCY\nNaN\nNaN\nDEPT OF FAMILY AND SUPPORT SERVICES\nALLISON'S INFANT & TODDLER CENTER INC\n62751817Z\n234 E 115TH ST FL 1ST\nNaN\nCHICAGO\nIllinois\n60628\n141923.0\nNaN\nNaN\n\n\n\n\n28828 rows × 20 columns\n\n\n\n每一行对应一个合同,我们有每个合同的编号、授予年份、合同金额、供应商的名称和地址等变量。\n现在,考虑以下对 contracts 数据集的分组摘要,显示每年按供应商所在州的合同数量:\n\ncontracts_summary = contracts.groupby(\"state\")[\"year\"].value_counts().reset_index()\ncontracts_summary\n\n\n\n\n\n\n\n\nstate\nyear\ncount\n\n\n\n\n0\nAlabama\n2023\n7\n\n\n1\nAlabama\n2021\n2\n\n\n2\nAlabama\n2020\n1\n\n\n3\nAlabama\n2022\n1\n\n\n4\nArizona\n2020\n3\n\n\n...\n...\n...\n...\n\n\n128\nWashington\n2021\n1\n\n\n129\nWisconsin\n2023\n25\n\n\n130\nWisconsin\n2020\n18\n\n\n131\nWisconsin\n2022\n17\n\n\n132\nWisconsin\n2021\n15\n\n\n\n\n133 rows × 3 columns\n\n\n\n这个分组操作的输出是一个典型的“长”数据集。每个观测单位(每个州)占多行,每个测量(每年)有一行。\n现在,让我们看看如何使用 pivot() 将长数据转换为宽格式。\n代码相当简单:\n\ncontracts_wide = contracts_summary.pivot(\n    index=\"state\", columns=\"year\", values=\"count\"\n).reset_index()\ncontracts_wide.head()\n\n\n\n\n\n\n\nyear\nstate\n2020\n2021\n2022\n2023\n\n\n\n\n0\nAlabama\n1.0\n2.0\n1.0\n7.0\n\n\n1\nArizona\n3.0\n1.0\n3.0\n2.0\n\n\n2\nArkansas\n1.0\nNaN\n1.0\nNaN\n\n\n3\nBritish Columbia\nNaN\n1.0\nNaN\nNaN\n\n\n4\nCalifornia\n36.0\n42.0\n43.0\n38.0\n\n\n\n\n\n\n\n如你所见,pivot() 有三个重要的参数:\n\nindex 定义了哪些列将用作新的索引。在我们的例子中,是 “state”,因为我们希望每一行表示一个州。\ncolumns 确定了哪个变量用于定义宽格式中的列名。在我们的例子中,是 “year”。你可以看到年份现在是列名。\nvalues 指定了哪些值将成为宽数据格式的核心。在我们的例子中,是合同数量 “count”。\n\n你也可能希望将年份作为主要的观测单位,每一年占一行。这可以类似于上述示例进行,但将 year 作为索引,state 作为列:\n\ncontracts_wide_year = contracts_summary.pivot(\n    index=\"year\", columns=\"state\", values=\"count\"\n).reset_index()\ncontracts_wide_year\n\n\n\n\n\n\n\nstate\nyear\nAlabama\nArizona\nArkansas\nBritish Columbia\nCalifornia\nCanada\nColorado\nConnecticut\nDelaware\n...\nOregon\nPennsylvania\nRhode Island\nSouth Carolina\nTennessee\nTexas\nVermont\nVirginia\nWashington\nWisconsin\n\n\n\n\n0\n2020\n1.0\n3.0\n1.0\nNaN\n36.0\n1.0\n6.0\n1.0\nNaN\n...\n5.0\n20.0\n1.0\n2.0\n2.0\n25.0\nNaN\n4.0\nNaN\n18.0\n\n\n1\n2021\n2.0\n1.0\nNaN\n1.0\n42.0\n1.0\n2.0\n5.0\nNaN\n...\nNaN\n24.0\nNaN\n3.0\n2.0\n24.0\n1.0\n4.0\n1.0\n15.0\n\n\n2\n2022\n1.0\n3.0\n1.0\nNaN\n43.0\n1.0\n7.0\n3.0\n1.0\n...\nNaN\n31.0\nNaN\n2.0\n3.0\n37.0\nNaN\n7.0\nNaN\n17.0\n\n\n3\n2023\n7.0\n2.0\nNaN\nNaN\n38.0\nNaN\n6.0\n5.0\n2.0\n...\nNaN\n37.0\nNaN\n1.0\n3.0\n28.0\nNaN\n9.0\nNaN\n25.0\n\n\n\n\n4 rows × 44 columns\n\n\n\n在这里,唯一的观测单位(我们的行)现在是年份(2020, 2021, 2022, 2023)。\n\n\n\n\n\n\n练习\n\n\n\n23.13 练习题:将 Temperatures 长格式转换回宽格式\n将你上面创建的长格式 temperatures_long 数据集转换回宽格式。你的答案应包含以下列名:“country”, “1994”, “1995”, 和 “1996”。\n\n# Your code here\n\n\n\n\n\n\n\n\n\n练习\n\n\n\n23.14 练习题:将 Population 数据转换为宽格式\npopulation 数据集显示了 219 个国家随时间变化的人口。\n将这些数据重塑为宽格式。\n\npopulation\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\n0\nAfghanistan\n1995\n17586073\n\n\n1\nAfghanistan\n1996\n18415307\n\n\n2\nAfghanistan\n1997\n19021226\n\n\n3\nAfghanistan\n1998\n19496836\n\n\n4\nAfghanistan\n1999\n19987071\n\n\n...\n...\n...\n...\n\n\n4040\nZimbabwe\n2009\n12888918\n\n\n4041\nZimbabwe\n2010\n13076978\n\n\n4042\nZimbabwe\n2011\n13358738\n\n\n4043\nZimbabwe\n2012\n13724317\n\n\n4044\nZimbabwe\n2013\n14149648\n\n\n\n\n4045 rows × 3 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题将-temperatures-长格式转换回宽格式",
    "href": "p_untangled_pivoting_cn.html#练习题将-temperatures-长格式转换回宽格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.13 练习题:将 Temperatures 长格式转换回宽格式",
    "text": "23.13 练习题:将 Temperatures 长格式转换回宽格式\n将你上面创建的长格式 temperatures_long 数据集转换回宽格式。你的答案应包含以下列名:“country”, “1994”, “1995”, 和 “1996”。\n\n# Your code here",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题将-population-数据转换为宽格式",
    "href": "p_untangled_pivoting_cn.html#练习题将-population-数据转换为宽格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.14 练习题:将 Population 数据转换为宽格式",
    "text": "23.14 练习题:将 Population 数据转换为宽格式\npopulation 数据集显示了 219 个国家随时间变化的人口。\n将这些数据重塑为宽格式。\n\npopulation\n\n\n\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\n0\nAfghanistan\n1995\n17586073\n\n\n1\nAfghanistan\n1996\n18415307\n\n\n2\nAfghanistan\n1997\n19021226\n\n\n3\nAfghanistan\n1998\n19496836\n\n\n4\nAfghanistan\n1999\n19987071\n\n\n...\n...\n...\n...\n\n\n4040\nZimbabwe\n2009\n12888918\n\n\n4041\nZimbabwe\n2010\n13076978\n\n\n4042\nZimbabwe\n2011\n13358738\n\n\n4043\nZimbabwe\n2012\n13724317\n\n\n4044\nZimbabwe\n2013\n14149648\n\n\n\n\n4045 rows × 3 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#重塑可能很难",
    "href": "p_untangled_pivoting_cn.html#重塑可能很难",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.15 重塑可能很难",
    "text": "23.15 重塑可能很难\n我们这里主要看了一些非常简单的重塑示例,但在实际中,重塑可能很难准确地完成。\n当遇到这种情况时,我们建议查看 pandas 团队的官方文档,因为它包含丰富的示例。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#总结",
    "href": "p_untangled_pivoting_cn.html#总结",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.16 总结",
    "text": "23.16 总结\n恭喜!你已经掌握了使用 pandas 重塑数据的技巧。\n你现在理解了宽格式和长格式之间的区别,并且能够熟练地使用 melt() 和 pivot() 根据需要转换你的数据。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题答案宽还是长",
    "href": "p_untangled_pivoting_cn.html#练习题答案宽还是长",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.17 练习题答案:宽还是长?",
    "text": "23.17 练习题答案:宽还是长?\n数据是宽格式。",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题答案将-temperatures-转换为长格式",
    "href": "p_untangled_pivoting_cn.html#练习题答案将-temperatures-转换为长格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.18 练习题答案:将 Temperatures 转换为长格式",
    "text": "23.18 练习题答案:将 Temperatures 转换为长格式\n\n# Melt the wide data into long format\ntemperatures_long = temperatures.melt(\n    id_vars=[\"country\"], var_name=\"year\", value_name=\"avgtemp\"\n)\n\n# Display the long format data\ntemperatures_long\n\n\n\n\n\n\n\n\ncountry\nyear\navgtemp\n\n\n\n\n0\nSweden\n1994\n1\n\n\n1\nDenmark\n1994\n2\n\n\n2\nNorway\n1994\n3\n\n\n3\nSweden\n1995\n3\n\n\n4\nDenmark\n1995\n4\n\n\n5\nNorway\n1995\n5\n\n\n6\nSweden\n1996\n5\n\n\n7\nDenmark\n1996\n6\n\n\n8\nNorway\n1996\n7",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题答案将-eurostat-的出生数据转换为长格式",
    "href": "p_untangled_pivoting_cn.html#练习题答案将-eurostat-的出生数据转换为长格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.19 练习题答案:将 Eurostat 的出生数据转换为长格式",
    "text": "23.19 练习题答案:将 Eurostat 的出生数据转换为长格式\n\n# Melt the wide data into long format\nbirths_long = euro_births_wide.melt(\n    id_vars=[\"country\"], var_name=\"year\", value_name=\"births_count\"\n)\n\n# Display the long format data\nbirths_long\n\n\n\n\n\n\n\n\ncountry\nyear\nbirths_count\n\n\n\n\n0\nBelgium\nx2015\n122274.0\n\n\n1\nBulgaria\nx2015\n65950.0\n\n\n2\nCzechia\nx2015\n110764.0\n\n\n3\nDenmark\nx2015\n58205.0\n\n\n4\nGermany\nx2015\n737575.0\n\n\n...\n...\n...\n...\n\n\n345\nUkraine\nx2021\n212.0\n\n\n346\nArmenia\nx2021\n271983.0\n\n\n347\nAzerbaijan\nx2021\nNaN\n\n\n348\nGeorgia\nx2021\n112284.0\n\n\n349\nNaN\nx2021\n45946.0\n\n\n\n\n350 rows × 3 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题答案将-temperatures-转换回宽格式",
    "href": "p_untangled_pivoting_cn.html#练习题答案将-temperatures-转换回宽格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.20 练习题答案:将 Temperatures 转换回宽格式",
    "text": "23.20 练习题答案:将 Temperatures 转换回宽格式\n\n# Pivot the long data into wide format\ntemperatures_wide = temperatures_long.pivot(\n    index=\"country\", columns=\"year\", values=\"avgtemp\"\n).reset_index()\n\n# Display the wide format data\ntemperatures_wide\n\n\n\n\n\n\n\nyear\ncountry\n1994\n1995\n1996\n\n\n\n\n0\nDenmark\n2\n4\n6\n\n\n1\nNorway\n3\n5\n7\n\n\n2\nSweden\n1\n3\n5",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_untangled_pivoting_cn.html#练习题答案将-population-数据转换为宽格式",
    "href": "p_untangled_pivoting_cn.html#练习题答案将-population-数据转换为宽格式",
    "title": "23  使用 melt() 和 pivot() 重新塑造数据",
    "section": "23.21 练习题答案:将 Population 数据转换为宽格式",
    "text": "23.21 练习题答案:将 Population 数据转换为宽格式\n\n# Pivot the long data into wide format\npopulation_wide = population.pivot(\n    index=\"country\", columns=\"year\", values=\"population\"\n).reset_index()\n\n# Display the wide format data\npopulation_wide\n\n\n\n\n\n\n\nyear\ncountry\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\n\n\n0\nAfghanistan\n17586073.0\n18415307.0\n19021226.0\n19496836.0\n19987071.0\n20595360.0\n21347782.0\n22202806.0\n23116142.0\n24018682.0\n24860855.0\n25631282.0\n26349243.0\n27032197.0\n27708187.0\n28397812.0\n29105480.0\n29824536.0\n30551674.0\n\n\n1\nAlbania\n3357858.0\n3341043.0\n3331317.0\n3325456.0\n3317941.0\n3304948.0\n3286084.0\n3263596.0\n3239385.0\n3216197.0\n3196130.0\n3179573.0\n3166222.0\n3156608.0\n3151185.0\n3150143.0\n3153883.0\n3162083.0\n3173271.0\n\n\n2\nAlgeria\n29315463.0\n29845208.0\n30345466.0\n30820435.0\n31276295.0\n31719449.0\n32150198.0\n32572977.0\n33003442.0\n33461345.0\n33960903.0\n34507214.0\n35097043.0\n35725377.0\n36383302.0\n37062820.0\n37762962.0\n38481705.0\n39208194.0\n\n\n3\nAmerican Samoa\n52874.0\n53926.0\n54942.0\n55899.0\n56768.0\n57522.0\n58176.0\n58729.0\n59117.0\n59262.0\n59117.0\n58652.0\n57919.0\n57053.0\n56245.0\n55636.0\n55274.0\n55128.0\n55165.0\n\n\n4\nAndorra\n63854.0\n64274.0\n64090.0\n63799.0\n64084.0\n65399.0\n68000.0\n71639.0\n75643.0\n79060.0\n81223.0\n81877.0\n81292.0\n79969.0\n78659.0\n77907.0\n77865.0\n78360.0\n79218.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n212\nWallis and Futuna Islands\n14143.0\n14221.0\n14309.0\n14394.0\n14460.0\n14497.0\n14501.0\n14476.0\n14422.0\n14344.0\n14246.0\n14126.0\n13988.0\n13840.0\n13697.0\n13565.0\n13451.0\n13353.0\n13272.0\n\n\n213\nWest Bank and Gaza Strip\n2598393.0\n2722497.0\n2851993.0\n2980563.0\n3099951.0\n3204572.0\n3291620.0\n3363542.0\n3426549.0\n3489743.0\n3559856.0\n3638829.0\n3725076.0\n3817551.0\n3914035.0\n4012880.0\n4114199.0\n4218771.0\n4326295.0\n\n\n214\nYemen\n15018201.0\n15578640.0\n16088019.0\n16564235.0\n17035531.0\n17522537.0\n18029989.0\n18551068.0\n19081306.0\n19612696.0\n20139661.0\n20661714.0\n21182162.0\n21703571.0\n22229625.0\n22763008.0\n23304206.0\n23852409.0\n24407381.0\n\n\n215\nZambia\n8841338.0\n9073311.0\n9320089.0\n9577483.0\n9839179.0\n10100981.0\n10362137.0\n10625423.0\n10894519.0\n11174650.0\n11470022.0\n11781612.0\n12109620.0\n12456527.0\n12825031.0\n13216985.0\n13633796.0\n14075099.0\n14538640.0\n\n\n216\nZimbabwe\n11639364.0\n11846110.0\n12045813.0\n12229500.0\n12384727.0\n12503652.0\n12586763.0\n12640922.0\n12673103.0\n12693047.0\n12710589.0\n12724308.0\n12740160.0\n12784041.0\n12888918.0\n13076978.0\n13358738.0\n13724317.0\n14149648.0\n\n\n\n\n217 rows × 20 columns",
    "crumbs": [
      "数据操作",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>使用 melt() 和 pivot() 重新塑造数据</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html",
    "href": "p_ai_LLM_functions_cn.html",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "",
    "text": "24.1 简介\n在本教程中,我们将探讨如何利用大型语言模型(LLMs)使用 OpenAI 的 API 生成文本。我们将使用 gpt-4o-mini 模型来生成对固定和可变提示的响应,使用辅助函数和向量化优化我们的代码,并使用 pandas DataFrame 处理数据。",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#学习目标",
    "href": "p_ai_LLM_functions_cn.html#学习目标",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.2 学习目标",
    "text": "24.2 学习目标\n\n设置 OpenAI 客户端\n定义和使用简单函数生成文本\n使用向量化将函数应用于 DataFrame",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#设置-openai-客户端",
    "href": "p_ai_LLM_functions_cn.html#设置-openai-客户端",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.3 设置 OpenAI 客户端",
    "text": "24.3 设置 OpenAI 客户端\n首先,我们需要使用您的 API 密钥设置 OpenAI 客户端。在这里,我们将密钥存储在名为 local_settings.py 的文件中,然后将其导入到我们的脚本中。\n\nfrom openai import OpenAI\nimport pandas as pd\nimport numpy as np\nfrom local_settings import OPENAI_KEY\n\n# 设置 OpenAI API 密钥\n# 使用您的 API 密钥初始化 OpenAI 客户端\nclient = OpenAI(api_key=OPENAI_KEY)\n\n或者,您可以在设置 api_key 时直接传递您的 API 密钥,但请注意不要在代码中泄露,尤其是如果您计划共享或发布代码时。",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#进行-api-调用",
    "href": "p_ai_LLM_functions_cn.html#进行-api-调用",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.4 进行 API 调用",
    "text": "24.4 进行 API 调用\n让我们进行一次 API 调用,使用 gpt-4o-mini 模型生成对提示的响应。\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"What is the most tourist-friendly city in France?\"}]\n)\nprint(response.choices[0].message.content)\n\nParis is often considered the most tourist-friendly city in France. Renowned for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral, Paris offers a wealth of activities, cultural experiences, and culinary delights. The city is well-equipped for tourists, with extensive public transportation, abundant information centers, and a wide variety of accommodations and dining options. Additionally, Paris hosts numerous events and festivals that cater to visitors, making it a top destination for travelers from around the world.",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#定义辅助函数",
    "href": "p_ai_LLM_functions_cn.html#定义辅助函数",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.5 定义辅助函数",
    "text": "24.5 定义辅助函数\n为了简化我们的代码并避免重复,我们将定义一个用于进行 API 调用的辅助函数。API 调用包含大量样板代码,因此将此逻辑封装在函数中可以使我们的代码更简洁、更易维护。\n如果您忘记如何构建 API 调用,请参考 OpenAI API 文档 或在线搜索“OpenAI Python API example”。\n以下是我们如何定义 llm_chat 函数:\n\ndef llm_chat(message):\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": message}]\n    )\n    return response.choices[0].message.content\n\n此函数接受一个 message 作为输入,发送给 LLM,并返回生成的响应。 model 参数指定要使用的模型 —— 在此情况下为 gpt-4o-mini。我们使用此模型是因为它在质量、速度和成本之间具有良好的平衡。如果您需要更高性能的模型,可以使用 gpt-4o,但请注意不要超过您的 API 配额。",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#固定问题",
    "href": "p_ai_LLM_functions_cn.html#固定问题",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.6 固定问题",
    "text": "24.6 固定问题\n让我们首先向 gpt-4o-mini 模型发送一个固定问题并获取响应。\n\n# 示例用法\nresponse = llm_chat(\"What is the most tourist-friendly city in France?\")\nprint(response)\n\nThe most tourist-friendly city in France is often considered to be Paris. Known as the \"City of Light,\" Paris offers a wealth of attractions, including iconic landmarks like the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and Montmartre. The city's extensive public transportation system makes it easy for visitors to navigate, and it is known for its vibrant culture, dining options, and shopping experiences.\n\nMoreover, Paris is well-equipped for tourists, with a wide range of accommodations, guided tours, and information centers. The city's rich history, beautiful architecture, and numerous parks and gardens also enhance its appeal to visitors from around the world.\n\nHowever, other cities in France, such as Nice, Lyon, and Marseille, also offer unique experiences and are considered friendly to tourists, each with their own charm and attractions.\n\n\n\n\n\n\n\n\n练习\n\n\n\n24.7 练习题:获取巴西最适合旅游的城市\n使用 llm_chat 函数询问模型巴西最适合旅游的城市。将响应存储在名为 rec_brazil 的变量中。打印响应。\n\n# 您的代码",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#练习题获取巴西最适合旅游的城市",
    "href": "p_ai_LLM_functions_cn.html#练习题获取巴西最适合旅游的城市",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.7 练习题:获取巴西最适合旅游的城市",
    "text": "24.7 练习题:获取巴西最适合旅游的城市\n使用 llm_chat 函数询问模型巴西最适合旅游的城市。将响应存储在名为 rec_brazil 的变量中。打印响应。\n\n# 您的代码",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#可变作为提示输入",
    "href": "p_ai_LLM_functions_cn.html#可变作为提示输入",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.8 可变作为提示输入",
    "text": "24.8 可变作为提示输入\n通常,您会希望基于不同的输入生成响应。让我们创建一个函数,该函数接受一个国家作为输入,并询问模型该国最适合旅游的城市。\n\ndef city_rec(country):\n    prompt = f\"What is the most tourist-friendly city in {country}?\"\n    return llm_chat(prompt)\n\n现在,您可以通过调用 city_rec(\"Country Name\") 来获取不同国家的推荐:\n\ncity_rec(\"Nigeria\")\n\n'One of the most tourist-friendly cities in Nigeria is Lagos. As the largest city in the country, Lagos offers a vibrant mix of culture, history, and modern attractions. Key points that make Lagos appealing to tourists include:\\n\\n1. **Cultural Diversity**: Lagos is a melting pot of cultures, showcasing a rich array of traditions, festivals, and cuisines.\\n\\n2. **Beaches**: The city boasts several beautiful beaches, such as Lekki and Tarkwa Bay, where visitors can relax and enjoy water activities.\\n\\n3. **Entertainment and Nightlife**: Lagos is known for its lively nightlife, with numerous clubs, restaurants, and entertainment options.\\n\\n4. **Museums and Art Galleries**: Visitors can explore places like the Nike Art Gallery and the National Museum, which provide insights into Nigerian art and history.\\n\\n5. **Local Markets**: Markets like Balogun and Lekki Market offer a unique shopping experience with local crafts, fabrics, and souvenirs.\\n\\n6. **Accessibility**: Lagos has an international airport (Murtala Muhammed International Airport) that connects it to major cities around the world, making it relatively easy for tourists to visit.\\n\\nWhile Lagos is a primary destination, other cities like Abuja (the capital), Calabar, and Port Harcourt also offer unique attractions and experiences for tourists.'\n\n\n然而,如果我们尝试将此函数直接用于国家列表或 DataFrame 列,它不会逐个处理每个国家。而是会尝试将列表连接成一个字符串,这不是我们想要的行为。\n\n# 错误用法\ncountry_df = pd.DataFrame({\"country\": [\"Nigeria\", \"Chile\", \"France\", \"Canada\"]})\n\nresponse = city_rec(country_df[\"country\"])\n\nprint(response)\n\nDetermining the \"most tourist-friendly\" city can vary based on personal experiences, business metrics, and travel reviews. However, generally speaking:\n\n1. **Nigeria**: Lagos is a major city that attracts tourists but may not be seen as the most tourist-friendly due to safety concerns and infrastructure challenges.\n   \n2. **Chile**: Santiago is the capital and offers a mix of cultural and modern attractions, making it relatively tourist-friendly, with good public transportation and hospitality.\n\n3. **France**: Paris is one of the most visited cities in the world, known for its iconic landmarks, rich history, and diverse gastronomy, making it highly tourist-friendly.\n\n4. **Canada**: Cities like Toronto and Vancouver are often considered very tourist-friendly, with a welcoming atmosphere, a range of attractions, and good public services.\n\nBased on global perception and tourist feedback, **Paris, France**, is often regarded as the most tourist-friendly city among the options provided.\n\n\n要逐个处理每个国家,我们可以使用 NumPy 的 vectorize 函数。此函数将 city_rec 转换为可以接受数组(如列表或 NumPy 数组)并按元素应用函数的形式。\n\n# 向量化函数\ncity_rec_vec = np.vectorize(city_rec)\n\n# 将函数应用于每个国家\ncountry_df[\"city_rec\"] = city_rec_vec(country_df[\"country\"])\ncountry_df\n\n\n\n\n\n\n\n\ncountry\ncity_rec\n\n\n\n\n0\nNigeria\nLagos is often considered the most tourist-fri...\n\n\n1\nChile\nSantiago is often considered the most tourist-...\n\n\n2\nFrance\nParis is often regarded as the most tourist-fr...\n\n\n3\nCanada\nDetermining the \"most tourist-friendly\" city i...\n\n\n\n\n\n\n\n此代码将输出一个包含新列 city_rec 的 DataFrame,其中包含每个国家对应的城市推荐。\n\n\n\n\n\n\n练习\n\n\n\n24.9 练习题:获取当地菜肴\n创建一个名为 get_local_dishes 的函数,该函数接受一个国家名称作为输入,并返回该国一些最著名的当地菜肴。然后,将此函数向量化并应用于 country_df DataFrame,为每个国家添加一个包含当地菜肴推荐的列。\n\n# 您的代码",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#练习题获取当地菜肴",
    "href": "p_ai_LLM_functions_cn.html#练习题获取当地菜肴",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.9 练习题:获取当地菜肴",
    "text": "24.9 练习题:获取当地菜肴\n创建一个名为 get_local_dishes 的函数,该函数接受一个国家名称作为输入,并返回该国一些最著名的当地菜肴。然后,将此函数向量化并应用于 country_df DataFrame,为每个国家添加一个包含当地菜肴推荐的列。\n\n# 您的代码",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#自动摘要电影数据集",
    "href": "p_ai_LLM_functions_cn.html#自动摘要电影数据集",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.10 自动摘要:电影数据集",
    "text": "24.10 自动摘要:电影数据集\n在此示例中,我们将使用来自 vega_datasets 的电影数据集为每部电影生成自动摘要。我们将每部电影的数据转换为字典,并将其作为输入提供给 LLM 生成一段关于其表现的摘要。\n首先,让我们加载电影数据集并预览前几行:\n\nimport pandas as pd\nimport vega_datasets as vd\n\n# 加载电影数据集\nmovies = vd.data.movies().head()  # 仅使用前 5 行以节省 API 积分\nmovies\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\nNaN\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nNone\nNone\nNaN\n6.1\n1071.0\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\nNaN\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nNone\nNone\nNaN\n6.9\n207.0\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\nNaN\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nNone\nNone\nNaN\n6.8\n865.0\n\n\n3\nLet's Talk About Sex\n373615.0\n373615.0\nNaN\n300000.0\nSep 11 1998\nNone\nNaN\nFine Line\nNone\nComedy\nNone\nNone\n13.0\nNaN\nNaN\n\n\n4\nSlam\n1009819.0\n1087521.0\nNaN\n1000000.0\nOct 09 1998\nR\nNaN\nTrimark\nOriginal Screenplay\nDrama\nContemporary Fiction\nNone\n62.0\n3.4\n165.0\n\n\n\n\n\n\n\n接下来,我们将 DataFrame 的每一行转换为字典。这将有助于将数据传递给 LLM。\n\n# 将每部电影的数据转换为字典\nmovies.to_dict(orient=\"records\")\n\n[{'Title': 'The Land Girls',\n  'US_Gross': 146083.0,\n  'Worldwide_Gross': 146083.0,\n  'US_DVD_Sales': nan,\n  'Production_Budget': 8000000.0,\n  'Release_Date': 'Jun 12 1998',\n  'MPAA_Rating': 'R',\n  'Running_Time_min': nan,\n  'Distributor': 'Gramercy',\n  'Source': None,\n  'Major_Genre': None,\n  'Creative_Type': None,\n  'Director': None,\n  'Rotten_Tomatoes_Rating': nan,\n  'IMDB_Rating': 6.1,\n  'IMDB_Votes': 1071.0},\n {'Title': 'First Love, Last Rites',\n  'US_Gross': 10876.0,\n  'Worldwide_Gross': 10876.0,\n  'US_DVD_Sales': nan,\n  'Production_Budget': 300000.0,\n  'Release_Date': 'Aug 07 1998',\n  'MPAA_Rating': 'R',\n  'Running_Time_min': nan,\n  'Distributor': 'Strand',\n  'Source': None,\n  'Major_Genre': 'Drama',\n  'Creative_Type': None,\n  'Director': None,\n  'Rotten_Tomatoes_Rating': nan,\n  'IMDB_Rating': 6.9,\n  'IMDB_Votes': 207.0},\n {'Title': 'I Married a Strange Person',\n  'US_Gross': 203134.0,\n  'Worldwide_Gross': 203134.0,\n  'US_DVD_Sales': nan,\n  'Production_Budget': 250000.0,\n  'Release_Date': 'Aug 28 1998',\n  'MPAA_Rating': None,\n  'Running_Time_min': nan,\n  'Distributor': 'Lionsgate',\n  'Source': None,\n  'Major_Genre': 'Comedy',\n  'Creative_Type': None,\n  'Director': None,\n  'Rotten_Tomatoes_Rating': nan,\n  'IMDB_Rating': 6.8,\n  'IMDB_Votes': 865.0},\n {'Title': \"Let's Talk About Sex\",\n  'US_Gross': 373615.0,\n  'Worldwide_Gross': 373615.0,\n  'US_DVD_Sales': nan,\n  'Production_Budget': 300000.0,\n  'Release_Date': 'Sep 11 1998',\n  'MPAA_Rating': None,\n  'Running_Time_min': nan,\n  'Distributor': 'Fine Line',\n  'Source': None,\n  'Major_Genre': 'Comedy',\n  'Creative_Type': None,\n  'Director': None,\n  'Rotten_Tomatoes_Rating': 13.0,\n  'IMDB_Rating': nan,\n  'IMDB_Votes': nan},\n {'Title': 'Slam',\n  'US_Gross': 1009819.0,\n  'Worldwide_Gross': 1087521.0,\n  'US_DVD_Sales': nan,\n  'Production_Budget': 1000000.0,\n  'Release_Date': 'Oct 09 1998',\n  'MPAA_Rating': 'R',\n  'Running_Time_min': nan,\n  'Distributor': 'Trimark',\n  'Source': 'Original Screenplay',\n  'Major_Genre': 'Drama',\n  'Creative_Type': 'Contemporary Fiction',\n  'Director': None,\n  'Rotten_Tomatoes_Rating': 62.0,\n  'IMDB_Rating': 3.4,\n  'IMDB_Votes': 165.0}]\n\n\n让我们将此新列存储在 DataFrame 中:\n\nmovies[\"full_dict\"] = movies.to_dict(orient=\"records\")\nmovies\n\n\n\n\n\n\n\n\nTitle\nUS_Gross\nWorldwide_Gross\nUS_DVD_Sales\nProduction_Budget\nRelease_Date\nMPAA_Rating\nRunning_Time_min\nDistributor\nSource\nMajor_Genre\nCreative_Type\nDirector\nRotten_Tomatoes_Rating\nIMDB_Rating\nIMDB_Votes\nfull_dict\n\n\n\n\n0\nThe Land Girls\n146083.0\n146083.0\nNaN\n8000000.0\nJun 12 1998\nR\nNaN\nGramercy\nNone\nNone\nNone\nNone\nNaN\n6.1\n1071.0\n{'Title': 'The Land Girls', 'US_Gross': 146083...\n\n\n1\nFirst Love, Last Rites\n10876.0\n10876.0\nNaN\n300000.0\nAug 07 1998\nR\nNaN\nStrand\nNone\nDrama\nNone\nNone\nNaN\n6.9\n207.0\n{'Title': 'First Love, Last Rites', 'US_Gross'...\n\n\n2\nI Married a Strange Person\n203134.0\n203134.0\nNaN\n250000.0\nAug 28 1998\nNone\nNaN\nLionsgate\nNone\nComedy\nNone\nNone\nNaN\n6.8\n865.0\n{'Title': 'I Married a Strange Person', 'US_Gr...\n\n\n3\nLet's Talk About Sex\n373615.0\n373615.0\nNaN\n300000.0\nSep 11 1998\nNone\nNaN\nFine Line\nNone\nComedy\nNone\nNone\n13.0\nNaN\nNaN\n{'Title': 'Let's Talk About Sex', 'US_Gross': ...\n\n\n4\nSlam\n1009819.0\n1087521.0\nNaN\n1000000.0\nOct 09 1998\nR\nNaN\nTrimark\nOriginal Screenplay\nDrama\nContemporary Fiction\nNone\n62.0\n3.4\n165.0\n{'Title': 'Slam', 'US_Gross': 1009819.0, 'Worl...\n\n\n\n\n\n\n\n现在,让我们定义一个 movie_performance 函数,该函数接受电影的数据字典,构建提示,并调用 llm_chat 函数以获取摘要:\n\ndef movie_performance(movie_data):\n    prompt = f\"Considering the following data on this movie {movie_data}, provide a one-paragraph summary of its performance for my report.\"\n    return llm_chat(prompt)\n\n我们将向量化此函数,以便可以将其应用于整个 full_dict 列:\n\nimport numpy as np\n\n# 向量化函数以应用于 DataFrame\nmovie_performance_vec = np.vectorize(movie_performance)\n\n让我们使用一个示例测试我们的函数:\n\n# 示例用法\nmovie_performance(\"Name: Kene's Movie, Sales: 100,000 USD\")\n\n\"Kene's Movie has demonstrated a commendable performance in the market, generating sales of 100,000 USD. This figure not only reflects the film's popularity but also indicates a strong reception from audiences. Such sales figures suggest successful marketing strategies and a solid viewer interest, positioning Kene's Movie as a significant contender within its genre. Overall, the movie's financial success highlights its appeal and potential for continued engagement in both current and future viewing platforms.\"\n\n\n最后,我们将应用向量化函数为每部电影生成摘要:\n\n# 为每部电影生成摘要\nmovies[\"llm_summary\"] = movie_performance_vec(movies[\"full_dict\"])\n\n您现在可以将生成的摘要与 DataFrame 一起保存到 CSV 文件:\n\n# 将结果保存到 CSV 文件\nmovies.to_csv(\"movies_output.csv\", index=False)\n\n这种方法允许您基于每部电影的完整数据生成详细摘要,这对于自动报告和数据分析非常有用。\n\n\n\n\n\n\n练习\n\n\n\n24.11 练习题:天气摘要\n使用来自 vega_datasets 的 seattle_weather 数据集的前 5 行,创建一个函数,该函数接受某一天的所有天气列,并生成该天天气状况的摘要。该函数应使用 LLM 根据提供的数据生成一段用于报告的一段摘要。将摘要存储在名为 weather_summary 的列中。\n\nweather = vd.data.seattle_weather().head()\nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\n\n\n\n\n\n\n\n\n# 您的代码",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#练习题天气摘要",
    "href": "p_ai_LLM_functions_cn.html#练习题天气摘要",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.11 练习题:天气摘要",
    "text": "24.11 练习题:天气摘要\n使用来自 vega_datasets 的 seattle_weather 数据集的前 5 行,创建一个函数,该函数接受某一天的所有天气列,并生成该天天气状况的摘要。该函数应使用 LLM 根据提供的数据生成一段用于报告的一段摘要。将摘要存储在名为 weather_summary 的列中。\n\nweather = vd.data.seattle_weather().head()\nweather\n\n\n\n\n\n\n\n\ndate\nprecipitation\ntemp_max\ntemp_min\nwind\nweather\n\n\n\n\n0\n2012-01-01\n0.0\n12.8\n5.0\n4.7\ndrizzle\n\n\n1\n2012-01-02\n10.9\n10.6\n2.8\n4.5\nrain\n\n\n2\n2012-01-03\n0.8\n11.7\n7.2\n2.3\nrain\n\n\n3\n2012-01-04\n20.3\n12.2\n5.6\n4.7\nrain\n\n\n4\n2012-01-05\n1.3\n8.9\n2.8\n6.1\nrain\n\n\n\n\n\n\n\n\n# 您的代码",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  },
  {
    "objectID": "p_ai_LLM_functions_cn.html#总结",
    "href": "p_ai_LLM_functions_cn.html#总结",
    "title": "24  在 Python 中使用 LLM 进行文本生成",
    "section": "24.12 总结",
    "text": "24.12 总结\n在本教程中,我们学习了在 Python 中使用 OpenAI 的 LLM 进行文本生成的基础知识,创建了辅助函数,并通过向量化将这些函数应用于数据集。\n在下一课中,我们将探讨结构化输出,允许我们指定从 LLM 获得响应的格式。我们将使用这一点从非结构化文本中提取结构化数据,这在数据分析中是常见任务。",
    "crumbs": [
      "使用 Python 中的 LLM",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>在 Python 中使用 LLM 进行文本生成</span>"
    ]
  }
]