---
title: 'Conditional Transformations of Variables'
---

```{python}
# | echo: false
# Setup
import pandas as pd
import numpy as np
pd.options.display.max_rows = 7
```

## Introduction

In the previous lesson, you learned the basics of data transformation in pandas.

In this lesson, we will explore how to **conditionally transform variables** in pandas using methods like `replace()` and custom functions. 

Conditional transformations are essential when you need to recode variables or create new ones based on specific criteria.

Let's dive in!

## Learning Objectives

By the end of this lesson, you will:

- Be able to transform or create new variables based on conditions using `replace()` and dictionaries.
- Know how to handle `NaN` values in `replace()` transformations.
- Be able to define and apply custom functions to recode variables.

## Packages

This lesson will require `pandas`, `numpy`, `plotly.express`, and `vega_datasets`:

```{python}
import pandas as pd
import numpy as np
import vega_datasets as vd
import plotly.express as px
```

## Introduction to `replace()`

One common task in data wrangling is to replace values in a column based on certain conditions. The `replace()` method in pandas is a versatile tool for this purpose.

In the `tips` dataset, the `day` column contains abbreviated day names:

```{python}
tips = px.data.tips()
tips['day'].unique()
```

Our goal is to replace these abbreviations with the full day names.

We can create a dictionary that maps the abbreviated names to the full names:

```{python}
day_mapping = {
    "Sun": "Sunday",
    "Sat": "Saturday",
    "Fri": "Friday",
    "Thur": "Thursday"
}
```

Now, we use the `replace()` method with the dictionary:

```{python}
tips['day_full'] = tips['day'].replace(day_mapping)
tips
```

Alternatively, we can perform the replacement directly within the `replace()` method without explicitly defining a dictionary:

```{python}
tips['day_full'] = tips['day'].replace({
    "Sun": "Sunday",
    "Sat": "Saturday",
    "Fri": "Friday",
    "Thur": "Thursday"
})
tips[['day', 'day_full']].head()
```


::: {.callout-tip title="Practice"}

## Practice Q: Abbreviate Sex

Using the `tips` dataset, replace the values in the `sex` column to abbreviate gender:

- Replace `"Female"` with `"F"`.
- Replace `"Male"` with `"M"`.

Assign the result to a new column called `sex_abbr` and display the first few rows.

```{python}
# Your code here:
```

:::

## Handling Missing Values with `replace()`

Sometimes, your dataset may contain missing values (`NaN` or `None`) that you want to replace with a placeholder or specific value. The `replace()` method can handle this.

Let's examine the `Creative_Type` column in the `movies` dataset from vega_datasets:

```{python}
movies = vd.data.movies()
movies['Creative_Type'].value_counts(dropna=False)
```

Notice that there are some `None` values in the `Creative_Type` column.

Let's replace `None` with `"Unknown/Unclear"`:

```{python}
movies['Creative_Type'] = movies['Creative_Type'].replace({
    None: "Unknown/Unclear", # ðŸ‘ˆ On this line, None is the key
})
```

Now, let's verify the replacement:

```{python}
movies['Creative_Type'].value_counts(dropna=False)
```

While `None` is typically used to represent missing strings, `NaN` is used for missing numbers. Consider the `US_DVD_Sales` column:

```{python}
movies.query("US_DVD_Sales.isna()").shape # Check the number of missing values
```

```{python}
movies['US_DVD_Sales'].tail(10) # View the last 10 values. Some are missing.
```

We can use `replace()` to replace `NaN` with 0:

```{python}
movies['US_DVD_Sales'] = movies['US_DVD_Sales'].replace({
    np.nan: 0 # ðŸ‘ˆ `NaN` is represented by `np.nan` in pandas
})
```

Let's verify the replacement:

```{python}
movies['US_DVD_Sales'].tail(10)
```

```{python}
movies.query("US_DVD_Sales.isna()").shape
```

::: {.callout-practice title="Practice"}

## Practice Q: Standardize MPAA Ratings

In the `movies` dataset, the `MPAA_Rating` column contains movie ratings. Some entries are `None` or `"Not Rated"`. Replace both `None` and `"Not Rated"` with `"Unrated"`.

Then, use `value_counts()` to see how many movies are unrated. There should be 699 movies in this category.

```{python}
# Your code here:

```

:::

## Categorizing Numeric Data with Custom Functions

Recall from our previous lesson that we can use custom functions with conditional logic to transform variables. For example, we can categorize the `US_Gross` column into three categories based on the following criteria:

- If the value is less than 10 million, the category is `"Low"`.
- If the value is between 10 million and 50 million, the category is `"Medium"`.
- If the value is greater than 50 million, the category is `"High"`.

```{python}
def categ_gross(gross):
    if gross < 10000000:
        return "Low"
    elif gross >= 10000000 and gross <= 50000000:
        return "Medium"
    elif gross > 50000000:
        return "High"
    else:
        return None 


categ_gross_vec = np.vectorize(categ_gross)
```


::: {.callout-note title="Side Note"}

The `np.vectorize` function in the above case will return `None` as a string. To enforce the `None` type, you can use the `otypes` parameter:

```{python}
categ_gross_vec = np.vectorize(categ_gross, otypes=[object])
```

:::


Now we can apply it to the entire column:

```{python}
movies['Gross_Category'] = categ_gross_vec(movies['US_Gross'])
movies['Gross_Category'].value_counts(dropna=False)
```

This can also be achieved with `pd.cut()`, `np.where()` and `np.select()`. But the custom function approach is the most flexible. Below we'll see how to extend this to more complex conditions.

## Complex Transformations with Custom Functions

The flexibility of custom functions can be extended easily to more complex conditional transformations. 

For example, suppose we want to flag superhero movies as "US action movie" or "Global action movie" based on their US and worldwide gross earnings.

- For Super Hero movies, if the US gross and worldwide gross are the same (indicating sales were only in the US), the movie is flagged as a **US action movie**.
- For Super Hero movies, if the worldwide gross is greater than the US gross, the movie is flagged as a **global action movie**.
- For all other movies, we leave the flag blank

We can define a funcion that takes in three arguments and returns the appropriate flag:

```{python}
# Define the function to flag movies based on the conditions
def flag_movie(movie_type, us, worldwide):
    if movie_type == 'Super Hero' and us == worldwide:
        return 'US action movie'
    elif movie_type == 'Super Hero' and worldwide > us:
        return 'Global action movie'
    else:
        return None
```

Let's test it out with a few sets of values:

```{python}
print(flag_movie(movie_type='Super Hero', us=100, worldwide=100))
print(flag_movie(movie_type='Super Hero', us=100, worldwide=200))
print(flag_movie(movie_type='Comedy', us=100, worldwide=100))
```

Now, let's vectorize it:

```{python}
flag_movie_vec = np.vectorize(flag_movie)
``` 

We can now apply it to the columns:

```{python}
movies['Action_Flag'] = flag_movie_vec(movies['Creative_Type'], movies['US_Gross'], movies['Worldwide_Gross'])
movies
```

To see the distribution of movie categories based on our flag, we can use `value_counts()`:

```{python}
movies['Action_Flag'].value_counts(dropna=False)
```

::: {.callout-practice title="Practice"}

### Practice: Flag Movies Based on Ratings

In the `movies` dataset, flag movies as **Critic-friendly** or **Commercial** based on their Rotten Tomatoes and IMDB ratings.

- If the Rotten Tomatoes rating is above 70% and the IMDB rating is below 5, the movie is flagged as **Critic-friendly**.
- If the Rotten Tomatoes rating is below 50% and the IMDB rating is above 7, the movie is flagged as **Commercial**.
- Otherwise, the movie is categorized as **Other**.
- Count how many movies are **Critic-friendly** and **Commercial**. There should be 13 Critic-friendly movies and 33 Commercial movies. Do you recognize any of them?

```{python}
# Your code here:

```

:::

## Wrap-Up

In this lesson, you learned how to conditionally transform variables in pandas using:

- The `replace()` method with dictionaries to map and replace specific values.
- Handling missing values (`NaN` or `None`) during replacements.
- Defining custom functions and applying them to handle complex conditions.

These techniques are powerful tools for data cleaning and preprocessing, allowing you to reshape your data to meet your analysis needs.

See you next time!

